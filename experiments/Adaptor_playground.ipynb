{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPY27lPqYCuXHHH6okv90GH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katarinagresova/AgoBind/blob/adaptor/experiments/Adaptor_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-1yLEAp4wEm",
        "outputId": "ced8282c-5b8b-42d4-c4e2-c171f8ef0096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adaptor in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from adaptor) (1.10.0+cu111)\n",
            "Collecting transformers==4.10.2\n",
            "  Using cached transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from adaptor) (0.1.96)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (0.0.49)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (4.63.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Using cached tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.2->adaptor) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.2->adaptor) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.10.2->adaptor) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.2->adaptor) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.2->adaptor) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.2->adaptor) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.2->adaptor) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.2->adaptor) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.2->adaptor) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.2->adaptor) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.2->adaptor) (7.1.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.11.6\n",
            "    Uninstalling tokenizers-0.11.6:\n",
            "      Successfully uninstalled tokenizers-0.11.6\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.18.0\n",
            "    Uninstalling transformers-4.18.0:\n",
            "      Successfully uninstalled transformers-4.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "agobind 0.0.1 requires transformers>=4.17.0, but you have transformers 4.10.2 which is incompatible.\u001b[0m\n",
            "Successfully installed tokenizers-0.10.3 transformers-4.10.2\n",
            "Collecting git+https://github.com/katarinagresova/AgoBind\n",
            "  Cloning https://github.com/katarinagresova/AgoBind to /tmp/pip-req-build-_ud7q37f\n",
            "  Running command git clone -q https://github.com/katarinagresova/AgoBind /tmp/pip-req-build-_ud7q37f\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from agobind==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: pip>=20.0.1 in /usr/local/lib/python3.7/dist-packages (from agobind==0.0.1) (21.1.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from agobind==0.0.1) (1.21.5)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from agobind==0.0.1) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from agobind==0.0.1) (4.63.0)\n",
            "Collecting transformers>=4.17.0\n",
            "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->agobind==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->agobind==0.0.1) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->agobind==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->agobind==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->agobind==0.0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->agobind==0.0.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->agobind==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.17.0->agobind==0.0.1) (0.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.17.0->agobind==0.0.1) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.17.0->agobind==0.0.1) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.17.0->agobind==0.0.1) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.17.0->agobind==0.0.1) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.17.0->agobind==0.0.1) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Using cached tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.17.0->agobind==0.0.1) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.17.0->agobind==0.0.1) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.17.0->agobind==0.0.1) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.17.0->agobind==0.0.1) (3.7.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.17.0->agobind==0.0.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.17.0->agobind==0.0.1) (1.1.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.10.3\n",
            "    Uninstalling tokenizers-0.10.3:\n",
            "      Successfully uninstalled tokenizers-0.10.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.10.2\n",
            "    Uninstalling transformers-4.10.2:\n",
            "      Successfully uninstalled transformers-4.10.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "adaptor 0.1.3 requires transformers==4.10.2, but you have transformers 4.18.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tokenizers-0.11.6 transformers-4.18.0\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: comet-ml in /usr/local/lib/python3.7/dist-packages (3.28.3)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (1.3.2)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (4.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (1.14.0)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (2.9.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (3.0.2)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (0.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet-ml) (1.15.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (3.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (7.352.0)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (0.20.35)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (2.23.0)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.7/dist-packages (from dulwich!=0.20.33,>=0.20.6->comet-ml) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from dulwich!=0.20.33,>=0.20.6->comet-ml) (2021.10.8)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.7/dist-packages (from everett[ini]>=1.0.1->comet-ml) (5.0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (3.10.0.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (4.11.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=3.1.0,>=2.6.0->comet-ml) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml) (2.10)\n"
          ]
        }
      ],
      "source": [
        "%pip install adaptor\n",
        "%pip install git+https://github.com/katarinagresova/AgoBind\n",
        "%pip install sklearn\n",
        "%pip install comet-ml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/katarinagresova/AgoBind.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71NIbB6H5Bk2",
        "outputId": "1eac5422-3f53-4fc1-f1a5-abeadefefc90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AgoBind' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AgoBind/experiments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BHnsbok5F2o",
        "outputId": "a7c27ba4-792f-43d0-a64f-1e175847b328"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AgoBind/experiments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import comet_ml"
      ],
      "metadata": {
        "id": "XQoSnzdd40nr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. pick the model base\n",
        "from adaptor.lang_module import LangModule\n",
        "\n",
        "kmer_len = 6\n",
        "stride = 1\n",
        "lang_module = LangModule(f\"armheb/DNA_bert_{kmer_len}\")"
      ],
      "metadata": {
        "id": "z5x0pz1C43RC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Initialize training arguments\n",
        "# We apply NUM_STEPS stopping strategy in cases where at least one of the objectives does not converge in max_steps\n",
        "from adaptor.utils import AdaptationArguments, StoppingStrategy\n",
        "\n",
        "training_arguments = AdaptationArguments(output_dir=\"dnabert_for_clash\",\n",
        "                                         learning_rate=2e-5,\n",
        "                                         max_steps=100000,\n",
        "                                         stopping_strategy=StoppingStrategy.ALL_OBJECTIVES_CONVERGED,\n",
        "                                         # stopping_strategy=StoppingStrategy.NUM_STEPS_ALL_OBJECTIVES,\n",
        "                                         do_train=True,\n",
        "                                         do_eval=True,\n",
        "                                         warmup_steps=10000,\n",
        "                                         gradient_accumulation_steps=10,\n",
        "                                         logging_steps=100,\n",
        "                                         eval_steps=100,\n",
        "                                         save_steps=100,\n",
        "                                         num_train_epochs=30,\n",
        "                                         evaluation_strategy=\"steps\",\n",
        "                                         also_log_converged_objectives=True)"
      ],
      "metadata": {
        "id": "lpMoF7qo45nc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def prepare_data(path_to_csv, path_to_txt, path_to_labels):\n",
        "    dset = pd.read_csv(path_to_csv, sep='\\t')\n",
        "    dset['seq'] = dset.apply(lambda x: x['miRNA'] + 'NNNN' + x['gene'], axis=1)\n",
        "    dset['seq'] = dset['seq'].apply(lambda x: ' '.join([x[i:i+kmer_len] for i in range(0, len(x)-kmer_len+1, stride)]))\n",
        "    np.savetxt(path_to_txt, dset['seq'].values, fmt='%s')\n",
        "    np.savetxt(path_to_labels, dset['label'].values, fmt='%s')"
      ],
      "metadata": {
        "id": "FqR2Q1zb47j9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_data('../data/train_set_1_1_CLASH2013_paper.tsv', '../data/train_set_1_1_CLASH2013_paper.txt', '../data/train_set_1_1_CLASH2013_paper_labels.txt')\n",
        "prepare_data('../data/evaluation_set_1_1_CLASH2013_paper.tsv', '../data/evaluation_set_1_1_CLASH2013_paper.txt', '../data/evaluation_set_1_1_CLASH2013_paper_labels.txt')"
      ],
      "metadata": {
        "id": "-6wBwnXQ5ALn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. pick objectives\n",
        "# Objectives take either List[str] for in-memory iteration, or a source file path for streamed iterati\n",
        "from adaptor.objectives.MLM import MaskedLanguageModeling\n",
        "from adaptor.objectives.classification import SequenceClassification\n",
        "\n",
        "mlm = MaskedLanguageModeling(lang_module,\n",
        "                                 batch_size=16,\n",
        "                                 texts_or_path='../data/train_set_1_1_CLASH2013_paper.txt',\n",
        "                                 val_texts_or_path='../data/evaluation_set_1_1_CLASH2013_paper.txt',\n",
        "                            )\n",
        "\n",
        "cls = SequenceClassification(lang_module,\n",
        "                                  batch_size=16,\n",
        "                                  texts_or_path='../data/train_set_1_1_CLASH2013_paper.txt',\n",
        "                                  labels_or_path='../data/train_set_1_1_CLASH2013_paper_labels.txt',\n",
        "                                 val_texts_or_path='../data/evaluation_set_1_1_CLASH2013_paper.txt',\n",
        "                                 val_labels_or_path='../data/evaluation_set_1_1_CLASH2013_paper_labels.txt',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMXvuaJX5WXX",
        "outputId": "04bcc9b4-5467-436c-e5dd-9a0603332802"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at armheb/DNA_bert_6 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at armheb/DNA_bert_6 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "These layers of the loaded SEQ_CLASSIFICATION were not merged: ['weight', 'bias', 'weight', 'bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. pick a schedule of the selected objectives\n",
        "# This one will initially fit the first objective until convergence on its eval set, then fits the second one \n",
        "from adaptor.schedules import ParallelSchedule, SequentialSchedule\n",
        "\n",
        "schedule = ParallelSchedule([mlm, cls], training_arguments)\n",
        "#schedule = SequentialSchedule([mlm, cls], training_arguments)"
      ],
      "metadata": {
        "id": "DlLlrNy05Ysd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comet_ml.init(project_name='dnabert_for_clash', api_key='3NQhHgMmmlfnoqTcvkG03nYo9')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JMVI06p5dT2",
        "outputId": "5bea2e2a-532d-44e5-d39f-e6e0f6c9afda"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMET INFO: Comet API key is valid\n",
            "COMET WARNING: running in Google Colab, but can't find mounted drive. Using HOME instead\n",
            "COMET WARNING: if drive is mounted, set COMET_CONFIG to save config there\n",
            "COMET INFO: Comet API key saved in /root/.comet.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import logging\n",
        "import os\n",
        "from typing import List, Dict, Tuple, Union, Optional\n",
        "\n",
        "from transformers import WEIGHTS_NAME\n",
        "import torch\n",
        "from transformers import Trainer, BatchEncoding\n",
        "from transformers.modeling_utils import unwrap_model\n",
        "\n",
        "from adaptor.lang_module import LangModule\n",
        "from adaptor.schedules import Schedule\n",
        "from adaptor.utils import AdaptationArguments\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "\n",
        "class Adapter(Trainer):\n",
        "    \"\"\"\n",
        "    Adapter instance is a lightweigt wrapper of HuggingFace Trainer.\n",
        "    1. It performs mapping of IterableDatasets constructed in Schedule, to Trainer(*dataset)\n",
        "    2. For user convenience, it re-evaluates arguments sanity for (multi-)objective adaptation.\n",
        "    3. It propagates computation of loss to schedule, which distributes them to corresponding Objectives.\n",
        "    4. It extends training logs (created in events `on_log` and `on_evaluate`) with objective-specific logs.\n",
        "    5. It extends model persistence on checkpoints and after the training to a separate model for each Objective.\n",
        "    \"\"\"\n",
        "\n",
        "    permitted_args = [\"args\", \"tokenizer\", \"callbacks\", \"optimizers\"]\n",
        "    eval_metrics_prefix = \"eval\"\n",
        "\n",
        "    def __init__(self, lang_module: LangModule, schedule: Schedule, args: AdaptationArguments, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialises Adapter, used in the same way as HuggingFace Trainer, refer to its documentation for more features.\n",
        "        :param lang_module: Wrapper of multi-head model with registered heads for each objective of `schedule`.\n",
        "        :param schedule: Adaptor's Schedule. Determines ordering of applying training Objectives and other.\n",
        "        :param args: Positional arguments to be passed to HF Trainer.\n",
        "        :param kwargs: Keyword arguments to be checked and passed to HF Trainer.\n",
        "        \"\"\"\n",
        "        unexpected_args = [k for k in kwargs.keys() if k not in self.permitted_args]\n",
        "        if unexpected_args:\n",
        "            raise ValueError(\"Adapter(**kwargs) got these unexpected kwargs: %s\" % unexpected_args)\n",
        "\n",
        "        self.schedule = schedule\n",
        "\n",
        "        orig_callbacks = [] if \"callbacks\" not in kwargs else kwargs.pop(\"callbacks\")\n",
        "        print(orig_callbacks)\n",
        "\n",
        "        super().__init__(model=lang_module,\n",
        "                         args=args,\n",
        "                         train_dataset=self.schedule.iterable_dataset(split=\"train\"),\n",
        "                         eval_dataset=self.schedule.iterable_dataset(split=\"eval\"),\n",
        "                         data_collator=self.flattened_collator,\n",
        "                         compute_metrics=None,  # would require a static prediction format among objectives\n",
        "                         callbacks=orig_callbacks + [schedule.should_stop_check_callback()],\n",
        "                         **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def flattened_collator(features: List[BatchEncoding]) -> BatchEncoding:\n",
        "        \"\"\"\n",
        "        Objectives take care of their own data collation, so this collator just flattens the outputs of batch_size=1.\n",
        "        :return: loss and a placeholder of unused outputs, for compatibility\n",
        "        \"\"\"\n",
        "        assert len(features) == 1, \"Sorry, for multi-GPU training, we only support DistributedDataParallel for now.\"\n",
        "\n",
        "        return features[0]\n",
        "\n",
        "    def compute_loss(self,\n",
        "                     model: LangModule,\n",
        "                     inputs: Dict[str, torch.Tensor],\n",
        "                     return_outputs: bool = False) -> Union[torch.FloatTensor, Tuple[torch.FloatTensor, None]]:\n",
        "        labels = inputs[\"labels\"] if \"labels\" in inputs else inputs[\"label\"]\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        if self.label_smoother is not None:\n",
        "            raise NotImplementedError()  # objective-dependent label smoothing is custom\n",
        "            # loss = self.label_smoother(outputs, labels)\n",
        "        else:\n",
        "            loss = self.schedule.compute_loss(outputs, labels)\n",
        "\n",
        "        mock_outputs = torch.tensor([-1, -1])\n",
        "        return (loss, mock_outputs) if return_outputs else loss\n",
        "\n",
        "    def log(self, logs: List[Dict[str, float]]) -> None:\n",
        "        is_eval_log = any(self.eval_metrics_prefix in log_key for log_key in logs)\n",
        "        extended_logs = self.schedule.objectives_log(split=\"eval\" if is_eval_log else \"train\")\n",
        "        return super().log({**logs, **extended_logs})\n",
        "\n",
        "    def evaluate(self, *args, **kwargs) -> Dict[str, float]:\n",
        "        logger.warning(\"Evaluating...\")\n",
        "        out = super(Adapter, self).evaluate(*args, **kwargs)\n",
        "        if \"metric_key_prefix\" in kwargs:\n",
        "            self.eval_metrics_prefix = kwargs[\"metric_key_prefix\"]\n",
        "\n",
        "        # refresh exhausted evaluation iteration for possible next evaluation\n",
        "        self.eval_dataset = self.schedule.iterable_dataset(\"eval\")\n",
        "\n",
        "        return out\n",
        "\n",
        "    def save_model(self, output_dir: Optional[str] = None) -> None:\n",
        "        # HF native reload compatibility\n",
        "        objectives_counter = {str(obj): 0 for obj in self.schedule.objectives[\"train\"].values()}\n",
        "\n",
        "        for objective_id in self.schedule.objectives[\"train\"].keys():\n",
        "            module = self.model.trainable_models[str(objective_id)]\n",
        "            objective = self.schedule.objectives[\"train\"][int(objective_id)]\n",
        "            output_module_path = os.path.join(output_dir, str(objective))\n",
        "\n",
        "            # if the objective of this id was already persisted, we'll index the configs of the next ones\n",
        "            if objectives_counter[str(objective)] != 0:\n",
        "                output_module_path += \"_{}\".format(objectives_counter[str(objective)])\n",
        "                objectives_counter[str(objective)] += 1\n",
        "\n",
        "            # we persist a shared tokenizer and training args either way\n",
        "            self.model.tokenizer.save_pretrained(output_module_path)\n",
        "            torch.save(self.args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "\n",
        "            if hasattr(module, \"save_pretrained\") or hasattr(unwrap_model(module), \"save_pretrained\"):\n",
        "                # if the head module has \"save_pretrained\" method, it will be called for persistence\n",
        "                module.save_pretrained(output_module_path, use_diff=True)\n",
        "            else:\n",
        "                # otherwise, we persist only a raw pytorch module\n",
        "                torch.save(module.state_dict(), os.path.join(output_module_path, WEIGHTS_NAME))\n",
        "\n",
        "            logger.info(f\"Model of objective {str(objective)} saved in {output_module_path}\")"
      ],
      "metadata": {
        "id": "acEWC3de5e7a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Run the training using Adapter, similarly to running HF.Trainer, only adding `schedule`\n",
        "#from adaptor.adapter import Adapter\n",
        "from transformers.integrations import CometCallback\n",
        "\n",
        "adapter = Adapter(lang_module=lang_module, schedule=schedule, args=training_arguments, callbacks=[CometCallback()])\n",
        "adapter.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6A1mQYUs5hJr",
        "outputId": "c8ad14a4-b1b8-41a9-965e-acf35841cdfc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<transformers.integrations.CometCallback object at 0x7fec83268990>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are adding a <class 'transformers.integrations.CometCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "CometCallback\n",
            "TensorBoardCallback\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 115440\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
            "  Gradient Accumulation steps = 10\n",
            "  Total optimization steps = 100000\n",
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/katarinagresova/dnabert-for-clash/0767e30f0730478faa9fdb70d84e08ee\n",
            "\n",
            "Automatic Comet.ml online logging enabled\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/katarinagresova/dnabert-for-clash/0767e30f0730478faa9fdb70d84e08ee\n",
            "COMET INFO:   Others:\n",
            "COMET INFO:     Created from : transformers\n",
            "COMET INFO:     notebook_url : https://colab.research.google.com/notebook#fileId=1Ub2_xJWF6C1SGOiOxFk54HhH0EVcoq6J\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     args/_n_gpu                            : 1\n",
            "COMET INFO:     args/_no_sync_in_gradient_accumulation : True\n",
            "COMET INFO:     args/_setup_devices                    : cuda:0\n",
            "COMET INFO:     args/adafactor                         : False\n",
            "COMET INFO:     args/adam_beta1                        : 0.9\n",
            "COMET INFO:     args/adam_beta2                        : 0.999\n",
            "COMET INFO:     args/adam_epsilon                      : 1e-08\n",
            "COMET INFO:     args/bf16                              : False\n",
            "COMET INFO:     args/bf16_full_eval                    : False\n",
            "COMET INFO:     args/data_seed                         : None\n",
            "COMET INFO:     args/dataloader_drop_last              : False\n",
            "COMET INFO:     args/dataloader_num_workers            : 0\n",
            "COMET INFO:     args/dataloader_pin_memory             : False\n",
            "COMET INFO:     args/ddp_bucket_cap_mb                 : None\n",
            "COMET INFO:     args/ddp_find_unused_parameters        : None\n",
            "COMET INFO:     args/debug                             : []\n",
            "COMET INFO:     args/deepspeed                         : None\n",
            "COMET INFO:     args/device                            : cuda:0\n",
            "COMET INFO:     args/disable_tqdm                      : True\n",
            "COMET INFO:     args/do_eval                           : True\n",
            "COMET INFO:     args/do_predict                        : False\n",
            "COMET INFO:     args/do_train                          : True\n",
            "COMET INFO:     args/eval_accumulation_steps           : None\n",
            "COMET INFO:     args/eval_batch_size                   : 1\n",
            "COMET INFO:     args/eval_delay                        : 0\n",
            "COMET INFO:     args/eval_steps                        : 100\n",
            "COMET INFO:     args/evaluation_strategy               : IntervalStrategy.STEPS\n",
            "COMET INFO:     args/fixed_adaptation_args             : {'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 1, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'do_predict': False, 'disable_tqdm': True, 'dataloader_pin_memory': False}\n",
            "COMET INFO:     args/fp16                              : False\n",
            "COMET INFO:     args/fp16_backend                      : auto\n",
            "COMET INFO:     args/fp16_full_eval                    : False\n",
            "COMET INFO:     args/fp16_opt_level                    : O1\n",
            "COMET INFO:     args/gradient_accumulation_steps       : 10\n",
            "COMET INFO:     args/gradient_checkpointing            : False\n",
            "COMET INFO:     args/greater_is_better                 : None\n",
            "COMET INFO:     args/group_by_length                   : False\n",
            "COMET INFO:     args/half_precision_backend            : auto\n",
            "COMET INFO:     args/hub_model_id                      : None\n",
            "COMET INFO:     args/hub_strategy                      : HubStrategy.EVERY_SAVE\n",
            "COMET INFO:     args/hub_token                         : None\n",
            "COMET INFO:     args/ignore_data_skip                  : False\n",
            "COMET INFO:     args/label_names                       : None\n",
            "COMET INFO:     args/label_smoothing_factor            : 0.0\n",
            "COMET INFO:     args/learning_rate                     : 2e-05\n",
            "COMET INFO:     args/length_column_name                : length\n",
            "COMET INFO:     args/load_best_model_at_end            : False\n",
            "COMET INFO:     args/local_process_index               : 0\n",
            "COMET INFO:     args/local_rank                        : -1\n",
            "COMET INFO:     args/log_converged_objectives          : True\n",
            "COMET INFO:     args/log_level                         : -1\n",
            "COMET INFO:     args/log_level_replica                 : -1\n",
            "COMET INFO:     args/log_on_each_node                  : True\n",
            "COMET INFO:     args/logging_dir                       : dnabert_for_clash/runs/Apr11_13-59-15_f964ddb5e442\n",
            "COMET INFO:     args/logging_first_step                : False\n",
            "COMET INFO:     args/logging_nan_inf_filter            : True\n",
            "COMET INFO:     args/logging_steps                     : 100\n",
            "COMET INFO:     args/logging_strategy                  : IntervalStrategy.STEPS\n",
            "COMET INFO:     args/lr_scheduler_type                 : SchedulerType.LINEAR\n",
            "COMET INFO:     args/max_grad_norm                     : 1.0\n",
            "COMET INFO:     args/max_steps                         : 100000\n",
            "COMET INFO:     args/metric_for_best_model             : None\n",
            "COMET INFO:     args/mp_parameters                     : \n",
            "COMET INFO:     args/n_gpu                             : 1\n",
            "COMET INFO:     args/no_cuda                           : False\n",
            "COMET INFO:     args/num_train_epochs                  : 30\n",
            "COMET INFO:     args/optim                             : OptimizerNames.ADAMW_HF\n",
            "COMET INFO:     args/output_dir                        : dnabert_for_clash\n",
            "COMET INFO:     args/overwrite_output_dir              : False\n",
            "COMET INFO:     args/parallel_mode                     : ParallelMode.NOT_PARALLEL\n",
            "COMET INFO:     args/past_index                        : -1\n",
            "COMET INFO:     args/per_device_eval_batch_size        : 1\n",
            "COMET INFO:     args/per_device_train_batch_size       : 1\n",
            "COMET INFO:     args/per_gpu_eval_batch_size           : None\n",
            "COMET INFO:     args/per_gpu_train_batch_size          : None\n",
            "COMET INFO:     args/place_model_on_device             : True\n",
            "COMET INFO:     args/prediction_loss_only              : False\n",
            "COMET INFO:     args/process_index                     : 0\n",
            "COMET INFO:     args/push_to_hub                       : False\n",
            "COMET INFO:     args/push_to_hub_model_id              : None\n",
            "COMET INFO:     args/push_to_hub_organization          : None\n",
            "COMET INFO:     args/push_to_hub_token                 : None\n",
            "COMET INFO:     args/remove_unused_columns             : True\n",
            "COMET INFO:     args/report_to                         : ['comet_ml', 'tensorboard']\n",
            "COMET INFO:     args/resume_from_checkpoint            : None\n",
            "COMET INFO:     args/run_name                          : dnabert_for_clash\n",
            "COMET INFO:     args/save_on_each_node                 : False\n",
            "COMET INFO:     args/save_steps                        : 100\n",
            "COMET INFO:     args/save_strategy                     : IntervalStrategy.STEPS\n",
            "COMET INFO:     args/save_total_limit                  : None\n",
            "COMET INFO:     args/seed                              : 42\n",
            "COMET INFO:     args/sharded_ddp                       : []\n",
            "COMET INFO:     args/should_log                        : True\n",
            "COMET INFO:     args/should_save                       : True\n",
            "COMET INFO:     args/skip_memory_metrics               : True\n",
            "COMET INFO:     args/stopping_patience                 : 10\n",
            "COMET INFO:     args/stopping_strategy                 : StoppingStrategy.ALL_OBJECTIVES_CONVERGED\n",
            "COMET INFO:     args/tf32                              : None\n",
            "COMET INFO:     args/tpu_metrics_debug                 : False\n",
            "COMET INFO:     args/tpu_num_cores                     : None\n",
            "COMET INFO:     args/train_batch_size                  : 1\n",
            "COMET INFO:     args/use_legacy_prediction_loop        : False\n",
            "COMET INFO:     args/warmup_ratio                      : 0.0\n",
            "COMET INFO:     args/warmup_steps                      : 10000\n",
            "COMET INFO:     args/weight_decay                      : 0.0\n",
            "COMET INFO:     args/world_size                        : 1\n",
            "COMET INFO:     args/xpu_backend                       : None\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     git metadata        : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     model graph         : 1\n",
            "COMET INFO:     notebook            : 2\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO:     source_code         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/katarinagresova/dnabert-for-clash/96c3317415b24d7a8f218d25164d66ea\n",
            "\n",
            "Automatic Comet.ml online logging enabled\n",
            "Converged objectives: []\n",
            "MaskedLanguageModeling:   0%|          | 1/1924 [00:00<07:14,  4.42batches/s, epoch=1, loss=0.148, split=train]Converged objectives: []\n",
            "\n",
            "SequenceClassification:   0%|          | 0/1924 [00:00<?, ?batches/s]\u001b[A\n",
            "MaskedLanguageModeling:   0%|          | 2/1924 [00:01<19:44,  1.62batches/s, epoch=1, loss=0.308, split=train]\n",
            "MaskedLanguageModeling:   0%|          | 3/1924 [00:01<23:14,  1.38batches/s, epoch=1, loss=0.397, split=train]\n",
            "MaskedLanguageModeling:   0%|          | 4/1924 [00:02<23:59,  1.33batches/s, epoch=1, loss=0.103, split=train]\n",
            "MaskedLanguageModeling:   0%|          | 5/1924 [00:03<24:23,  1.31batches/s, epoch=1, loss=0.206, split=train]\n",
            "MaskedLanguageModeling:   0%|          | 6/1924 [00:04<25:19,  1.26batches/s, epoch=1, loss=0.278, split=train]\n",
            "MaskedLanguageModeling:   0%|          | 7/1924 [00:05<25:06,  1.27batches/s, epoch=1, loss=0.292, split=train]\n",
            "MaskedLanguageModeling:   0%|          | 8/1924 [00:05<25:04,  1.27batches/s, epoch=1, loss=0.178, split=train]\n",
            "MaskedLanguageModeling:   0%|          | 9/1924 [00:06<25:04,  1.27batches/s, epoch=1, loss=0.133, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 10/1924 [00:07<24:58,  1.28batches/s, epoch=1, loss=0.202, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 11/1924 [00:08<25:40,  1.24batches/s, epoch=1, loss=0.205, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 12/1924 [00:09<25:26,  1.25batches/s, epoch=1, loss=0.379, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 13/1924 [00:09<25:19,  1.26batches/s, epoch=1, loss=0.0625, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 14/1924 [00:10<25:12,  1.26batches/s, epoch=1, loss=0.201, split=train] \n",
            "MaskedLanguageModeling:   1%|          | 15/1924 [00:11<25:09,  1.26batches/s, epoch=1, loss=0.0391, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 16/1924 [00:12<25:40,  1.24batches/s, epoch=1, loss=0.266, split=train] \n",
            "MaskedLanguageModeling:   1%|          | 17/1924 [00:13<25:28,  1.25batches/s, epoch=1, loss=0.049, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 18/1924 [00:13<25:24,  1.25batches/s, epoch=1, loss=0.508, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 19/1924 [00:14<25:24,  1.25batches/s, epoch=1, loss=0.18, split=train] \n",
            "MaskedLanguageModeling:   1%|          | 20/1924 [00:15<25:17,  1.25batches/s, epoch=1, loss=0.234, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 21/1924 [00:16<25:47,  1.23batches/s, epoch=1, loss=0.438, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 22/1924 [00:17<25:33,  1.24batches/s, epoch=1, loss=0.326, split=train]\n",
            "MaskedLanguageModeling:   1%|          | 23/1924 [00:17<25:21,  1.25batches/s, epoch=1, loss=0.38, split=train] \n",
            "MaskedLanguageModeling:   1%|          | 24/1924 [00:18<25:15,  1.25batches/s, epoch=1, loss=0.12, split=train]\n",
            "MaskedLanguageModeling:   1%|▏         | 25/1924 [00:19<25:14,  1.25batches/s, epoch=1, loss=0.0871, split=train]\n",
            "MaskedLanguageModeling:   1%|▏         | 26/1924 [00:20<25:46,  1.23batches/s, epoch=1, loss=0.252, split=train] \n",
            "MaskedLanguageModeling:   1%|▏         | 27/1924 [00:21<25:32,  1.24batches/s, epoch=1, loss=0.37, split=train] \n",
            "MaskedLanguageModeling:   1%|▏         | 28/1924 [00:21<25:25,  1.24batches/s, epoch=1, loss=0.125, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 29/1924 [00:22<25:12,  1.25batches/s, epoch=1, loss=0.188, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 30/1924 [00:23<25:08,  1.26batches/s, epoch=1, loss=0.271, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 31/1924 [00:24<25:37,  1.23batches/s, epoch=1, loss=0.0736, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 32/1924 [00:25<25:20,  1.24batches/s, epoch=1, loss=0.22, split=train]  \n",
            "MaskedLanguageModeling:   2%|▏         | 33/1924 [00:25<25:14,  1.25batches/s, epoch=1, loss=0.164, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 34/1924 [00:26<25:06,  1.25batches/s, epoch=1, loss=0.123, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 35/1924 [00:27<25:06,  1.25batches/s, epoch=1, loss=0.116, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 36/1924 [00:28<25:37,  1.23batches/s, epoch=1, loss=0.393, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 37/1924 [00:29<25:26,  1.24batches/s, epoch=1, loss=0.407, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 38/1924 [00:30<25:20,  1.24batches/s, epoch=1, loss=0.336, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 39/1924 [00:30<25:11,  1.25batches/s, epoch=1, loss=0.299, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 40/1924 [00:31<25:04,  1.25batches/s, epoch=1, loss=0.324, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 41/1924 [00:32<25:33,  1.23batches/s, epoch=1, loss=0.275, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 42/1924 [00:33<25:18,  1.24batches/s, epoch=1, loss=0.191, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 43/1924 [00:34<25:13,  1.24batches/s, epoch=1, loss=0.285, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 44/1924 [00:34<25:02,  1.25batches/s, epoch=1, loss=0.362, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 45/1924 [00:35<25:01,  1.25batches/s, epoch=1, loss=0.191, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 46/1924 [00:36<25:24,  1.23batches/s, epoch=1, loss=0.235, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 47/1924 [00:37<25:13,  1.24batches/s, epoch=1, loss=0.238, split=train]\n",
            "MaskedLanguageModeling:   2%|▏         | 48/1924 [00:38<25:06,  1.25batches/s, epoch=1, loss=0.214, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 49/1924 [00:38<25:02,  1.25batches/s, epoch=1, loss=0.248, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 50/1924 [00:39<24:58,  1.25batches/s, epoch=1, loss=0.17, split=train] \n",
            "MaskedLanguageModeling:   3%|▎         | 51/1924 [00:40<25:25,  1.23batches/s, epoch=1, loss=0.19, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 52/1924 [00:41<25:14,  1.24batches/s, epoch=1, loss=0.172, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 53/1924 [00:42<25:09,  1.24batches/s, epoch=1, loss=0.207, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 54/1924 [00:42<24:59,  1.25batches/s, epoch=1, loss=0.262, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 55/1924 [00:43<24:57,  1.25batches/s, epoch=1, loss=0.187, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 56/1924 [00:44<25:26,  1.22batches/s, epoch=1, loss=0.337, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 57/1924 [00:45<25:14,  1.23batches/s, epoch=1, loss=0.532, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 58/1924 [00:46<25:09,  1.24batches/s, epoch=1, loss=0.178, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 59/1924 [00:46<24:56,  1.25batches/s, epoch=1, loss=0.0905, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 60/1924 [00:47<24:46,  1.25batches/s, epoch=1, loss=0.263, split=train] \n",
            "MaskedLanguageModeling:   3%|▎         | 61/1924 [00:48<25:14,  1.23batches/s, epoch=1, loss=0.122, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 62/1924 [00:49<25:06,  1.24batches/s, epoch=1, loss=0.259, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 63/1924 [00:50<24:58,  1.24batches/s, epoch=1, loss=0.212, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 64/1924 [00:50<24:57,  1.24batches/s, epoch=1, loss=0.154, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 65/1924 [00:51<24:51,  1.25batches/s, epoch=1, loss=0.125, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 66/1924 [00:52<25:21,  1.22batches/s, epoch=1, loss=0.149, split=train]\n",
            "MaskedLanguageModeling:   3%|▎         | 67/1924 [00:53<25:06,  1.23batches/s, epoch=1, loss=0.326, split=train]\n",
            "MaskedLanguageModeling:   4%|▎         | 68/1924 [00:54<25:00,  1.24batches/s, epoch=1, loss=0.257, split=train]\n",
            "MaskedLanguageModeling:   4%|▎         | 69/1924 [00:55<24:58,  1.24batches/s, epoch=1, loss=0.24, split=train] \n",
            "MaskedLanguageModeling:   4%|▎         | 70/1924 [00:55<24:53,  1.24batches/s, epoch=1, loss=0.224, split=train]\n",
            "MaskedLanguageModeling:   4%|▎         | 71/1924 [00:56<25:22,  1.22batches/s, epoch=1, loss=0.243, split=train]\n",
            "MaskedLanguageModeling:   4%|▎         | 72/1924 [00:57<25:01,  1.23batches/s, epoch=1, loss=0.18, split=train] \n",
            "MaskedLanguageModeling:   4%|▍         | 73/1924 [00:58<25:19,  1.22batches/s, epoch=1, loss=0.147, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 74/1924 [00:59<25:16,  1.22batches/s, epoch=1, loss=0.11, split=train] \n",
            "MaskedLanguageModeling:   4%|▍         | 75/1924 [00:59<25:14,  1.22batches/s, epoch=1, loss=0.188, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 76/1924 [01:00<25:37,  1.20batches/s, epoch=1, loss=0.232, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 77/1924 [01:01<25:17,  1.22batches/s, epoch=1, loss=0.16, split=train] \n",
            "MaskedLanguageModeling:   4%|▍         | 78/1924 [01:02<25:10,  1.22batches/s, epoch=1, loss=0.123, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 79/1924 [01:03<24:57,  1.23batches/s, epoch=1, loss=0.16, split=train] \n",
            "MaskedLanguageModeling:   4%|▍         | 80/1924 [01:04<24:51,  1.24batches/s, epoch=1, loss=0.138, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 81/1924 [01:04<25:18,  1.21batches/s, epoch=1, loss=0.184, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 82/1924 [01:05<25:03,  1.23batches/s, epoch=1, loss=0.22, split=train] \n",
            "MaskedLanguageModeling:   4%|▍         | 83/1924 [01:06<24:53,  1.23batches/s, epoch=1, loss=0.271, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 84/1924 [01:07<24:46,  1.24batches/s, epoch=1, loss=0.261, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 85/1924 [01:08<24:45,  1.24batches/s, epoch=1, loss=0.251, split=train]\n",
            "MaskedLanguageModeling:   4%|▍         | 86/1924 [01:08<25:11,  1.22batches/s, epoch=1, loss=0.295, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 87/1924 [01:09<24:58,  1.23batches/s, epoch=1, loss=0.374, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 88/1924 [01:10<24:49,  1.23batches/s, epoch=1, loss=0.366, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 89/1924 [01:11<24:48,  1.23batches/s, epoch=1, loss=0.144, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 90/1924 [01:12<24:42,  1.24batches/s, epoch=1, loss=0.318, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 91/1924 [01:13<25:06,  1.22batches/s, epoch=1, loss=0.28, split=train] \n",
            "MaskedLanguageModeling:   5%|▍         | 92/1924 [01:13<24:52,  1.23batches/s, epoch=1, loss=0.21, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 93/1924 [01:14<24:44,  1.23batches/s, epoch=1, loss=0.398, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 94/1924 [01:15<24:40,  1.24batches/s, epoch=1, loss=0.317, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 95/1924 [01:16<24:31,  1.24batches/s, epoch=1, loss=0.125, split=train]\n",
            "MaskedLanguageModeling:   5%|▍         | 96/1924 [01:17<25:02,  1.22batches/s, epoch=1, loss=0.295, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 97/1924 [01:17<24:52,  1.22batches/s, epoch=1, loss=0.291, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 98/1924 [01:18<24:42,  1.23batches/s, epoch=1, loss=0.243, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 99/1924 [01:19<24:35,  1.24batches/s, epoch=1, loss=0.179, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 100/1924 [01:20<24:31,  1.24batches/s, epoch=1, loss=0.21, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 101/1924 [01:21<25:00,  1.21batches/s, epoch=1, loss=0.187, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 102/1924 [01:21<24:49,  1.22batches/s, epoch=1, loss=0.371, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 103/1924 [01:22<24:43,  1.23batches/s, epoch=1, loss=0.141, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 104/1924 [01:23<24:40,  1.23batches/s, epoch=1, loss=0.268, split=train]\n",
            "MaskedLanguageModeling:   5%|▌         | 105/1924 [01:24<24:34,  1.23batches/s, epoch=1, loss=0.173, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 106/1924 [01:25<24:58,  1.21batches/s, epoch=1, loss=0.248, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 107/1924 [01:26<24:43,  1.22batches/s, epoch=1, loss=0.295, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 108/1924 [01:26<24:32,  1.23batches/s, epoch=1, loss=0.319, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 109/1924 [01:27<24:30,  1.23batches/s, epoch=1, loss=0.303, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 110/1924 [01:28<24:28,  1.24batches/s, epoch=1, loss=0.218, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 111/1924 [01:29<24:51,  1.22batches/s, epoch=1, loss=0.206, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 112/1924 [01:30<24:38,  1.23batches/s, epoch=1, loss=0.0785, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 113/1924 [01:30<24:30,  1.23batches/s, epoch=1, loss=0.117, split=train] \n",
            "MaskedLanguageModeling:   6%|▌         | 114/1924 [01:31<24:25,  1.24batches/s, epoch=1, loss=0.183, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 115/1924 [01:32<24:18,  1.24batches/s, epoch=1, loss=0.0667, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 116/1924 [01:33<24:46,  1.22batches/s, epoch=1, loss=0.321, split=train] \n",
            "MaskedLanguageModeling:   6%|▌         | 117/1924 [01:34<24:38,  1.22batches/s, epoch=1, loss=0.206, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 118/1924 [01:34<24:30,  1.23batches/s, epoch=1, loss=0.267, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 119/1924 [01:35<24:26,  1.23batches/s, epoch=1, loss=0.171, split=train]\n",
            "MaskedLanguageModeling:   6%|▌         | 120/1924 [01:36<24:22,  1.23batches/s, epoch=1, loss=0.319, split=train]\n",
            "MaskedLanguageModeling:   6%|▋         | 121/1924 [01:37<24:48,  1.21batches/s, epoch=1, loss=0.355, split=train]\n",
            "MaskedLanguageModeling:   6%|▋         | 122/1924 [01:38<24:36,  1.22batches/s, epoch=1, loss=0.125, split=train]\n",
            "MaskedLanguageModeling:   6%|▋         | 123/1924 [01:39<24:28,  1.23batches/s, epoch=1, loss=0.257, split=train]\n",
            "MaskedLanguageModeling:   6%|▋         | 124/1924 [01:39<24:24,  1.23batches/s, epoch=1, loss=0.105, split=train]\n",
            "MaskedLanguageModeling:   6%|▋         | 125/1924 [01:40<24:20,  1.23batches/s, epoch=1, loss=0.331, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 126/1924 [01:41<24:44,  1.21batches/s, epoch=1, loss=0.157, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 127/1924 [01:42<24:31,  1.22batches/s, epoch=1, loss=0.41, split=train] \n",
            "MaskedLanguageModeling:   7%|▋         | 128/1924 [01:43<24:27,  1.22batches/s, epoch=1, loss=0.294, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 129/1924 [01:43<24:19,  1.23batches/s, epoch=1, loss=0.07, split=train] \n",
            "MaskedLanguageModeling:   7%|▋         | 130/1924 [01:44<24:10,  1.24batches/s, epoch=1, loss=0.199, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 131/1924 [01:45<24:34,  1.22batches/s, epoch=1, loss=0.222, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 132/1924 [01:46<24:24,  1.22batches/s, epoch=1, loss=0.202, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 133/1924 [01:47<24:17,  1.23batches/s, epoch=1, loss=0.215, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 134/1924 [01:48<24:10,  1.23batches/s, epoch=1, loss=0.149, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 135/1924 [01:48<24:04,  1.24batches/s, epoch=1, loss=0.214, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 136/1924 [01:49<24:29,  1.22batches/s, epoch=1, loss=0.245, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 137/1924 [01:50<24:16,  1.23batches/s, epoch=1, loss=0.202, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 138/1924 [01:51<24:07,  1.23batches/s, epoch=1, loss=0.262, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 139/1924 [01:52<24:03,  1.24batches/s, epoch=1, loss=0.184, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 140/1924 [01:52<24:01,  1.24batches/s, epoch=1, loss=0.305, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 141/1924 [01:53<24:24,  1.22batches/s, epoch=1, loss=0.194, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 142/1924 [01:54<24:13,  1.23batches/s, epoch=1, loss=0.126, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 143/1924 [01:55<24:07,  1.23batches/s, epoch=1, loss=0.163, split=train]\n",
            "MaskedLanguageModeling:   7%|▋         | 144/1924 [01:56<23:59,  1.24batches/s, epoch=1, loss=0.163, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 145/1924 [01:56<23:56,  1.24batches/s, epoch=1, loss=0.233, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 146/1924 [01:57<24:22,  1.22batches/s, epoch=1, loss=0.307, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 147/1924 [01:58<24:12,  1.22batches/s, epoch=1, loss=0.15, split=train] \n",
            "MaskedLanguageModeling:   8%|▊         | 148/1924 [01:59<24:04,  1.23batches/s, epoch=1, loss=0.268, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 149/1924 [02:00<23:56,  1.24batches/s, epoch=1, loss=0.0563, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 150/1924 [02:01<23:52,  1.24batches/s, epoch=1, loss=0.239, split=train] \n",
            "MaskedLanguageModeling:   8%|▊         | 151/1924 [02:01<24:18,  1.22batches/s, epoch=1, loss=0.176, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 152/1924 [02:02<24:08,  1.22batches/s, epoch=1, loss=0.0751, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 153/1924 [02:03<24:03,  1.23batches/s, epoch=1, loss=0.105, split=train] \n",
            "MaskedLanguageModeling:   8%|▊         | 154/1924 [02:04<24:01,  1.23batches/s, epoch=1, loss=0.217, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 155/1924 [02:05<24:00,  1.23batches/s, epoch=1, loss=0.172, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 156/1924 [02:05<24:23,  1.21batches/s, epoch=1, loss=0.235, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 157/1924 [02:06<24:08,  1.22batches/s, epoch=1, loss=0.234, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 158/1924 [02:07<23:58,  1.23batches/s, epoch=1, loss=0.294, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 159/1924 [02:08<23:52,  1.23batches/s, epoch=1, loss=0.457, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 160/1924 [02:09<23:49,  1.23batches/s, epoch=1, loss=0.145, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 161/1924 [02:10<24:10,  1.22batches/s, epoch=1, loss=0.263, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 162/1924 [02:10<24:00,  1.22batches/s, epoch=1, loss=0.104, split=train]\n",
            "MaskedLanguageModeling:   8%|▊         | 163/1924 [02:11<23:57,  1.22batches/s, epoch=1, loss=0.247, split=train]\n",
            "MaskedLanguageModeling:   9%|▊         | 164/1924 [02:12<23:52,  1.23batches/s, epoch=1, loss=0.178, split=train]\n",
            "MaskedLanguageModeling:   9%|▊         | 165/1924 [02:13<23:46,  1.23batches/s, epoch=1, loss=0.0715, split=train]\n",
            "MaskedLanguageModeling:   9%|▊         | 166/1924 [02:14<24:14,  1.21batches/s, epoch=1, loss=0.0857, split=train]\n",
            "MaskedLanguageModeling:   9%|▊         | 167/1924 [02:14<23:56,  1.22batches/s, epoch=1, loss=0.26, split=train]  \n",
            "MaskedLanguageModeling:   9%|▊         | 168/1924 [02:15<23:52,  1.23batches/s, epoch=1, loss=0.229, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 169/1924 [02:16<23:43,  1.23batches/s, epoch=1, loss=0.128, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 170/1924 [02:17<23:38,  1.24batches/s, epoch=1, loss=0.0881, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 171/1924 [02:18<24:09,  1.21batches/s, epoch=1, loss=0.309, split=train] \n",
            "MaskedLanguageModeling:   9%|▉         | 172/1924 [02:19<23:57,  1.22batches/s, epoch=1, loss=0.192, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 173/1924 [02:19<23:44,  1.23batches/s, epoch=1, loss=0.0956, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 174/1924 [02:20<23:38,  1.23batches/s, epoch=1, loss=0.504, split=train] \n",
            "MaskedLanguageModeling:   9%|▉         | 175/1924 [02:21<23:38,  1.23batches/s, epoch=1, loss=0.12, split=train] \n",
            "MaskedLanguageModeling:   9%|▉         | 176/1924 [02:22<23:59,  1.21batches/s, epoch=1, loss=0.0901, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 177/1924 [02:23<23:46,  1.22batches/s, epoch=1, loss=0.315, split=train] \n",
            "MaskedLanguageModeling:   9%|▉         | 178/1924 [02:23<23:38,  1.23batches/s, epoch=1, loss=0.152, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 179/1924 [02:24<23:32,  1.24batches/s, epoch=1, loss=0.34, split=train] \n",
            "MaskedLanguageModeling:   9%|▉         | 180/1924 [02:25<23:27,  1.24batches/s, epoch=1, loss=0.228, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 181/1924 [02:26<23:53,  1.22batches/s, epoch=1, loss=0.247, split=train]\n",
            "MaskedLanguageModeling:   9%|▉         | 182/1924 [02:27<23:42,  1.22batches/s, epoch=1, loss=0.172, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 183/1924 [02:27<23:41,  1.22batches/s, epoch=1, loss=0.0777, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 184/1924 [02:28<23:39,  1.23batches/s, epoch=1, loss=0.232, split=train] \n",
            "MaskedLanguageModeling:  10%|▉         | 185/1924 [02:29<23:35,  1.23batches/s, epoch=1, loss=0.221, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 186/1924 [02:30<24:07,  1.20batches/s, epoch=1, loss=0.282, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 187/1924 [02:31<23:45,  1.22batches/s, epoch=1, loss=0.299, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 188/1924 [02:32<23:33,  1.23batches/s, epoch=1, loss=0.184, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 189/1924 [02:32<23:30,  1.23batches/s, epoch=1, loss=0.541, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 190/1924 [02:33<23:27,  1.23batches/s, epoch=1, loss=0.233, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 191/1924 [02:34<23:55,  1.21batches/s, epoch=1, loss=0.219, split=train]\n",
            "MaskedLanguageModeling:  10%|▉         | 192/1924 [02:35<23:39,  1.22batches/s, epoch=1, loss=0.251, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 193/1924 [02:36<23:33,  1.22batches/s, epoch=1, loss=0.173, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 194/1924 [02:36<23:31,  1.23batches/s, epoch=1, loss=0.143, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 195/1924 [02:37<23:18,  1.24batches/s, epoch=1, loss=0.22, split=train] \n",
            "MaskedLanguageModeling:  10%|█         | 196/1924 [02:38<23:44,  1.21batches/s, epoch=1, loss=0.442, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 197/1924 [02:39<23:34,  1.22batches/s, epoch=1, loss=0.167, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 198/1924 [02:40<23:26,  1.23batches/s, epoch=1, loss=0.159, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 199/1924 [02:41<23:21,  1.23batches/s, epoch=1, loss=0.241, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 200/1924 [02:41<23:17,  1.23batches/s, epoch=1, loss=0.201, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 201/1924 [02:42<23:44,  1.21batches/s, epoch=1, loss=0.194, split=train]\n",
            "MaskedLanguageModeling:  10%|█         | 202/1924 [02:43<23:31,  1.22batches/s, epoch=1, loss=0.304, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 203/1924 [02:44<23:23,  1.23batches/s, epoch=1, loss=0.186, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 204/1924 [02:45<23:16,  1.23batches/s, epoch=1, loss=0.209, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 205/1924 [02:45<23:09,  1.24batches/s, epoch=1, loss=0.173, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 206/1924 [02:46<23:40,  1.21batches/s, epoch=1, loss=0.358, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 207/1924 [02:47<23:22,  1.22batches/s, epoch=1, loss=0.188, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 208/1924 [02:48<23:15,  1.23batches/s, epoch=1, loss=0.0704, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 209/1924 [02:49<23:18,  1.23batches/s, epoch=1, loss=0.449, split=train] \n",
            "MaskedLanguageModeling:  11%|█         | 210/1924 [02:50<23:14,  1.23batches/s, epoch=1, loss=0.418, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 211/1924 [02:50<23:37,  1.21batches/s, epoch=1, loss=0.549, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 212/1924 [02:51<23:25,  1.22batches/s, epoch=1, loss=0.166, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 213/1924 [02:52<23:14,  1.23batches/s, epoch=1, loss=0.137, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 214/1924 [02:53<23:10,  1.23batches/s, epoch=1, loss=0.167, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 215/1924 [02:54<23:03,  1.24batches/s, epoch=1, loss=0.286, split=train]\n",
            "MaskedLanguageModeling:  11%|█         | 216/1924 [02:54<23:37,  1.20batches/s, epoch=1, loss=0.285, split=train]\n",
            "MaskedLanguageModeling:  11%|█▏        | 217/1924 [02:55<23:22,  1.22batches/s, epoch=1, loss=0.271, split=train]\n",
            "MaskedLanguageModeling:  11%|█▏        | 218/1924 [02:56<23:16,  1.22batches/s, epoch=1, loss=0.228, split=train]\n",
            "MaskedLanguageModeling:  11%|█▏        | 219/1924 [02:57<23:08,  1.23batches/s, epoch=1, loss=0.0974, split=train]\n",
            "MaskedLanguageModeling:  11%|█▏        | 220/1924 [02:58<23:03,  1.23batches/s, epoch=1, loss=0.214, split=train] \n",
            "MaskedLanguageModeling:  11%|█▏        | 221/1924 [02:59<23:26,  1.21batches/s, epoch=1, loss=0.14, split=train] \n",
            "MaskedLanguageModeling:  12%|█▏        | 222/1924 [02:59<23:15,  1.22batches/s, epoch=1, loss=0.173, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 223/1924 [03:00<23:07,  1.23batches/s, epoch=1, loss=0.19, split=train] \n",
            "MaskedLanguageModeling:  12%|█▏        | 224/1924 [03:01<23:03,  1.23batches/s, epoch=1, loss=0.0965, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 225/1924 [03:02<23:00,  1.23batches/s, epoch=1, loss=0.44, split=train]  \n",
            "MaskedLanguageModeling:  12%|█▏        | 226/1924 [03:03<23:20,  1.21batches/s, epoch=1, loss=0.153, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 227/1924 [03:03<23:07,  1.22batches/s, epoch=1, loss=0.199, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 228/1924 [03:04<22:59,  1.23batches/s, epoch=1, loss=0.161, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 229/1924 [03:05<22:52,  1.23batches/s, epoch=1, loss=0.178, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 230/1924 [03:06<22:47,  1.24batches/s, epoch=1, loss=0.141, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 231/1924 [03:07<23:16,  1.21batches/s, epoch=1, loss=0.119, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 232/1924 [03:08<23:03,  1.22batches/s, epoch=1, loss=0.277, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 233/1924 [03:08<22:59,  1.23batches/s, epoch=1, loss=0.208, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 234/1924 [03:09<22:55,  1.23batches/s, epoch=1, loss=0.0521, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 235/1924 [03:10<22:52,  1.23batches/s, epoch=1, loss=0.121, split=train] \n",
            "MaskedLanguageModeling:  12%|█▏        | 236/1924 [03:11<23:16,  1.21batches/s, epoch=1, loss=0.151, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 237/1924 [03:12<23:04,  1.22batches/s, epoch=1, loss=0.0947, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 238/1924 [03:12<22:54,  1.23batches/s, epoch=1, loss=0.267, split=train] \n",
            "MaskedLanguageModeling:  12%|█▏        | 239/1924 [03:13<22:52,  1.23batches/s, epoch=1, loss=0.116, split=train]\n",
            "MaskedLanguageModeling:  12%|█▏        | 240/1924 [03:14<22:48,  1.23batches/s, epoch=1, loss=0.181, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 241/1924 [03:15<23:11,  1.21batches/s, epoch=1, loss=0.526, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 242/1924 [03:16<22:57,  1.22batches/s, epoch=1, loss=0.0926, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 243/1924 [03:17<22:48,  1.23batches/s, epoch=1, loss=0.212, split=train] \n",
            "MaskedLanguageModeling:  13%|█▎        | 244/1924 [03:17<22:42,  1.23batches/s, epoch=1, loss=0.128, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 245/1924 [03:18<22:36,  1.24batches/s, epoch=1, loss=0.285, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 246/1924 [03:19<23:01,  1.21batches/s, epoch=1, loss=0.227, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 247/1924 [03:20<22:53,  1.22batches/s, epoch=1, loss=0.192, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 248/1924 [03:21<22:47,  1.23batches/s, epoch=1, loss=0.207, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 249/1924 [03:21<22:45,  1.23batches/s, epoch=1, loss=0.266, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 250/1924 [03:22<22:43,  1.23batches/s, epoch=1, loss=0.0969, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 251/1924 [03:23<23:08,  1.21batches/s, epoch=1, loss=0.34, split=train]  \n",
            "MaskedLanguageModeling:  13%|█▎        | 252/1924 [03:24<22:51,  1.22batches/s, epoch=1, loss=0.35, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 253/1924 [03:25<22:43,  1.23batches/s, epoch=1, loss=0.0306, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 254/1924 [03:25<22:37,  1.23batches/s, epoch=1, loss=0.309, split=train] \n",
            "MaskedLanguageModeling:  13%|█▎        | 255/1924 [03:26<22:34,  1.23batches/s, epoch=1, loss=0.514, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 256/1924 [03:27<22:57,  1.21batches/s, epoch=1, loss=0.162, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 257/1924 [03:28<22:46,  1.22batches/s, epoch=1, loss=0.163, split=train]\n",
            "MaskedLanguageModeling:  13%|█▎        | 258/1924 [03:29<22:34,  1.23batches/s, epoch=1, loss=0.11, split=train] \n",
            "MaskedLanguageModeling:  13%|█▎        | 259/1924 [03:30<22:27,  1.24batches/s, epoch=1, loss=0.192, split=train]\n",
            "MaskedLanguageModeling:  14%|█▎        | 260/1924 [03:30<22:22,  1.24batches/s, epoch=1, loss=0.303, split=train]\n",
            "MaskedLanguageModeling:  14%|█▎        | 261/1924 [03:31<22:48,  1.22batches/s, epoch=1, loss=0.407, split=train]\n",
            "MaskedLanguageModeling:  14%|█▎        | 262/1924 [03:32<22:40,  1.22batches/s, epoch=1, loss=0.418, split=train]\n",
            "MaskedLanguageModeling:  14%|█▎        | 263/1924 [03:33<22:34,  1.23batches/s, epoch=1, loss=0.174, split=train]\n",
            "MaskedLanguageModeling:  14%|█▎        | 264/1924 [03:34<22:29,  1.23batches/s, epoch=1, loss=0.138, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 265/1924 [03:34<22:25,  1.23batches/s, epoch=1, loss=0.104, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 266/1924 [03:35<22:48,  1.21batches/s, epoch=1, loss=0.372, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 267/1924 [03:36<22:36,  1.22batches/s, epoch=1, loss=0.153, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 268/1924 [03:37<22:26,  1.23batches/s, epoch=1, loss=0.282, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 269/1924 [03:38<22:24,  1.23batches/s, epoch=1, loss=0.0296, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 270/1924 [03:39<22:21,  1.23batches/s, epoch=1, loss=0.698, split=train] \n",
            "MaskedLanguageModeling:  14%|█▍        | 271/1924 [03:39<22:43,  1.21batches/s, epoch=1, loss=0.343, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 272/1924 [03:40<22:32,  1.22batches/s, epoch=1, loss=0.2, split=train]  \n",
            "MaskedLanguageModeling:  14%|█▍        | 273/1924 [03:41<22:28,  1.22batches/s, epoch=1, loss=0.349, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 274/1924 [03:42<22:23,  1.23batches/s, epoch=1, loss=0.175, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 275/1924 [03:43<22:15,  1.23batches/s, epoch=1, loss=0.318, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 276/1924 [03:43<22:45,  1.21batches/s, epoch=1, loss=0.0371, split=train]\n",
            "MaskedLanguageModeling:  14%|█▍        | 277/1924 [03:44<22:35,  1.21batches/s, epoch=1, loss=0.283, split=train] \n",
            "MaskedLanguageModeling:  14%|█▍        | 278/1924 [03:45<22:25,  1.22batches/s, epoch=1, loss=0.0729, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 279/1924 [03:46<22:17,  1.23batches/s, epoch=1, loss=0.228, split=train] \n",
            "MaskedLanguageModeling:  15%|█▍        | 280/1924 [03:47<22:15,  1.23batches/s, epoch=1, loss=0.0402, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 281/1924 [03:48<22:37,  1.21batches/s, epoch=1, loss=0.348, split=train] \n",
            "MaskedLanguageModeling:  15%|█▍        | 282/1924 [03:48<22:26,  1.22batches/s, epoch=1, loss=0.213, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 283/1924 [03:49<22:19,  1.23batches/s, epoch=1, loss=0.214, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 284/1924 [03:50<22:14,  1.23batches/s, epoch=1, loss=0.247, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 285/1924 [03:51<22:09,  1.23batches/s, epoch=1, loss=0.159, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 286/1924 [03:52<22:29,  1.21batches/s, epoch=1, loss=0.335, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 287/1924 [03:52<22:16,  1.23batches/s, epoch=1, loss=0.405, split=train]\n",
            "MaskedLanguageModeling:  15%|█▍        | 288/1924 [03:53<22:09,  1.23batches/s, epoch=1, loss=0.411, split=train]\n",
            "MaskedLanguageModeling:  15%|█▌        | 289/1924 [03:54<22:05,  1.23batches/s, epoch=1, loss=0.167, split=train]\n",
            "MaskedLanguageModeling:  15%|█▌        | 290/1924 [03:55<22:03,  1.23batches/s, epoch=1, loss=0.112, split=train]\n",
            "MaskedLanguageModeling:  15%|█▌        | 291/1924 [03:56<22:29,  1.21batches/s, epoch=1, loss=0.474, split=train]\n",
            "MaskedLanguageModeling:  15%|█▌        | 292/1924 [03:57<22:16,  1.22batches/s, epoch=1, loss=0.0646, split=train]\n",
            "MaskedLanguageModeling:  15%|█▌        | 293/1924 [03:57<22:09,  1.23batches/s, epoch=1, loss=0.0848, split=train]\n",
            "MaskedLanguageModeling:  15%|█▌        | 294/1924 [03:58<22:04,  1.23batches/s, epoch=1, loss=0.355, split=train] \n",
            "MaskedLanguageModeling:  15%|█▌        | 295/1924 [03:59<22:03,  1.23batches/s, epoch=1, loss=0.18, split=train] \n",
            "MaskedLanguageModeling:  15%|█▌        | 296/1924 [04:00<22:29,  1.21batches/s, epoch=1, loss=0.0902, split=train]\n",
            "MaskedLanguageModeling:  15%|█▌        | 297/1924 [04:01<22:16,  1.22batches/s, epoch=1, loss=0.162, split=train] \n",
            "MaskedLanguageModeling:  15%|█▌        | 298/1924 [04:01<22:12,  1.22batches/s, epoch=1, loss=0.163, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 299/1924 [04:02<22:09,  1.22batches/s, epoch=1, loss=0.134, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 300/1924 [04:03<22:01,  1.23batches/s, epoch=1, loss=0.215, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 301/1924 [04:04<22:18,  1.21batches/s, epoch=1, loss=0.132, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 302/1924 [04:05<22:07,  1.22batches/s, epoch=1, loss=0.17, split=train] \n",
            "MaskedLanguageModeling:  16%|█▌        | 303/1924 [04:06<22:02,  1.23batches/s, epoch=1, loss=0.219, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 304/1924 [04:06<21:58,  1.23batches/s, epoch=1, loss=0.238, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 305/1924 [04:07<21:53,  1.23batches/s, epoch=1, loss=0.16, split=train] \n",
            "MaskedLanguageModeling:  16%|█▌        | 306/1924 [04:08<22:14,  1.21batches/s, epoch=1, loss=0.186, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 307/1924 [04:09<22:00,  1.22batches/s, epoch=1, loss=0.169, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 308/1924 [04:10<21:52,  1.23batches/s, epoch=1, loss=0.303, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 309/1924 [04:10<21:50,  1.23batches/s, epoch=1, loss=0.198, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 310/1924 [04:11<21:46,  1.24batches/s, epoch=1, loss=0.181, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 311/1924 [04:12<22:13,  1.21batches/s, epoch=1, loss=0.237, split=train]\n",
            "MaskedLanguageModeling:  16%|█▌        | 312/1924 [04:13<22:02,  1.22batches/s, epoch=1, loss=0.171, split=train]\n",
            "MaskedLanguageModeling:  16%|█▋        | 313/1924 [04:14<21:55,  1.22batches/s, epoch=1, loss=0.211, split=train]\n",
            "MaskedLanguageModeling:  16%|█▋        | 314/1924 [04:15<21:52,  1.23batches/s, epoch=1, loss=0.278, split=train]\n",
            "MaskedLanguageModeling:  16%|█▋        | 315/1924 [04:15<21:45,  1.23batches/s, epoch=1, loss=0.322, split=train]\n",
            "MaskedLanguageModeling:  16%|█▋        | 316/1924 [04:16<22:09,  1.21batches/s, epoch=1, loss=0.298, split=train]\n",
            "MaskedLanguageModeling:  16%|█▋        | 317/1924 [04:17<21:58,  1.22batches/s, epoch=1, loss=0.269, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 318/1924 [04:18<21:48,  1.23batches/s, epoch=1, loss=0.161, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 319/1924 [04:19<21:42,  1.23batches/s, epoch=1, loss=0.217, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 320/1924 [04:19<21:45,  1.23batches/s, epoch=1, loss=0.2, split=train]  \n",
            "MaskedLanguageModeling:  17%|█▋        | 321/1924 [04:20<22:06,  1.21batches/s, epoch=1, loss=0.15, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 322/1924 [04:21<21:49,  1.22batches/s, epoch=1, loss=0.257, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 323/1924 [04:22<21:38,  1.23batches/s, epoch=1, loss=0.153, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 324/1924 [04:23<21:34,  1.24batches/s, epoch=1, loss=0.249, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 325/1924 [04:23<21:31,  1.24batches/s, epoch=1, loss=0.307, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 326/1924 [04:24<22:00,  1.21batches/s, epoch=1, loss=0.329, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 327/1924 [04:25<21:49,  1.22batches/s, epoch=1, loss=0.23, split=train] \n",
            "MaskedLanguageModeling:  17%|█▋        | 328/1924 [04:26<21:44,  1.22batches/s, epoch=1, loss=0.174, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 329/1924 [04:27<21:43,  1.22batches/s, epoch=1, loss=0.127, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 330/1924 [04:28<21:38,  1.23batches/s, epoch=1, loss=0.204, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 331/1924 [04:28<21:56,  1.21batches/s, epoch=1, loss=0.142, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 332/1924 [04:29<21:41,  1.22batches/s, epoch=1, loss=0.179, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 333/1924 [04:30<21:30,  1.23batches/s, epoch=1, loss=0.401, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 334/1924 [04:31<21:31,  1.23batches/s, epoch=1, loss=0.24, split=train] \n",
            "MaskedLanguageModeling:  17%|█▋        | 335/1924 [04:32<21:28,  1.23batches/s, epoch=1, loss=0.124, split=train]\n",
            "MaskedLanguageModeling:  17%|█▋        | 336/1924 [04:33<21:51,  1.21batches/s, epoch=1, loss=0.144, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 337/1924 [04:33<21:43,  1.22batches/s, epoch=1, loss=0.298, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 338/1924 [04:34<21:39,  1.22batches/s, epoch=1, loss=0.196, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 339/1924 [04:35<21:31,  1.23batches/s, epoch=1, loss=0.178, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 340/1924 [04:36<21:27,  1.23batches/s, epoch=1, loss=0.189, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 341/1924 [04:37<21:55,  1.20batches/s, epoch=1, loss=0.121, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 342/1924 [04:37<21:39,  1.22batches/s, epoch=1, loss=0.234, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 343/1924 [04:38<21:30,  1.23batches/s, epoch=1, loss=0.296, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 344/1924 [04:39<21:25,  1.23batches/s, epoch=1, loss=0.133, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 345/1924 [04:40<21:20,  1.23batches/s, epoch=1, loss=0.248, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 346/1924 [04:41<21:41,  1.21batches/s, epoch=1, loss=0.231, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 347/1924 [04:41<21:28,  1.22batches/s, epoch=1, loss=0.211, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 348/1924 [04:42<21:19,  1.23batches/s, epoch=1, loss=0.0866, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 349/1924 [04:43<21:19,  1.23batches/s, epoch=1, loss=0.302, split=train] \n",
            "MaskedLanguageModeling:  18%|█▊        | 350/1924 [04:44<21:15,  1.23batches/s, epoch=1, loss=0.108, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 351/1924 [04:45<21:43,  1.21batches/s, epoch=1, loss=0.146, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 352/1924 [04:46<21:32,  1.22batches/s, epoch=1, loss=0.147, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 353/1924 [04:46<21:26,  1.22batches/s, epoch=1, loss=0.178, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 354/1924 [04:47<21:18,  1.23batches/s, epoch=1, loss=0.276, split=train]\n",
            "MaskedLanguageModeling:  18%|█▊        | 355/1924 [04:48<21:14,  1.23batches/s, epoch=1, loss=0.351, split=train]\n",
            "MaskedLanguageModeling:  19%|█▊        | 356/1924 [04:49<21:35,  1.21batches/s, epoch=1, loss=0.0852, split=train]\n",
            "MaskedLanguageModeling:  19%|█▊        | 357/1924 [04:50<21:23,  1.22batches/s, epoch=1, loss=0.184, split=train] \n",
            "MaskedLanguageModeling:  19%|█▊        | 358/1924 [04:50<21:14,  1.23batches/s, epoch=1, loss=0.43, split=train] \n",
            "MaskedLanguageModeling:  19%|█▊        | 359/1924 [04:51<21:13,  1.23batches/s, epoch=1, loss=0.117, split=train]\n",
            "MaskedLanguageModeling:  19%|█▊        | 360/1924 [04:52<21:09,  1.23batches/s, epoch=1, loss=0.179, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 361/1924 [04:53<21:30,  1.21batches/s, epoch=1, loss=0.1, split=train]  \n",
            "MaskedLanguageModeling:  19%|█▉        | 362/1924 [04:54<21:22,  1.22batches/s, epoch=1, loss=0.339, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 363/1924 [04:55<21:14,  1.22batches/s, epoch=1, loss=0.116, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 364/1924 [04:55<21:08,  1.23batches/s, epoch=1, loss=0.33, split=train] \n",
            "MaskedLanguageModeling:  19%|█▉        | 365/1924 [04:56<21:02,  1.23batches/s, epoch=1, loss=0.185, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 366/1924 [04:57<21:25,  1.21batches/s, epoch=1, loss=0.172, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 367/1924 [04:58<21:13,  1.22batches/s, epoch=1, loss=0.335, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 368/1924 [04:59<21:07,  1.23batches/s, epoch=1, loss=0.137, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 369/1924 [04:59<21:01,  1.23batches/s, epoch=1, loss=0.128, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 370/1924 [05:00<20:54,  1.24batches/s, epoch=1, loss=0.101, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 371/1924 [05:01<21:18,  1.21batches/s, epoch=1, loss=0.389, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 372/1924 [05:02<21:05,  1.23batches/s, epoch=1, loss=0.151, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 373/1924 [05:03<21:03,  1.23batches/s, epoch=1, loss=0.114, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 374/1924 [05:04<20:58,  1.23batches/s, epoch=1, loss=0.172, split=train]\n",
            "MaskedLanguageModeling:  19%|█▉        | 375/1924 [05:04<20:54,  1.23batches/s, epoch=1, loss=0.172, split=train]\n",
            "MaskedLanguageModeling:  20%|█▉        | 376/1924 [05:05<21:17,  1.21batches/s, epoch=1, loss=0.221, split=train]\n",
            "MaskedLanguageModeling:  20%|█▉        | 377/1924 [05:06<21:02,  1.22batches/s, epoch=1, loss=0.19, split=train] \n",
            "MaskedLanguageModeling:  20%|█▉        | 378/1924 [05:07<20:55,  1.23batches/s, epoch=1, loss=0.243, split=train]\n",
            "MaskedLanguageModeling:  20%|█▉        | 379/1924 [05:08<20:52,  1.23batches/s, epoch=1, loss=0.2, split=train]  \n",
            "MaskedLanguageModeling:  20%|█▉        | 380/1924 [05:08<20:48,  1.24batches/s, epoch=1, loss=0.16, split=train]\n",
            "MaskedLanguageModeling:  20%|█▉        | 381/1924 [05:09<21:15,  1.21batches/s, epoch=1, loss=0.27, split=train]\n",
            "MaskedLanguageModeling:  20%|█▉        | 382/1924 [05:10<21:08,  1.22batches/s, epoch=1, loss=0.361, split=train]\n",
            "MaskedLanguageModeling:  20%|█▉        | 383/1924 [05:11<21:04,  1.22batches/s, epoch=1, loss=0.0681, split=train]\n",
            "MaskedLanguageModeling:  20%|█▉        | 384/1924 [05:12<20:59,  1.22batches/s, epoch=1, loss=0.258, split=train] \n",
            "MaskedLanguageModeling:  20%|██        | 385/1924 [05:13<20:52,  1.23batches/s, epoch=1, loss=0.137, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 386/1924 [05:13<21:10,  1.21batches/s, epoch=1, loss=0.119, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 387/1924 [05:14<20:57,  1.22batches/s, epoch=1, loss=0.249, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 388/1924 [05:15<20:51,  1.23batches/s, epoch=1, loss=0.379, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 389/1924 [05:16<20:43,  1.23batches/s, epoch=1, loss=0.176, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 390/1924 [05:17<20:42,  1.23batches/s, epoch=1, loss=0.201, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 391/1924 [05:17<21:06,  1.21batches/s, epoch=1, loss=0.435, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 392/1924 [05:18<20:59,  1.22batches/s, epoch=1, loss=0.381, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 393/1924 [05:19<20:52,  1.22batches/s, epoch=1, loss=0.253, split=train]\n",
            "MaskedLanguageModeling:  20%|██        | 394/1924 [05:20<20:46,  1.23batches/s, epoch=1, loss=0.0756, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 395/1924 [05:21<20:37,  1.24batches/s, epoch=1, loss=0.176, split=train] \n",
            "MaskedLanguageModeling:  21%|██        | 396/1924 [05:22<20:59,  1.21batches/s, epoch=1, loss=0.31, split=train] \n",
            "MaskedLanguageModeling:  21%|██        | 397/1924 [05:22<20:47,  1.22batches/s, epoch=1, loss=0.173, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 398/1924 [05:23<20:41,  1.23batches/s, epoch=1, loss=0.335, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 399/1924 [05:24<20:40,  1.23batches/s, epoch=1, loss=0.0738, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 400/1924 [05:25<20:35,  1.23batches/s, epoch=1, loss=0.212, split=train] \n",
            "MaskedLanguageModeling:  21%|██        | 401/1924 [05:26<20:59,  1.21batches/s, epoch=1, loss=0.113, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 402/1924 [05:26<20:49,  1.22batches/s, epoch=1, loss=0.263, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 403/1924 [05:27<20:44,  1.22batches/s, epoch=1, loss=0.341, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 404/1924 [05:28<20:36,  1.23batches/s, epoch=1, loss=0.311, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 405/1924 [05:29<20:31,  1.23batches/s, epoch=1, loss=0.155, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 406/1924 [05:30<20:53,  1.21batches/s, epoch=1, loss=0.427, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 407/1924 [05:31<20:42,  1.22batches/s, epoch=1, loss=0.157, split=train]\n",
            "MaskedLanguageModeling:  21%|██        | 408/1924 [05:31<20:34,  1.23batches/s, epoch=1, loss=0.251, split=train]\n",
            "MaskedLanguageModeling:  21%|██▏       | 409/1924 [05:32<20:31,  1.23batches/s, epoch=1, loss=0.233, split=train]\n",
            "MaskedLanguageModeling:  21%|██▏       | 410/1924 [05:33<20:26,  1.23batches/s, epoch=1, loss=0.113, split=train]\n",
            "MaskedLanguageModeling:  21%|██▏       | 411/1924 [05:34<20:49,  1.21batches/s, epoch=1, loss=0.118, split=train]\n",
            "MaskedLanguageModeling:  21%|██▏       | 412/1924 [05:35<20:40,  1.22batches/s, epoch=1, loss=0.243, split=train]\n",
            "MaskedLanguageModeling:  21%|██▏       | 413/1924 [05:35<20:33,  1.22batches/s, epoch=1, loss=0.158, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 414/1924 [05:36<20:28,  1.23batches/s, epoch=1, loss=0.144, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 415/1924 [05:37<20:23,  1.23batches/s, epoch=1, loss=0.241, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 416/1924 [05:38<20:46,  1.21batches/s, epoch=1, loss=0.271, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 417/1924 [05:39<20:37,  1.22batches/s, epoch=1, loss=0.118, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 418/1924 [05:39<20:30,  1.22batches/s, epoch=1, loss=0.127, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 419/1924 [05:40<20:28,  1.23batches/s, epoch=1, loss=0.29, split=train] \n",
            "MaskedLanguageModeling:  22%|██▏       | 420/1924 [05:41<20:23,  1.23batches/s, epoch=1, loss=0.148, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 421/1924 [05:42<20:49,  1.20batches/s, epoch=1, loss=0.12, split=train] \n",
            "MaskedLanguageModeling:  22%|██▏       | 422/1924 [05:43<20:32,  1.22batches/s, epoch=1, loss=0.154, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 423/1924 [05:44<20:28,  1.22batches/s, epoch=1, loss=0.16, split=train] \n",
            "MaskedLanguageModeling:  22%|██▏       | 424/1924 [05:44<20:25,  1.22batches/s, epoch=1, loss=0.179, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 425/1924 [05:45<20:22,  1.23batches/s, epoch=1, loss=0.1, split=train]  \n",
            "MaskedLanguageModeling:  22%|██▏       | 426/1924 [05:46<20:41,  1.21batches/s, epoch=1, loss=0.0299, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 427/1924 [05:47<20:30,  1.22batches/s, epoch=1, loss=0.137, split=train] \n",
            "MaskedLanguageModeling:  22%|██▏       | 428/1924 [05:48<20:19,  1.23batches/s, epoch=1, loss=0.252, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 429/1924 [05:48<20:13,  1.23batches/s, epoch=1, loss=0.267, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 430/1924 [05:49<20:07,  1.24batches/s, epoch=1, loss=0.307, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 431/1924 [05:50<20:34,  1.21batches/s, epoch=1, loss=0.286, split=train]\n",
            "MaskedLanguageModeling:  22%|██▏       | 432/1924 [05:51<20:23,  1.22batches/s, epoch=1, loss=0.242, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 433/1924 [05:52<20:14,  1.23batches/s, epoch=1, loss=0.21, split=train] \n",
            "MaskedLanguageModeling:  23%|██▎       | 434/1924 [05:53<20:10,  1.23batches/s, epoch=1, loss=0.351, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 435/1924 [05:53<20:08,  1.23batches/s, epoch=1, loss=0.101, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 436/1924 [05:54<20:34,  1.21batches/s, epoch=1, loss=0.206, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 437/1924 [05:55<20:19,  1.22batches/s, epoch=1, loss=0.124, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 438/1924 [05:56<20:14,  1.22batches/s, epoch=1, loss=0.156, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 439/1924 [05:57<20:09,  1.23batches/s, epoch=1, loss=0.274, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 440/1924 [05:57<20:02,  1.23batches/s, epoch=1, loss=0.115, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 441/1924 [05:58<20:23,  1.21batches/s, epoch=1, loss=0.262, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 442/1924 [05:59<20:12,  1.22batches/s, epoch=1, loss=0.24, split=train] \n",
            "MaskedLanguageModeling:  23%|██▎       | 443/1924 [06:00<20:06,  1.23batches/s, epoch=1, loss=0.2, split=train] \n",
            "MaskedLanguageModeling:  23%|██▎       | 444/1924 [06:01<19:59,  1.23batches/s, epoch=1, loss=0.079, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 445/1924 [06:02<19:56,  1.24batches/s, epoch=1, loss=0.133, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 446/1924 [06:02<20:16,  1.22batches/s, epoch=1, loss=0.289, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 447/1924 [06:03<20:08,  1.22batches/s, epoch=1, loss=0.216, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 448/1924 [06:04<19:59,  1.23batches/s, epoch=1, loss=0.314, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 449/1924 [06:05<19:52,  1.24batches/s, epoch=1, loss=0.292, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 450/1924 [06:06<19:49,  1.24batches/s, epoch=1, loss=0.218, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 451/1924 [06:06<20:11,  1.22batches/s, epoch=1, loss=0.109, split=train]\n",
            "MaskedLanguageModeling:  23%|██▎       | 452/1924 [06:07<20:01,  1.22batches/s, epoch=1, loss=0.297, split=train]\n",
            "MaskedLanguageModeling:  24%|██▎       | 453/1924 [06:08<19:57,  1.23batches/s, epoch=1, loss=0.329, split=train]\n",
            "MaskedLanguageModeling:  24%|██▎       | 454/1924 [06:09<19:59,  1.23batches/s, epoch=1, loss=0.0733, split=train]\n",
            "MaskedLanguageModeling:  24%|██▎       | 455/1924 [06:10<19:56,  1.23batches/s, epoch=1, loss=0.205, split=train] \n",
            "MaskedLanguageModeling:  24%|██▎       | 456/1924 [06:11<20:15,  1.21batches/s, epoch=1, loss=0.227, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 457/1924 [06:11<20:02,  1.22batches/s, epoch=1, loss=0.199, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 458/1924 [06:12<19:55,  1.23batches/s, epoch=1, loss=0.321, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 459/1924 [06:13<19:52,  1.23batches/s, epoch=1, loss=0.145, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 460/1924 [06:14<19:45,  1.23batches/s, epoch=1, loss=0.258, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 461/1924 [06:15<20:05,  1.21batches/s, epoch=1, loss=0.108, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 462/1924 [06:15<19:58,  1.22batches/s, epoch=1, loss=0.102, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 463/1924 [06:16<19:49,  1.23batches/s, epoch=1, loss=0.3, split=train]  \n",
            "MaskedLanguageModeling:  24%|██▍       | 464/1924 [06:17<19:47,  1.23batches/s, epoch=1, loss=0.186, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 465/1924 [06:18<19:40,  1.24batches/s, epoch=1, loss=0.16, split=train] \n",
            "MaskedLanguageModeling:  24%|██▍       | 466/1924 [06:19<20:05,  1.21batches/s, epoch=1, loss=0.21, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 467/1924 [06:20<19:54,  1.22batches/s, epoch=1, loss=0.115, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 468/1924 [06:20<19:48,  1.23batches/s, epoch=1, loss=0.0699, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 469/1924 [06:21<19:43,  1.23batches/s, epoch=1, loss=0.128, split=train] \n",
            "MaskedLanguageModeling:  24%|██▍       | 470/1924 [06:22<19:41,  1.23batches/s, epoch=1, loss=0.108, split=train]\n",
            "MaskedLanguageModeling:  24%|██▍       | 471/1924 [06:23<20:00,  1.21batches/s, epoch=1, loss=0.229, split=train]\n",
            "MaskedLanguageModeling:  25%|██▍       | 472/1924 [06:24<19:51,  1.22batches/s, epoch=1, loss=0.17, split=train] \n",
            "MaskedLanguageModeling:  25%|██▍       | 473/1924 [06:24<19:44,  1.23batches/s, epoch=1, loss=0.335, split=train]\n",
            "MaskedLanguageModeling:  25%|██▍       | 474/1924 [06:25<19:37,  1.23batches/s, epoch=1, loss=0.125, split=train]\n",
            "MaskedLanguageModeling:  25%|██▍       | 475/1924 [06:26<19:32,  1.24batches/s, epoch=1, loss=0.166, split=train]\n",
            "MaskedLanguageModeling:  25%|██▍       | 476/1924 [06:27<19:53,  1.21batches/s, epoch=1, loss=0.193, split=train]\n",
            "MaskedLanguageModeling:  25%|██▍       | 477/1924 [06:28<19:44,  1.22batches/s, epoch=1, loss=0.226, split=train]\n",
            "MaskedLanguageModeling:  25%|██▍       | 478/1924 [06:29<19:37,  1.23batches/s, epoch=1, loss=0.0795, split=train]\n",
            "MaskedLanguageModeling:  25%|██▍       | 479/1924 [06:29<19:33,  1.23batches/s, epoch=1, loss=0.105, split=train] \n",
            "MaskedLanguageModeling:  25%|██▍       | 480/1924 [06:30<19:33,  1.23batches/s, epoch=1, loss=0.118, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 481/1924 [06:31<19:53,  1.21batches/s, epoch=1, loss=0.135, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 482/1924 [06:32<19:43,  1.22batches/s, epoch=1, loss=0.236, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 483/1924 [06:33<19:35,  1.23batches/s, epoch=1, loss=0.153, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 484/1924 [06:33<19:32,  1.23batches/s, epoch=1, loss=0.171, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 485/1924 [06:34<19:28,  1.23batches/s, epoch=1, loss=0.29, split=train] \n",
            "MaskedLanguageModeling:  25%|██▌       | 486/1924 [06:35<19:50,  1.21batches/s, epoch=1, loss=0.436, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 487/1924 [06:36<19:37,  1.22batches/s, epoch=1, loss=0.351, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 488/1924 [06:37<19:30,  1.23batches/s, epoch=1, loss=0.139, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 489/1924 [06:38<19:25,  1.23batches/s, epoch=1, loss=0.341, split=train]\n",
            "MaskedLanguageModeling:  25%|██▌       | 490/1924 [06:38<19:19,  1.24batches/s, epoch=1, loss=0.0959, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 491/1924 [06:39<19:42,  1.21batches/s, epoch=1, loss=0.226, split=train] \n",
            "MaskedLanguageModeling:  26%|██▌       | 492/1924 [06:40<19:29,  1.22batches/s, epoch=1, loss=0.159, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 493/1924 [06:41<19:26,  1.23batches/s, epoch=1, loss=0.168, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 494/1924 [06:42<19:25,  1.23batches/s, epoch=1, loss=0.118, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 495/1924 [06:42<19:21,  1.23batches/s, epoch=1, loss=0.124, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 496/1924 [06:43<19:42,  1.21batches/s, epoch=1, loss=0.304, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 497/1924 [06:44<19:29,  1.22batches/s, epoch=1, loss=0.108, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 498/1924 [06:45<19:20,  1.23batches/s, epoch=1, loss=0.131, split=train]\n",
            "MaskedLanguageModeling:  26%|██▌       | 499/1924 [06:46<19:14,  1.23batches/s, epoch=1, loss=0.36, split=train] \n",
            "MaskedLanguageModeling:  26%|██▌       | 500/1924 [06:46<19:10,  1.24batches/s, epoch=1, loss=0.428, split=train]\n",
            "SequenceClassification:  26%|██▌       | 500/1924 [06:46<19:12,  1.24batches/s, epoch=1, loss=0.625, split=train]\u001b[AConverged objectives: []\n",
            "Evaluating...\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 250\n",
            "  Batch size = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.4433, 'learning_rate': 2.0000000000000002e-07, 'train_MaskedLanguageModeling_loss': 0.21739389516413213, 'train_MaskedLanguageModeling_num_batches': 500, 'train_SequenceClassification_loss': 0.6692616649866104, 'train_SequenceClassification_num_batches': 500, 'epoch': 0.01}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MaskedLanguageModeling: 250batches [00:39,  6.29batches/s, epoch=1, loss=0.0308, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 251 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 251batches [00:39,  6.31batches/s, epoch=1, loss=0.186, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 252 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 252batches [00:39,  6.34batches/s, epoch=1, loss=0.136, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 253 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 253batches [00:39,  6.35batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 254 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 254batches [00:40,  6.27batches/s, epoch=1, loss=0.397, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 255 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 255batches [00:40,  6.27batches/s, epoch=1, loss=0.228, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 256 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 256batches [00:40,  6.27batches/s, epoch=1, loss=0.07, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 257 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 257batches [00:40,  6.33batches/s, epoch=1, loss=0.267, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 258 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 258batches [00:40,  6.34batches/s, epoch=1, loss=0.28, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 259 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 259batches [00:40,  6.36batches/s, epoch=1, loss=0.28, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 260 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 260batches [00:40,  6.36batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 261 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 261batches [00:41,  6.35batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 262 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 262batches [00:41,  6.34batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 263 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 263batches [00:41,  6.34batches/s, epoch=1, loss=0.27, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 264 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 264batches [00:41,  6.35batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 265 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 265batches [00:41,  6.36batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 266 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 266batches [00:41,  6.34batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 267 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 267batches [00:42,  6.33batches/s, epoch=1, loss=0.338, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 268 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 268batches [00:42,  6.31batches/s, epoch=1, loss=0.36, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 269 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 269batches [00:42,  6.23batches/s, epoch=1, loss=0.222, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 270 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 270batches [00:42,  6.24batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 271 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 271batches [00:42,  6.31batches/s, epoch=1, loss=0.334, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 272 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 272batches [00:42,  6.37batches/s, epoch=1, loss=0.0858, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 273 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 273batches [00:43,  6.33batches/s, epoch=1, loss=0.148, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 274 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 274batches [00:43,  6.34batches/s, epoch=1, loss=0.355, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 275 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 275batches [00:43,  6.24batches/s, epoch=1, loss=0.0569, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 276 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 276batches [00:43,  6.32batches/s, epoch=1, loss=0.209, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 277 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 277batches [00:43,  6.32batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 278 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 278batches [00:43,  6.31batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 279 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 279batches [00:43,  6.32batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 280 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 280batches [00:44,  6.31batches/s, epoch=1, loss=0.214, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 281 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 281batches [00:44,  6.25batches/s, epoch=1, loss=0.188, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 282 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 282batches [00:44,  6.24batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 283 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 283batches [00:44,  6.27batches/s, epoch=1, loss=0.066, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 284 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 284batches [00:44,  6.25batches/s, epoch=1, loss=0.0228, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 285 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 285batches [00:44,  6.26batches/s, epoch=1, loss=0.155, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 286 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 286batches [00:45,  6.29batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 287 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 287batches [00:45,  6.30batches/s, epoch=1, loss=0.348, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 288 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 288batches [00:45,  6.30batches/s, epoch=1, loss=0.138, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 289 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 289batches [00:45,  6.33batches/s, epoch=1, loss=0.0775, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 290 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 290batches [00:45,  6.34batches/s, epoch=1, loss=0.241, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 291 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 291batches [00:45,  6.33batches/s, epoch=1, loss=0.149, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 292 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 292batches [00:46,  6.30batches/s, epoch=1, loss=0.166, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 293 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 293batches [00:46,  6.32batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 294 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 294batches [00:46,  6.30batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 295 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 295batches [00:46,  6.32batches/s, epoch=1, loss=0.162, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 296 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 296batches [00:46,  6.33batches/s, epoch=1, loss=0.245, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 297 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 297batches [00:46,  6.28batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 298 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 298batches [00:46,  6.26batches/s, epoch=1, loss=0.427, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 299 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 299batches [00:47,  6.31batches/s, epoch=1, loss=0.196, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 300 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 300batches [00:47,  6.31batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 301 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 301batches [00:47,  6.27batches/s, epoch=1, loss=0.0826, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 302 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 302batches [00:47,  6.29batches/s, epoch=1, loss=0.215, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 303 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 303batches [00:47,  6.29batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 304 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 304batches [00:47,  6.25batches/s, epoch=1, loss=0.269, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 305 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 305batches [00:48,  6.25batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 306 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 306batches [00:48,  6.24batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 307 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 307batches [00:48,  6.21batches/s, epoch=1, loss=0.0548, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 308 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 308batches [00:48,  6.29batches/s, epoch=1, loss=0.0927, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 309 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 309batches [00:48,  6.26batches/s, epoch=1, loss=0.299, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 310 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 310batches [00:48,  6.30batches/s, epoch=1, loss=0.396, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 311 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 311batches [00:49,  6.30batches/s, epoch=1, loss=0.206, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 312 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 312batches [00:49,  6.33batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 313 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 313batches [00:49,  6.32batches/s, epoch=1, loss=0.14, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 314 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 314batches [00:49,  6.32batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 315 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 315batches [00:49,  6.33batches/s, epoch=1, loss=0.188, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 316 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 316batches [00:49,  6.31batches/s, epoch=1, loss=0.161, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 317 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 317batches [00:50,  6.27batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 318 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 318batches [00:50,  6.32batches/s, epoch=1, loss=0.267, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 319 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 319batches [00:50,  6.35batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 320 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 320batches [00:50,  6.26batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 321 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 321batches [00:50,  6.22batches/s, epoch=1, loss=0.077, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 322 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 322batches [00:50,  6.26batches/s, epoch=1, loss=0.0929, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 323 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 323batches [00:50,  6.26batches/s, epoch=1, loss=0.115, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 324 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 324batches [00:51,  6.24batches/s, epoch=1, loss=0.169, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 325 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 325batches [00:51,  6.22batches/s, epoch=1, loss=0.359, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 326 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 326batches [00:51,  6.22batches/s, epoch=1, loss=0.257, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 327 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 327batches [00:51,  6.25batches/s, epoch=1, loss=0.331, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 328 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 328batches [00:51,  6.26batches/s, epoch=1, loss=0.227, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 329 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 329batches [00:51,  6.33batches/s, epoch=1, loss=0.361, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 330 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 330batches [00:52,  6.34batches/s, epoch=1, loss=0.249, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 331 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 331batches [00:52,  6.34batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 332 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 332batches [00:52,  6.34batches/s, epoch=1, loss=0.298, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 333 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 333batches [00:52,  6.25batches/s, epoch=1, loss=0.13, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 334 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 334batches [00:52,  6.25batches/s, epoch=1, loss=0.213, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 335 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 335batches [00:52,  6.33batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 336 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 336batches [00:53,  6.38batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 337 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 337batches [00:53,  6.32batches/s, epoch=1, loss=0.106, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 338 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 338batches [00:53,  6.31batches/s, epoch=1, loss=0.0913, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 339 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 339batches [00:53,  6.29batches/s, epoch=1, loss=0.34, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 340 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 340batches [00:53,  6.28batches/s, epoch=1, loss=0.269, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 341 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 341batches [00:53,  6.29batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 342 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 342batches [00:53,  6.30batches/s, epoch=1, loss=0.211, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 343 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 343batches [00:54,  6.29batches/s, epoch=1, loss=0.299, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 344 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 344batches [00:54,  6.30batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 345 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 345batches [00:54,  6.26batches/s, epoch=1, loss=0.404, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 346 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 346batches [00:54,  6.24batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 347 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 347batches [00:54,  6.25batches/s, epoch=1, loss=0.251, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 348 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 348batches [00:54,  6.31batches/s, epoch=1, loss=0.109, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 349 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 349batches [00:55,  6.32batches/s, epoch=1, loss=0.173, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 350 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 350batches [00:55,  6.30batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 351 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 351batches [00:55,  6.31batches/s, epoch=1, loss=0.37, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 352 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 352batches [00:55,  6.28batches/s, epoch=1, loss=0.0758, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 353 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 353batches [00:55,  6.32batches/s, epoch=1, loss=0.238, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 354 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 354batches [00:55,  6.31batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 355 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 355batches [00:56,  6.36batches/s, epoch=1, loss=0.17, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 356 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 356batches [00:56,  6.33batches/s, epoch=1, loss=0.15, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 357 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 357batches [00:56,  6.29batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 358 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 358batches [00:56,  6.29batches/s, epoch=1, loss=0.263, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 359 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 359batches [00:56,  6.24batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 360 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 360batches [00:56,  6.26batches/s, epoch=1, loss=0.0509, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 361 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 361batches [00:56,  6.26batches/s, epoch=1, loss=0.0929, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 362 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 362batches [00:57,  6.19batches/s, epoch=1, loss=0.36, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 363 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 363batches [00:57,  6.20batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 364 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 364batches [00:57,  6.17batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 365 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 365batches [00:57,  6.19batches/s, epoch=1, loss=0.0712, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 366 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 366batches [00:57,  6.22batches/s, epoch=1, loss=0.266, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 367 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 367batches [00:57,  6.20batches/s, epoch=1, loss=0.226, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 368 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 368batches [00:58,  6.25batches/s, epoch=1, loss=0.258, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 369 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 369batches [00:58,  6.22batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 370 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 370batches [00:58,  6.25batches/s, epoch=1, loss=0.0467, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 371 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 371batches [00:58,  6.31batches/s, epoch=1, loss=0.243, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 372 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 372batches [00:58,  6.29batches/s, epoch=1, loss=0.102, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 373 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 373batches [00:58,  6.28batches/s, epoch=1, loss=0.0958, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 374 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 374batches [00:59,  6.27batches/s, epoch=1, loss=0.146, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 375 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 375batches [00:59,  6.29batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 376 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 376batches [00:59,  6.34batches/s, epoch=1, loss=0.14, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 377 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 377batches [00:59,  6.31batches/s, epoch=1, loss=0.339, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 378 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 378batches [00:59,  6.27batches/s, epoch=1, loss=0.154, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 379 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 379batches [00:59,  6.25batches/s, epoch=1, loss=0.0752, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 380 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 380batches [01:00,  6.24batches/s, epoch=1, loss=0.272, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 381 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 381batches [01:00,  6.22batches/s, epoch=1, loss=0.1, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 382 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 382batches [01:00,  6.21batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 383 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 383batches [01:00,  6.25batches/s, epoch=1, loss=0.0635, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 384 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 384batches [01:00,  6.19batches/s, epoch=1, loss=0.0867, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 385 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 385batches [01:00,  6.20batches/s, epoch=1, loss=0.29, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 386 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 386batches [01:01,  6.20batches/s, epoch=1, loss=0.162, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 387 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 387batches [01:01,  6.26batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 388 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 388batches [01:01,  6.27batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 389 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 389batches [01:01,  6.26batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 390 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 390batches [01:01,  6.26batches/s, epoch=1, loss=0.185, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 391 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 391batches [01:01,  6.26batches/s, epoch=1, loss=0.183, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 392 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 392batches [01:01,  6.29batches/s, epoch=1, loss=0.275, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 393 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 393batches [01:02,  6.29batches/s, epoch=1, loss=0.473, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 394 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 394batches [01:02,  6.22batches/s, epoch=1, loss=0.272, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 395 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 395batches [01:02,  6.23batches/s, epoch=1, loss=0.376, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 396 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 396batches [01:02,  6.30batches/s, epoch=1, loss=0.266, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 397 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 397batches [01:02,  6.31batches/s, epoch=1, loss=0.145, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 398 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 398batches [01:02,  6.28batches/s, epoch=1, loss=0.15, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 399 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 399batches [01:03,  6.28batches/s, epoch=1, loss=0.143, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 400 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 400batches [01:03,  6.27batches/s, epoch=1, loss=0.207, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 401 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 401batches [01:03,  6.26batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 402 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 402batches [01:03,  6.28batches/s, epoch=1, loss=0.0546, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 403 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 403batches [01:03,  6.26batches/s, epoch=1, loss=0.0634, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 404 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 404batches [01:03,  6.26batches/s, epoch=1, loss=0.251, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 405 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 405batches [01:04,  6.22batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 406 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 406batches [01:04,  6.22batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 407 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 407batches [01:04,  6.23batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 408 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 408batches [01:04,  6.23batches/s, epoch=1, loss=0.286, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 409 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 409batches [01:04,  6.26batches/s, epoch=1, loss=0.0983, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 410 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 410batches [01:04,  6.28batches/s, epoch=1, loss=0.222, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 411 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 411batches [01:04,  6.26batches/s, epoch=1, loss=0.311, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 412 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 412batches [01:05,  6.29batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 413 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 413batches [01:05,  6.27batches/s, epoch=1, loss=0.231, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 414 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 414batches [01:05,  6.30batches/s, epoch=1, loss=0.103, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 415 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 415batches [01:05,  6.33batches/s, epoch=1, loss=0.103, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 416 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 416batches [01:05,  6.29batches/s, epoch=1, loss=0.242, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 417 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 417batches [01:05,  6.29batches/s, epoch=1, loss=0.183, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 418 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 418batches [01:06,  6.29batches/s, epoch=1, loss=0.313, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 419 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 419batches [01:06,  6.29batches/s, epoch=1, loss=0.251, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 420 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 420batches [01:06,  6.36batches/s, epoch=1, loss=0.0949, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 421 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 421batches [01:06,  6.35batches/s, epoch=1, loss=0.107, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 422 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 422batches [01:06,  6.32batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 423 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 423batches [01:06,  6.25batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 424 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 424batches [01:07,  6.27batches/s, epoch=1, loss=0.227, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 425 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 425batches [01:07,  6.25batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 426 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 426batches [01:07,  6.14batches/s, epoch=1, loss=0.237, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 427 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 427batches [01:07,  6.17batches/s, epoch=1, loss=0.0654, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 428 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 428batches [01:07,  6.13batches/s, epoch=1, loss=0.294, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 429 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 429batches [01:07,  6.18batches/s, epoch=1, loss=0.217, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 430 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 430batches [01:08,  6.23batches/s, epoch=1, loss=0.183, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 431 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 431batches [01:08,  6.26batches/s, epoch=1, loss=0.268, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 432 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 432batches [01:08,  6.26batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 433 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 433batches [01:08,  6.24batches/s, epoch=1, loss=0.247, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 434 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 434batches [01:08,  6.26batches/s, epoch=1, loss=0.117, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 435 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 435batches [01:08,  6.27batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 436 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 436batches [01:08,  6.31batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 437 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 437batches [01:09,  6.29batches/s, epoch=1, loss=0.091, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 438 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 438batches [01:09,  6.20batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 439 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 439batches [01:09,  6.15batches/s, epoch=1, loss=0.0914, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 440 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 440batches [01:09,  6.24batches/s, epoch=1, loss=0.162, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 441 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 441batches [01:09,  6.26batches/s, epoch=1, loss=0.19, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 442 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 442batches [01:09,  6.27batches/s, epoch=1, loss=0.103, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 443 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 443batches [01:10,  6.23batches/s, epoch=1, loss=0.138, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 444 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 444batches [01:10,  6.22batches/s, epoch=1, loss=0.37, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 445 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 445batches [01:10,  6.27batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 446 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 446batches [01:10,  6.32batches/s, epoch=1, loss=0.223, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 447 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 447batches [01:10,  6.25batches/s, epoch=1, loss=0.214, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 448 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 448batches [01:10,  6.20batches/s, epoch=1, loss=0.31, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 449 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 449batches [01:11,  6.24batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 450 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 450batches [01:11,  6.23batches/s, epoch=1, loss=0.085, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 451 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 451batches [01:11,  6.22batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 452 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 452batches [01:11,  6.22batches/s, epoch=1, loss=0.099, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 453 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 453batches [01:11,  6.20batches/s, epoch=1, loss=0.199, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 454 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 454batches [01:11,  6.20batches/s, epoch=1, loss=0.188, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 455 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 455batches [01:12,  6.23batches/s, epoch=1, loss=0.0922, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 456 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 456batches [01:12,  6.30batches/s, epoch=1, loss=0.385, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 457 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 457batches [01:12,  6.34batches/s, epoch=1, loss=0.315, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 458 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 458batches [01:12,  6.31batches/s, epoch=1, loss=0.0645, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 459 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 459batches [01:12,  6.29batches/s, epoch=1, loss=0.204, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 460 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 460batches [01:12,  6.29batches/s, epoch=1, loss=0.191, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 461 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 461batches [01:12,  6.26batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 462 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 462batches [01:13,  6.25batches/s, epoch=1, loss=0.0888, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 463 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 463batches [01:13,  6.26batches/s, epoch=1, loss=0.148, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 464 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 464batches [01:13,  6.30batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 465 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 465batches [01:13,  6.27batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 466 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 466batches [01:13,  6.28batches/s, epoch=1, loss=0.262, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 467 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 467batches [01:13,  6.28batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 468 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 468batches [01:14,  6.27batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 469 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 469batches [01:14,  6.23batches/s, epoch=1, loss=0.0633, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 470 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 470batches [01:14,  6.21batches/s, epoch=1, loss=0.215, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 471 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 471batches [01:14,  6.20batches/s, epoch=1, loss=0.0836, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 472 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 472batches [01:14,  6.25batches/s, epoch=1, loss=0.2, split=eval]   /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 473 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 473batches [01:14,  6.29batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 474 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 474batches [01:15,  6.28batches/s, epoch=1, loss=0.0632, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 475 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 475batches [01:15,  6.32batches/s, epoch=1, loss=0.0457, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 476 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 476batches [01:15,  6.26batches/s, epoch=1, loss=0.306, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 477 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 477batches [01:15,  6.20batches/s, epoch=1, loss=0.212, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 478 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 478batches [01:15,  6.24batches/s, epoch=1, loss=0.098, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 479 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 479batches [01:15,  6.26batches/s, epoch=1, loss=0.225, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 480 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 480batches [01:16,  6.23batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 481 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 481batches [01:16,  6.21batches/s, epoch=1, loss=0.339, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 482 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 482batches [01:16,  6.25batches/s, epoch=1, loss=0.234, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 483 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 483batches [01:16,  6.25batches/s, epoch=1, loss=0.0836, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 484 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 484batches [01:16,  6.31batches/s, epoch=1, loss=0.154, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 485 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 485batches [01:16,  6.31batches/s, epoch=1, loss=0.119, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 486 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 486batches [01:16,  6.27batches/s, epoch=1, loss=0.0439, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 487 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 487batches [01:17,  6.26batches/s, epoch=1, loss=0.144, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 488 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 488batches [01:17,  6.27batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 489 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 489batches [01:17,  6.30batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 490 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 490batches [01:17,  6.32batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 491 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 491batches [01:17,  6.29batches/s, epoch=1, loss=0.226, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 492 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 492batches [01:17,  6.28batches/s, epoch=1, loss=0.0952, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 493 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 493batches [01:18,  6.28batches/s, epoch=1, loss=0.288, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 494 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 494batches [01:18,  6.28batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 495 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 495batches [01:18,  6.32batches/s, epoch=1, loss=0.394, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 496 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 496batches [01:18,  6.35batches/s, epoch=1, loss=0.268, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 497 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 497batches [01:18,  6.38batches/s, epoch=1, loss=0.19, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 498 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 498batches [01:18,  6.34batches/s, epoch=1, loss=0.278, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 499 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 499batches [01:19,  6.31batches/s, epoch=1, loss=0.21, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 500 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 500batches [01:19,  6.33batches/s, epoch=1, loss=0.0565, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 501 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 501batches [01:19,  6.32batches/s, epoch=1, loss=0.423, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 502 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 502batches [01:19,  6.32batches/s, epoch=1, loss=0.108, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 503 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 503batches [01:19,  6.29batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 504 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 504batches [01:19,  6.28batches/s, epoch=1, loss=0.162, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 505 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 505batches [01:19,  6.23batches/s, epoch=1, loss=0.332, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 506 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 506batches [01:20,  6.23batches/s, epoch=1, loss=0.246, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 507 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 507batches [01:20,  6.26batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 508 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 508batches [01:20,  6.26batches/s, epoch=1, loss=0.0791, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 509 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 509batches [01:20,  6.23batches/s, epoch=1, loss=0.135, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 510 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 510batches [01:20,  6.21batches/s, epoch=1, loss=0.201, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 511 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 511batches [01:20,  6.22batches/s, epoch=1, loss=0.233, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 512 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 512batches [01:21,  6.19batches/s, epoch=1, loss=0.234, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 513 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 513batches [01:21,  6.24batches/s, epoch=1, loss=0.213, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 514 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 514batches [01:21,  6.26batches/s, epoch=1, loss=0.256, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 515 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 515batches [01:21,  6.30batches/s, epoch=1, loss=0.214, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 516 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 516batches [01:21,  6.21batches/s, epoch=1, loss=0.16, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 517 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 517batches [01:21,  6.27batches/s, epoch=1, loss=0.328, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 518 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 518batches [01:22,  6.27batches/s, epoch=1, loss=0.259, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 519 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 519batches [01:22,  6.29batches/s, epoch=1, loss=0.274, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 520 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 520batches [01:22,  6.31batches/s, epoch=1, loss=0.162, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 521 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 521batches [01:22,  6.28batches/s, epoch=1, loss=0.058, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 522 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 522batches [01:22,  6.29batches/s, epoch=1, loss=0.438, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 523 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 523batches [01:22,  6.29batches/s, epoch=1, loss=0.183, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 524 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 524batches [01:23,  6.29batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 525 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 525batches [01:23,  6.27batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 526 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 526batches [01:23,  6.17batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 527 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 527batches [01:23,  6.21batches/s, epoch=1, loss=0.127, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 528 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 528batches [01:23,  6.26batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 529 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 529batches [01:23,  6.26batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 530 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 530batches [01:23,  6.27batches/s, epoch=1, loss=0.196, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 531 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 531batches [01:24,  6.28batches/s, epoch=1, loss=0.0802, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 532 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 532batches [01:24,  6.23batches/s, epoch=1, loss=0.242, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 533 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 533batches [01:24,  6.22batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 534 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 534batches [01:24,  6.23batches/s, epoch=1, loss=0.261, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 535 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 535batches [01:24,  6.20batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 536 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 536batches [01:24,  6.23batches/s, epoch=1, loss=0.288, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 537 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 537batches [01:25,  6.26batches/s, epoch=1, loss=0.101, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 538 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 538batches [01:25,  6.25batches/s, epoch=1, loss=0.355, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 539 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 539batches [01:25,  6.30batches/s, epoch=1, loss=0.0902, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 540 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 540batches [01:25,  6.30batches/s, epoch=1, loss=0.1, split=eval]   /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 541 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 541batches [01:25,  6.33batches/s, epoch=1, loss=0.371, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 542 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 542batches [01:25,  6.31batches/s, epoch=1, loss=0.0954, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 543 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 543batches [01:26,  6.28batches/s, epoch=1, loss=0.14, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 544 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 544batches [01:26,  6.28batches/s, epoch=1, loss=0.267, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 545 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 545batches [01:26,  6.24batches/s, epoch=1, loss=0.154, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 546 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 546batches [01:26,  6.29batches/s, epoch=1, loss=0.229, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 547 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 547batches [01:26,  6.32batches/s, epoch=1, loss=0.173, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 548 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 548batches [01:26,  6.34batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 549 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 549batches [01:27,  6.33batches/s, epoch=1, loss=0.275, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 550 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 550batches [01:27,  6.25batches/s, epoch=1, loss=0.117, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 551 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 551batches [01:27,  6.23batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 552 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 552batches [01:27,  6.16batches/s, epoch=1, loss=0.28, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 553 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 553batches [01:27,  6.22batches/s, epoch=1, loss=0.0766, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 554 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 554batches [01:27,  6.22batches/s, epoch=1, loss=0.201, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 555 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 555batches [01:27,  6.22batches/s, epoch=1, loss=0.278, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 556 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 556batches [01:28,  6.24batches/s, epoch=1, loss=0.166, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 557 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 557batches [01:28,  6.22batches/s, epoch=1, loss=0.168, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 558 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 558batches [01:28,  6.22batches/s, epoch=1, loss=0.339, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 559 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 559batches [01:28,  6.24batches/s, epoch=1, loss=0.0633, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 560 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 560batches [01:28,  6.21batches/s, epoch=1, loss=0.28, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 561 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 561batches [01:28,  6.27batches/s, epoch=1, loss=0.0967, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 562 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 562batches [01:29,  6.27batches/s, epoch=1, loss=0.0713, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 563 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 563batches [01:29,  6.27batches/s, epoch=1, loss=0.166, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 564 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 564batches [01:29,  6.26batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 565 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 565batches [01:29,  6.23batches/s, epoch=1, loss=0.212, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 566 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 566batches [01:29,  6.24batches/s, epoch=1, loss=0.121, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 567 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 567batches [01:29,  6.24batches/s, epoch=1, loss=0.147, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 568 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 568batches [01:30,  6.21batches/s, epoch=1, loss=0.115, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 569 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 569batches [01:30,  6.22batches/s, epoch=1, loss=0.401, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 570 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 570batches [01:30,  6.20batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 571 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 571batches [01:30,  6.20batches/s, epoch=1, loss=0.145, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 572 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 572batches [01:30,  6.16batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 573 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 573batches [01:30,  6.19batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 574 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 574batches [01:31,  6.22batches/s, epoch=1, loss=0.311, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 575 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 575batches [01:31,  6.22batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 576 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 576batches [01:31,  6.21batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 577 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 577batches [01:31,  6.20batches/s, epoch=1, loss=0.201, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 578 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 578batches [01:31,  6.22batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 579 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 579batches [01:31,  6.07batches/s, epoch=1, loss=0.329, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 580 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 580batches [01:32,  6.09batches/s, epoch=1, loss=0.108, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 581 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 581batches [01:32,  6.19batches/s, epoch=1, loss=0.29, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 582 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 582batches [01:32,  6.23batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 583 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 583batches [01:32,  6.19batches/s, epoch=1, loss=0.0613, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 584 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 584batches [01:32,  6.18batches/s, epoch=1, loss=0.173, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 585 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 585batches [01:32,  6.18batches/s, epoch=1, loss=0.0615, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 586 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 586batches [01:32,  6.25batches/s, epoch=1, loss=0.216, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 587 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 587batches [01:33,  6.30batches/s, epoch=1, loss=0.153, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 588 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 588batches [01:33,  6.28batches/s, epoch=1, loss=0.288, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 589 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 589batches [01:33,  6.26batches/s, epoch=1, loss=0.237, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 590 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 590batches [01:33,  6.26batches/s, epoch=1, loss=0.0896, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 591 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 591batches [01:33,  6.29batches/s, epoch=1, loss=0.177, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 592 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 592batches [01:33,  6.29batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 593 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 593batches [01:34,  6.32batches/s, epoch=1, loss=0.274, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 594 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 594batches [01:34,  6.29batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 595 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 595batches [01:34,  6.27batches/s, epoch=1, loss=0.219, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 596 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 596batches [01:34,  6.28batches/s, epoch=1, loss=0.15, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 597 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 597batches [01:34,  6.25batches/s, epoch=1, loss=0.402, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 598 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 598batches [01:34,  6.26batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 599 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 599batches [01:35,  6.26batches/s, epoch=1, loss=0.113, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 600 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 600batches [01:35,  6.25batches/s, epoch=1, loss=0.0863, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 601 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 601batches [01:35,  6.20batches/s, epoch=1, loss=0.21, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 602 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 602batches [01:35,  6.18batches/s, epoch=1, loss=0.219, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 603 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 603batches [01:35,  6.14batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 604 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 604batches [01:35,  6.25batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 605 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 605batches [01:36,  6.24batches/s, epoch=1, loss=0.208, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 606 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 606batches [01:36,  6.28batches/s, epoch=1, loss=0.261, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 607 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 607batches [01:36,  6.27batches/s, epoch=1, loss=0.372, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 608 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 608batches [01:36,  6.24batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 609 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 609batches [01:36,  6.31batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 610 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 610batches [01:36,  6.27batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 611 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 611batches [01:36,  6.23batches/s, epoch=1, loss=0.242, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 612 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 612batches [01:37,  6.26batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 613 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 613batches [01:37,  6.31batches/s, epoch=1, loss=0.0394, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 614 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 614batches [01:37,  6.36batches/s, epoch=1, loss=0.205, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 615 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 615batches [01:37,  6.38batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 616 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 616batches [01:37,  6.33batches/s, epoch=1, loss=0.142, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 617 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 617batches [01:37,  6.29batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 618 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 618batches [01:38,  6.26batches/s, epoch=1, loss=0.152, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 619 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 619batches [01:38,  6.29batches/s, epoch=1, loss=0.22, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 620 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 620batches [01:38,  6.25batches/s, epoch=1, loss=0.223, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 621 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 621batches [01:38,  6.24batches/s, epoch=1, loss=0.281, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 622 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 622batches [01:38,  6.23batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 623 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 623batches [01:38,  6.21batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 624 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 624batches [01:39,  6.24batches/s, epoch=1, loss=0.117, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 625 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 625batches [01:39,  6.31batches/s, epoch=1, loss=0.243, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 626 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 626batches [01:39,  6.24batches/s, epoch=1, loss=0.161, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 627 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 627batches [01:39,  6.21batches/s, epoch=1, loss=0.45, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 628 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 628batches [01:39,  6.25batches/s, epoch=1, loss=0.0419, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 629 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 629batches [01:39,  6.27batches/s, epoch=1, loss=0.285, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 630 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 630batches [01:39,  6.32batches/s, epoch=1, loss=0.0782, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 631 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 631batches [01:40,  6.31batches/s, epoch=1, loss=0.226, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 632 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 632batches [01:40,  6.26batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 633 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 633batches [01:40,  6.26batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 634 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 634batches [01:40,  6.26batches/s, epoch=1, loss=0.0942, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 635 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 635batches [01:40,  6.28batches/s, epoch=1, loss=0.0829, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 636 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 636batches [01:40,  6.27batches/s, epoch=1, loss=0.253, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 637 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 637batches [01:41,  6.37batches/s, epoch=1, loss=0.256, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 638 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 638batches [01:41,  6.37batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 639 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 639batches [01:41,  6.31batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 640 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 640batches [01:41,  6.31batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 641 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 641batches [01:41,  6.27batches/s, epoch=1, loss=0.453, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 642 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 642batches [01:41,  6.29batches/s, epoch=1, loss=0.0901, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 643 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 643batches [01:42,  6.29batches/s, epoch=1, loss=0.0583, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 644 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 644batches [01:42,  6.28batches/s, epoch=1, loss=0.595, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 645 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 645batches [01:42,  6.30batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 646 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 646batches [01:42,  6.27batches/s, epoch=1, loss=0.306, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 647 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 647batches [01:42,  6.32batches/s, epoch=1, loss=0.09, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 648 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 648batches [01:42,  6.30batches/s, epoch=1, loss=0.188, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 649 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 649batches [01:43,  6.32batches/s, epoch=1, loss=0.161, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 650 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 650batches [01:43,  6.32batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 651 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 651batches [01:43,  6.30batches/s, epoch=1, loss=0.152, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 652 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 652batches [01:43,  6.29batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 653 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 653batches [01:43,  6.24batches/s, epoch=1, loss=0.12, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 654 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 654batches [01:43,  6.29batches/s, epoch=1, loss=0.443, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 655 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 655batches [01:43,  6.26batches/s, epoch=1, loss=0.17, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 656 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 656batches [01:44,  6.28batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 657 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 657batches [01:44,  6.25batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 658 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 658batches [01:44,  6.27batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 659 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 659batches [01:44,  6.27batches/s, epoch=1, loss=0.207, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 660 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 660batches [01:44,  6.24batches/s, epoch=1, loss=0.305, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 661 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 661batches [01:44,  6.22batches/s, epoch=1, loss=0.189, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 662 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 662batches [01:45,  6.24batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 663 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 663batches [01:45,  6.25batches/s, epoch=1, loss=0.168, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 664 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 664batches [01:45,  6.24batches/s, epoch=1, loss=0.196, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 665 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 665batches [01:45,  6.22batches/s, epoch=1, loss=0.147, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 666 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 666batches [01:45,  6.25batches/s, epoch=1, loss=0.165, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 667 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 667batches [01:45,  6.27batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 668 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 668batches [01:46,  6.25batches/s, epoch=1, loss=0.326, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 669 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 669batches [01:46,  6.27batches/s, epoch=1, loss=0.499, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 670 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 670batches [01:46,  6.28batches/s, epoch=1, loss=0.143, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 671 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 671batches [01:46,  6.31batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 672 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 672batches [01:46,  6.33batches/s, epoch=1, loss=0.236, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 673 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 673batches [01:46,  6.28batches/s, epoch=1, loss=0.271, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 674 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 674batches [01:47,  6.26batches/s, epoch=1, loss=0.13, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 675 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 675batches [01:47,  6.28batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 676 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 676batches [01:47,  6.27batches/s, epoch=1, loss=0.239, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 677 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 677batches [01:47,  6.23batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 678 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 678batches [01:47,  6.21batches/s, epoch=1, loss=0.297, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 679 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 679batches [01:47,  6.21batches/s, epoch=1, loss=0.338, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 680 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 680batches [01:47,  6.18batches/s, epoch=1, loss=0.147, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 681 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 681batches [01:48,  6.22batches/s, epoch=1, loss=0.372, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 682 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 682batches [01:48,  6.24batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 683 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 683batches [01:48,  6.23batches/s, epoch=1, loss=0.0683, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 684 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 684batches [01:48,  6.18batches/s, epoch=1, loss=0.05, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 685 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 685batches [01:48,  6.18batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 686 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 686batches [01:48,  6.20batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 687 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 687batches [01:49,  6.21batches/s, epoch=1, loss=0.173, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 688 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 688batches [01:49,  6.20batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 689 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 689batches [01:49,  6.21batches/s, epoch=1, loss=0.282, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 690 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 690batches [01:49,  6.21batches/s, epoch=1, loss=0.2, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 691 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 691batches [01:49,  6.22batches/s, epoch=1, loss=0.246, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 692 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 692batches [01:49,  6.28batches/s, epoch=1, loss=0.348, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 693 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 693batches [01:50,  6.28batches/s, epoch=1, loss=0.128, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 694 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 694batches [01:50,  6.28batches/s, epoch=1, loss=0.291, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 695 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 695batches [01:50,  6.28batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 696 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 696batches [01:50,  6.29batches/s, epoch=1, loss=0.269, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 697 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 697batches [01:50,  6.33batches/s, epoch=1, loss=0.244, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 698 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 698batches [01:50,  6.26batches/s, epoch=1, loss=0.102, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 699 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 699batches [01:51,  6.27batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 700 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 700batches [01:51,  6.28batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 701 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 701batches [01:51,  6.27batches/s, epoch=1, loss=0.145, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 702 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 702batches [01:51,  6.27batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 703 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 703batches [01:51,  6.26batches/s, epoch=1, loss=0.183, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 704 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 704batches [01:51,  6.23batches/s, epoch=1, loss=0.471, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 705 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 705batches [01:51,  6.22batches/s, epoch=1, loss=0.081, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 706 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 706batches [01:52,  6.23batches/s, epoch=1, loss=0.116, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 707 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 707batches [01:52,  6.25batches/s, epoch=1, loss=0.209, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 708 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 708batches [01:52,  6.31batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 709 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 709batches [01:52,  6.34batches/s, epoch=1, loss=0.07, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 710 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 710batches [01:52,  6.24batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 711 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 711batches [01:52,  6.27batches/s, epoch=1, loss=0.145, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 712 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 712batches [01:53,  6.27batches/s, epoch=1, loss=0.201, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 713 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 713batches [01:53,  6.27batches/s, epoch=1, loss=0.227, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 714 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 714batches [01:53,  6.29batches/s, epoch=1, loss=0.0217, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 715 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 715batches [01:53,  6.29batches/s, epoch=1, loss=0.148, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 716 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 716batches [01:53,  6.26batches/s, epoch=1, loss=0.079, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 717 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 717batches [01:53,  6.25batches/s, epoch=1, loss=0.115, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 718 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 718batches [01:54,  6.27batches/s, epoch=1, loss=0.103, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 719 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 719batches [01:54,  6.31batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 720 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 720batches [01:54,  6.37batches/s, epoch=1, loss=0.169, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 721 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 721batches [01:54,  6.33batches/s, epoch=1, loss=0.305, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 722 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 722batches [01:54,  6.24batches/s, epoch=1, loss=0.161, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 723 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 723batches [01:54,  6.25batches/s, epoch=1, loss=0.142, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 724 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 724batches [01:55,  6.25batches/s, epoch=1, loss=0.261, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 725 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 725batches [01:55,  6.25batches/s, epoch=1, loss=0.128, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 726 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 726batches [01:55,  6.28batches/s, epoch=1, loss=0.236, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 727 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 727batches [01:55,  6.26batches/s, epoch=1, loss=0.479, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 728 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 728batches [01:55,  6.24batches/s, epoch=1, loss=0.191, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 729 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 729batches [01:55,  6.23batches/s, epoch=1, loss=0.154, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 730 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 730batches [01:55,  6.25batches/s, epoch=1, loss=0.368, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 731 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 731batches [01:56,  6.29batches/s, epoch=1, loss=0.142, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 732 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 732batches [01:56,  6.28batches/s, epoch=1, loss=0.0466, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 733 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 733batches [01:56,  6.28batches/s, epoch=1, loss=0.348, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 734 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 734batches [01:56,  6.28batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 735 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 735batches [01:56,  6.26batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 736 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 736batches [01:56,  6.29batches/s, epoch=1, loss=0.322, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 737 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 737batches [01:57,  6.29batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 738 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 738batches [01:57,  6.32batches/s, epoch=1, loss=0.127, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 739 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 739batches [01:57,  6.23batches/s, epoch=1, loss=0.234, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 740 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 740batches [01:57,  6.23batches/s, epoch=1, loss=0.0366, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 741 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 741batches [01:57,  6.30batches/s, epoch=1, loss=0.131, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 742 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 742batches [01:57,  6.31batches/s, epoch=1, loss=0.292, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 743 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 743batches [01:58,  6.31batches/s, epoch=1, loss=0.284, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 744 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 744batches [01:58,  6.31batches/s, epoch=1, loss=0.24, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 745 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 745batches [01:58,  6.29batches/s, epoch=1, loss=0.21, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 746 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 746batches [01:58,  6.24batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 747 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 747batches [01:58,  6.27batches/s, epoch=1, loss=0.0414, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 748 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 748batches [01:58,  6.28batches/s, epoch=1, loss=0.146, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 749 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 749batches [01:58,  6.30batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 750 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 750batches [01:59,  6.34batches/s, epoch=1, loss=0.153, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 751 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 751batches [01:59,  6.27batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 752 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 752batches [01:59,  6.29batches/s, epoch=1, loss=0.211, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 753 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 753batches [01:59,  6.29batches/s, epoch=1, loss=0.253, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 754 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 754batches [01:59,  6.33batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 755 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 755batches [01:59,  6.34batches/s, epoch=1, loss=0.0978, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 756 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 756batches [02:00,  6.31batches/s, epoch=1, loss=0.217, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 757 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 757batches [02:00,  6.32batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 758 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 758batches [02:00,  6.30batches/s, epoch=1, loss=0.258, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 759 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 759batches [02:00,  6.32batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 760 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 760batches [02:00,  6.31batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 761 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 761batches [02:00,  6.31batches/s, epoch=1, loss=0.324, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 762 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 762batches [02:01,  6.26batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 763 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 763batches [02:01,  6.27batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 764 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 764batches [02:01,  6.26batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 765 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 765batches [02:01,  6.24batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 766 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 766batches [02:01,  6.25batches/s, epoch=1, loss=0.109, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 767 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 767batches [02:01,  6.23batches/s, epoch=1, loss=0.235, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 768 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 768batches [02:02,  6.13batches/s, epoch=1, loss=0.434, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 769 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 769batches [02:02,  6.16batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 770 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 770batches [02:02,  6.19batches/s, epoch=1, loss=0.329, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 771 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 771batches [02:02,  6.20batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 772 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 772batches [02:02,  6.23batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 773 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 773batches [02:02,  6.22batches/s, epoch=1, loss=0.265, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 774 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 774batches [02:02,  6.25batches/s, epoch=1, loss=0.357, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 775 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 775batches [02:03,  6.19batches/s, epoch=1, loss=0.094, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 776 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 776batches [02:03,  6.21batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 777 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 777batches [02:03,  6.20batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 778 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 778batches [02:03,  6.21batches/s, epoch=1, loss=0.379, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 779 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 779batches [02:03,  6.23batches/s, epoch=1, loss=0.11, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 780 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 780batches [02:03,  6.27batches/s, epoch=1, loss=0.141, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 781 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 781batches [02:04,  6.29batches/s, epoch=1, loss=0.0885, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 782 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 782batches [02:04,  6.29batches/s, epoch=1, loss=0.127, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 783 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 783batches [02:04,  6.21batches/s, epoch=1, loss=0.302, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 784 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 784batches [02:04,  6.21batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 785 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 785batches [02:04,  6.23batches/s, epoch=1, loss=0.335, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 786 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 786batches [02:04,  6.25batches/s, epoch=1, loss=0.224, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 787 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 787batches [02:05,  6.26batches/s, epoch=1, loss=0.209, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 788 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 788batches [02:05,  6.22batches/s, epoch=1, loss=0.217, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 789 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 789batches [02:05,  6.19batches/s, epoch=1, loss=0.373, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 790 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 790batches [02:05,  6.20batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 791 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 791batches [02:05,  6.18batches/s, epoch=1, loss=0.245, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 792 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 792batches [02:05,  6.18batches/s, epoch=1, loss=0.0595, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 793 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 793batches [02:06,  6.19batches/s, epoch=1, loss=0.132, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 794 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 794batches [02:06,  6.16batches/s, epoch=1, loss=0.115, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 795 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 795batches [02:06,  6.19batches/s, epoch=1, loss=0.224, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 796 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 796batches [02:06,  6.19batches/s, epoch=1, loss=0.304, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 797 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 797batches [02:06,  6.20batches/s, epoch=1, loss=0.0525, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 798 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 798batches [02:06,  6.21batches/s, epoch=1, loss=0.325, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 799 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 799batches [02:07,  6.26batches/s, epoch=1, loss=0.0254, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 800 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 800batches [02:07,  6.28batches/s, epoch=1, loss=0.304, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 801 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 801batches [02:07,  6.29batches/s, epoch=1, loss=0.427, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 802 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 802batches [02:07,  6.30batches/s, epoch=1, loss=0.122, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 803 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 803batches [02:07,  6.28batches/s, epoch=1, loss=0.148, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 804 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 804batches [02:07,  6.29batches/s, epoch=1, loss=0.0967, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 805 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 805batches [02:07,  6.32batches/s, epoch=1, loss=0.171, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 806 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 806batches [02:08,  6.29batches/s, epoch=1, loss=0.304, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 807 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 807batches [02:08,  6.29batches/s, epoch=1, loss=0.393, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 808 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 808batches [02:08,  6.27batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 809 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 809batches [02:08,  6.24batches/s, epoch=1, loss=0.263, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 810 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 810batches [02:08,  6.17batches/s, epoch=1, loss=0.101, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 811 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 811batches [02:08,  6.22batches/s, epoch=1, loss=0.32, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 812 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 812batches [02:09,  6.22batches/s, epoch=1, loss=0.303, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 813 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 813batches [02:09,  6.14batches/s, epoch=1, loss=0.172, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 814 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 814batches [02:09,  6.14batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 815 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 815batches [02:09,  6.20batches/s, epoch=1, loss=0.445, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 816 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 816batches [02:09,  6.26batches/s, epoch=1, loss=0.336, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 817 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 817batches [02:09,  6.24batches/s, epoch=1, loss=0.29, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 818 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 818batches [02:10,  6.23batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 819 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 819batches [02:10,  6.26batches/s, epoch=1, loss=0.372, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 820 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 820batches [02:10,  6.21batches/s, epoch=1, loss=0.0639, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 821 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 821batches [02:10,  6.24batches/s, epoch=1, loss=0.125, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 822 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 822batches [02:10,  6.31batches/s, epoch=1, loss=0.331, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 823 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 823batches [02:10,  6.26batches/s, epoch=1, loss=0.114, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 824 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 824batches [02:11,  6.24batches/s, epoch=1, loss=0.0758, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 825 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 825batches [02:11,  6.26batches/s, epoch=1, loss=0.238, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 826 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 826batches [02:11,  6.21batches/s, epoch=1, loss=0.152, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 827 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 827batches [02:11,  6.27batches/s, epoch=1, loss=0.183, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 828 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 828batches [02:11,  6.26batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 829 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 829batches [02:11,  6.25batches/s, epoch=1, loss=0.336, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 830 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 830batches [02:11,  6.26batches/s, epoch=1, loss=0.172, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 831 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 831batches [02:12,  6.27batches/s, epoch=1, loss=0.24, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 832 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 832batches [02:12,  6.26batches/s, epoch=1, loss=0.0609, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 833 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 833batches [02:12,  6.27batches/s, epoch=1, loss=0.315, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 834 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 834batches [02:12,  6.25batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 835 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 835batches [02:12,  6.18batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 836 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 836batches [02:12,  6.14batches/s, epoch=1, loss=0.142, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 837 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 837batches [02:13,  6.20batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 838 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 838batches [02:13,  6.20batches/s, epoch=1, loss=0.183, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 839 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 839batches [02:13,  6.12batches/s, epoch=1, loss=0.225, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 840 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 840batches [02:13,  6.18batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 841 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 841batches [02:13,  6.16batches/s, epoch=1, loss=0.289, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 842 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 842batches [02:13,  6.21batches/s, epoch=1, loss=0.236, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 843 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 843batches [02:14,  6.21batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 844 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 844batches [02:14,  6.24batches/s, epoch=1, loss=0.295, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 845 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 845batches [02:14,  6.24batches/s, epoch=1, loss=0.225, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 846 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 846batches [02:14,  6.27batches/s, epoch=1, loss=0.356, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 847 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 847batches [02:14,  6.32batches/s, epoch=1, loss=0.0967, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 848 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 848batches [02:14,  6.25batches/s, epoch=1, loss=0.221, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 849 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 849batches [02:15,  6.27batches/s, epoch=1, loss=0.181, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 850 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 850batches [02:15,  6.29batches/s, epoch=1, loss=0.191, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 851 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 851batches [02:15,  6.25batches/s, epoch=1, loss=0.083, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 852 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 852batches [02:15,  6.26batches/s, epoch=1, loss=0.222, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 853 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 853batches [02:15,  6.29batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 854 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 854batches [02:15,  6.23batches/s, epoch=1, loss=0.0851, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 855 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 855batches [02:15,  6.29batches/s, epoch=1, loss=0.344, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 856 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 856batches [02:16,  6.27batches/s, epoch=1, loss=0.12, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 857 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 857batches [02:16,  6.26batches/s, epoch=1, loss=0.308, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 858 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 858batches [02:16,  6.23batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 859 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 859batches [02:16,  6.24batches/s, epoch=1, loss=0.298, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 860 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 860batches [02:16,  6.19batches/s, epoch=1, loss=0.262, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 861 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 861batches [02:16,  6.24batches/s, epoch=1, loss=0.196, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 862 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 862batches [02:17,  6.26batches/s, epoch=1, loss=0.211, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 863 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 863batches [02:17,  6.31batches/s, epoch=1, loss=0.0809, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 864 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 864batches [02:17,  6.27batches/s, epoch=1, loss=0.0749, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 865 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 865batches [02:17,  6.18batches/s, epoch=1, loss=0.276, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 866 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 866batches [02:17,  6.23batches/s, epoch=1, loss=0.162, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 867 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 867batches [02:17,  6.27batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 868 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 868batches [02:18,  6.30batches/s, epoch=1, loss=0.358, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 869 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 869batches [02:18,  6.31batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 870 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 870batches [02:18,  6.25batches/s, epoch=1, loss=0.153, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 871 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 871batches [02:18,  6.25batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 872 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 872batches [02:18,  6.28batches/s, epoch=1, loss=0.0928, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 873 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 873batches [02:18,  6.25batches/s, epoch=1, loss=0.104, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 874 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 874batches [02:19,  6.31batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 875 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 875batches [02:19,  6.31batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 876 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 876batches [02:19,  6.30batches/s, epoch=1, loss=0.101, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 877 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 877batches [02:19,  6.27batches/s, epoch=1, loss=0.251, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 878 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 878batches [02:19,  6.25batches/s, epoch=1, loss=0.226, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 879 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 879batches [02:19,  6.26batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 880 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 880batches [02:19,  6.23batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 881 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 881batches [02:20,  6.23batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 882 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 882batches [02:20,  6.20batches/s, epoch=1, loss=0.0577, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 883 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 883batches [02:20,  6.21batches/s, epoch=1, loss=0.385, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 884 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 884batches [02:20,  6.22batches/s, epoch=1, loss=0.191, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 885 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 885batches [02:20,  6.20batches/s, epoch=1, loss=0.138, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 886 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 886batches [02:20,  6.22batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 887 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 887batches [02:21,  6.18batches/s, epoch=1, loss=0.263, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 888 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 888batches [02:21,  6.15batches/s, epoch=1, loss=0.0701, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 889 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 889batches [02:21,  6.25batches/s, epoch=1, loss=0.171, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 890 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 890batches [02:21,  6.23batches/s, epoch=1, loss=0.138, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 891 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 891batches [02:21,  6.23batches/s, epoch=1, loss=0.281, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 892 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 892batches [02:21,  6.22batches/s, epoch=1, loss=0.172, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 893 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 893batches [02:22,  6.24batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 894 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 894batches [02:22,  6.28batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 895 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 895batches [02:22,  6.34batches/s, epoch=1, loss=0.0578, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 896 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 896batches [02:22,  6.32batches/s, epoch=1, loss=0.174, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 897 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 897batches [02:22,  6.24batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 898 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 898batches [02:22,  6.23batches/s, epoch=1, loss=0.135, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 899 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 899batches [02:23,  6.25batches/s, epoch=1, loss=0.246, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 900 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 900batches [02:23,  6.23batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 901 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 901batches [02:23,  6.26batches/s, epoch=1, loss=0.259, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 902 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 902batches [02:23,  6.16batches/s, epoch=1, loss=0.195, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 903 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 903batches [02:23,  6.17batches/s, epoch=1, loss=0.0819, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 904 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 904batches [02:23,  6.15batches/s, epoch=1, loss=0.13, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 905 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 905batches [02:23,  6.13batches/s, epoch=1, loss=0.278, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 906 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 906batches [02:24,  6.20batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 907 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 907batches [02:24,  6.21batches/s, epoch=1, loss=0.361, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 908 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 908batches [02:24,  6.17batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 909 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 909batches [02:24,  6.19batches/s, epoch=1, loss=0.0898, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 910 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 910batches [02:24,  6.18batches/s, epoch=1, loss=0.144, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 911 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 911batches [02:24,  6.20batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 912 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 912batches [02:25,  6.24batches/s, epoch=1, loss=0.288, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 913 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 913batches [02:25,  6.22batches/s, epoch=1, loss=0.11, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 914 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 914batches [02:25,  6.26batches/s, epoch=1, loss=0.407, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 915 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 915batches [02:25,  6.23batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 916 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 916batches [02:25,  6.24batches/s, epoch=1, loss=0.447, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 917 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 917batches [02:25,  6.25batches/s, epoch=1, loss=0.0914, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 918 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 918batches [02:26,  6.28batches/s, epoch=1, loss=0.0859, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 919 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 919batches [02:26,  6.33batches/s, epoch=1, loss=0.194, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 920 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 920batches [02:26,  6.27batches/s, epoch=1, loss=0.36, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 921 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 921batches [02:26,  6.26batches/s, epoch=1, loss=0.0866, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 922 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 922batches [02:26,  6.22batches/s, epoch=1, loss=0.171, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 923 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 923batches [02:26,  6.23batches/s, epoch=1, loss=0.269, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 924 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 924batches [02:27,  6.25batches/s, epoch=1, loss=0.239, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 925 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 925batches [02:27,  6.27batches/s, epoch=1, loss=0.117, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 926 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 926batches [02:27,  6.29batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 927 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 927batches [02:27,  6.26batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 928 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 928batches [02:27,  6.24batches/s, epoch=1, loss=0.241, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 929 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 929batches [02:27,  6.23batches/s, epoch=1, loss=0.302, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 930 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 930batches [02:27,  6.30batches/s, epoch=1, loss=0.121, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 931 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 931batches [02:28,  6.30batches/s, epoch=1, loss=0.116, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 932 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 932batches [02:28,  6.25batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 933 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 933batches [02:28,  6.28batches/s, epoch=1, loss=0.226, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 934 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 934batches [02:28,  6.28batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 935 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 935batches [02:28,  6.28batches/s, epoch=1, loss=0.249, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 936 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 936batches [02:28,  6.28batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 937 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 937batches [02:29,  6.25batches/s, epoch=1, loss=0.0868, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 938 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 938batches [02:29,  6.21batches/s, epoch=1, loss=0.114, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 939 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 939batches [02:29,  6.22batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 940 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 940batches [02:29,  6.27batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 941 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 941batches [02:29,  6.27batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 942 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 942batches [02:29,  6.27batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 943 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 943batches [02:30,  6.26batches/s, epoch=1, loss=0.21, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 944 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 944batches [02:30,  6.25batches/s, epoch=1, loss=0.0364, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 945 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 945batches [02:30,  6.23batches/s, epoch=1, loss=0.264, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 946 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 946batches [02:30,  6.09batches/s, epoch=1, loss=0.166, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 947 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 947batches [02:30,  6.16batches/s, epoch=1, loss=0.103, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 948 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 948batches [02:30,  6.24batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 949 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 949batches [02:31,  6.24batches/s, epoch=1, loss=0.245, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 950 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 950batches [02:31,  6.22batches/s, epoch=1, loss=0.142, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 951 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 951batches [02:31,  6.22batches/s, epoch=1, loss=0.289, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 952 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 952batches [02:31,  6.23batches/s, epoch=1, loss=0.168, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 953 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 953batches [02:31,  6.24batches/s, epoch=1, loss=0.165, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 954 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 954batches [02:31,  6.21batches/s, epoch=1, loss=0.191, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 955 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 955batches [02:31,  6.29batches/s, epoch=1, loss=0.321, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 956 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 956batches [02:32,  6.30batches/s, epoch=1, loss=0.318, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 957 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 957batches [02:32,  6.29batches/s, epoch=1, loss=0.211, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 958 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 958batches [02:32,  6.28batches/s, epoch=1, loss=0.166, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 959 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 959batches [02:32,  6.26batches/s, epoch=1, loss=0.277, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 960 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 960batches [02:32,  6.26batches/s, epoch=1, loss=0.0792, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 961 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 961batches [02:32,  6.29batches/s, epoch=1, loss=0.11, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 962 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 962batches [02:33,  6.36batches/s, epoch=1, loss=0.11, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 963 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 963batches [02:33,  6.32batches/s, epoch=1, loss=0.324, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 964 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 964batches [02:33,  6.29batches/s, epoch=1, loss=0.269, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 965 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 965batches [02:33,  6.30batches/s, epoch=1, loss=0.0955, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 966 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 966batches [02:33,  6.30batches/s, epoch=1, loss=0.0761, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 967 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 967batches [02:33,  6.30batches/s, epoch=1, loss=0.331, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 968 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 968batches [02:34,  6.28batches/s, epoch=1, loss=0.296, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 969 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 969batches [02:34,  6.28batches/s, epoch=1, loss=0.13, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 970 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 970batches [02:34,  6.25batches/s, epoch=1, loss=0.173, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 971 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 971batches [02:34,  6.22batches/s, epoch=1, loss=0.159, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 972 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 972batches [02:34,  6.23batches/s, epoch=1, loss=0.166, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 973 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 973batches [02:34,  6.25batches/s, epoch=1, loss=0.162, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 974 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 974batches [02:35,  6.29batches/s, epoch=1, loss=0.203, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 975 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 975batches [02:35,  6.30batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 976 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 976batches [02:35,  6.27batches/s, epoch=1, loss=0.303, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 977 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 977batches [02:35,  6.26batches/s, epoch=1, loss=0.16, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 978 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 978batches [02:35,  6.28batches/s, epoch=1, loss=0.342, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 979 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 979batches [02:35,  6.24batches/s, epoch=1, loss=0.143, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 980 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 980batches [02:35,  6.28batches/s, epoch=1, loss=0.196, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 981 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 981batches [02:36,  6.26batches/s, epoch=1, loss=0.0576, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 982 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 982batches [02:36,  6.23batches/s, epoch=1, loss=0.218, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 983 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 983batches [02:36,  6.24batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 984 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 984batches [02:36,  6.27batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 985 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 985batches [02:36,  6.33batches/s, epoch=1, loss=0.313, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 986 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 986batches [02:36,  6.30batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 987 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 987batches [02:37,  6.29batches/s, epoch=1, loss=0.283, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 988 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 988batches [02:37,  6.29batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 989 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 989batches [02:37,  6.29batches/s, epoch=1, loss=0.26, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 990 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 990batches [02:37,  6.21batches/s, epoch=1, loss=0.252, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 991 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 991batches [02:37,  6.21batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 992 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 992batches [02:37,  6.23batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 993 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 993batches [02:38,  6.22batches/s, epoch=1, loss=0.138, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 994 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 994batches [02:38,  6.24batches/s, epoch=1, loss=0.198, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 995 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 995batches [02:38,  6.21batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 996 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 996batches [02:38,  6.26batches/s, epoch=1, loss=0.199, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 997 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 997batches [02:38,  6.30batches/s, epoch=1, loss=0.0909, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 998 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 998batches [02:38,  6.26batches/s, epoch=1, loss=0.136, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 999 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 999batches [02:39,  6.29batches/s, epoch=1, loss=0.439, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1000 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1000batches [02:39,  6.27batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1001 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1001batches [02:39,  6.29batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1002 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1002batches [02:39,  6.31batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1003 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1003batches [02:39,  6.26batches/s, epoch=1, loss=0.192, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1004 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1004batches [02:39,  6.29batches/s, epoch=1, loss=0.197, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1005 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1005batches [02:39,  6.26batches/s, epoch=1, loss=0.323, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1006 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1006batches [02:40,  6.26batches/s, epoch=1, loss=0.182, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1007 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1007batches [02:40,  6.27batches/s, epoch=1, loss=0.128, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1008 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1008batches [02:40,  6.27batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1009 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1009batches [02:40,  6.26batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1010 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1010batches [02:40,  6.22batches/s, epoch=1, loss=0.195, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1011 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1011batches [02:40,  6.21batches/s, epoch=1, loss=0.11, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1012 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1012batches [02:41,  6.21batches/s, epoch=1, loss=0.0788, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1013 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1013batches [02:41,  6.23batches/s, epoch=1, loss=0.137, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1014 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1014batches [02:41,  6.25batches/s, epoch=1, loss=0.182, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1015 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1015batches [02:41,  6.20batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1016 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1016batches [02:41,  6.24batches/s, epoch=1, loss=0.121, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1017 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1017batches [02:41,  6.24batches/s, epoch=1, loss=0.195, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1018 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1018batches [02:42,  6.29batches/s, epoch=1, loss=0.121, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1019 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1019batches [02:42,  6.30batches/s, epoch=1, loss=0.109, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1020 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1020batches [02:42,  6.23batches/s, epoch=1, loss=0.0908, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1021 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1021batches [02:42,  6.23batches/s, epoch=1, loss=0.114, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1022 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1022batches [02:42,  6.27batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1023 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1023batches [02:42,  6.32batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1024 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1024batches [02:43,  6.32batches/s, epoch=1, loss=0.172, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1025 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1025batches [02:43,  6.32batches/s, epoch=1, loss=0.0694, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1026 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1026batches [02:43,  6.31batches/s, epoch=1, loss=0.217, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1027 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1027batches [02:43,  6.28batches/s, epoch=1, loss=0.31, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1028 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1028batches [02:43,  6.28batches/s, epoch=1, loss=0.455, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1029 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1029batches [02:43,  6.26batches/s, epoch=1, loss=0.0987, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1030 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1030batches [02:43,  6.27batches/s, epoch=1, loss=0.146, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1031 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1031batches [02:44,  6.28batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1032 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1032batches [02:44,  6.23batches/s, epoch=1, loss=0.206, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1033 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1033batches [02:44,  6.22batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1034 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1034batches [02:44,  6.21batches/s, epoch=1, loss=0.238, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1035 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1035batches [02:44,  6.17batches/s, epoch=1, loss=0.254, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1036 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1036batches [02:44,  6.20batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1037 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1037batches [02:45,  6.22batches/s, epoch=1, loss=0.136, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1038 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1038batches [02:45,  6.29batches/s, epoch=1, loss=0.248, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1039 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1039batches [02:45,  6.29batches/s, epoch=1, loss=0.291, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1040 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1040batches [02:45,  6.31batches/s, epoch=1, loss=0.0937, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1041 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1041batches [02:45,  6.31batches/s, epoch=1, loss=0.146, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1042 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1042batches [02:45,  6.25batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1043 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1043batches [02:46,  6.27batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1044 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1044batches [02:46,  6.29batches/s, epoch=1, loss=0.407, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1045 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1045batches [02:46,  6.26batches/s, epoch=1, loss=0.0977, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1046 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1046batches [02:46,  6.29batches/s, epoch=1, loss=0.207, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1047 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1047batches [02:46,  6.30batches/s, epoch=1, loss=0.384, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1048 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1048batches [02:46,  6.28batches/s, epoch=1, loss=0.135, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1049 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1049batches [02:46,  6.29batches/s, epoch=1, loss=0.248, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1050 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1050batches [02:47,  6.30batches/s, epoch=1, loss=0.0799, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1051 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1051batches [02:47,  6.29batches/s, epoch=1, loss=0.389, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1052 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1052batches [02:47,  6.26batches/s, epoch=1, loss=0.283, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1053 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1053batches [02:47,  6.24batches/s, epoch=1, loss=0.224, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1054 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1054batches [02:47,  6.25batches/s, epoch=1, loss=0.201, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1055 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1055batches [02:47,  6.26batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1056 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1056batches [02:48,  6.26batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1057 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1057batches [02:48,  6.25batches/s, epoch=1, loss=0.236, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1058 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1058batches [02:48,  6.26batches/s, epoch=1, loss=0.0894, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1059 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1059batches [02:48,  6.23batches/s, epoch=1, loss=0.269, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1060 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1060batches [02:48,  6.25batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1061 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1061batches [02:48,  6.22batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1062 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1062batches [02:49,  6.25batches/s, epoch=1, loss=0.296, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1063 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1063batches [02:49,  6.27batches/s, epoch=1, loss=0.279, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1064 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1064batches [02:49,  6.21batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1065 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1065batches [02:49,  6.23batches/s, epoch=1, loss=0.04, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1066 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1066batches [02:49,  6.30batches/s, epoch=1, loss=0.254, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1067 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1067batches [02:49,  6.34batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1068 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1068batches [02:50,  6.30batches/s, epoch=1, loss=0.203, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1069 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1069batches [02:50,  6.25batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1070 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1070batches [02:50,  6.25batches/s, epoch=1, loss=0.317, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1071 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1071batches [02:50,  6.28batches/s, epoch=1, loss=0.072, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1072 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1072batches [02:50,  6.29batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1073 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1073batches [02:50,  6.22batches/s, epoch=1, loss=0.0716, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1074 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1074batches [02:50,  6.18batches/s, epoch=1, loss=0.0677, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1075 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1075batches [02:51,  6.21batches/s, epoch=1, loss=0.302, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1076 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1076batches [02:51,  6.20batches/s, epoch=1, loss=0.0578, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1077 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1077batches [02:51,  6.22batches/s, epoch=1, loss=0.185, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1078 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1078batches [02:51,  6.23batches/s, epoch=1, loss=0.117, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1079 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1079batches [02:51,  6.23batches/s, epoch=1, loss=0.298, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1080 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1080batches [02:51,  6.22batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1081 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1081batches [02:52,  6.21batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1082 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1082batches [02:52,  6.24batches/s, epoch=1, loss=0.303, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1083 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1083batches [02:52,  6.23batches/s, epoch=1, loss=0.219, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1084 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1084batches [02:52,  6.24batches/s, epoch=1, loss=0.15, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1085 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1085batches [02:52,  6.17batches/s, epoch=1, loss=0.104, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1086 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1086batches [02:52,  6.22batches/s, epoch=1, loss=0.082, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1087 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1087batches [02:53,  6.25batches/s, epoch=1, loss=0.0657, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1088 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1088batches [02:53,  6.25batches/s, epoch=1, loss=0.139, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1089 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1089batches [02:53,  6.16batches/s, epoch=1, loss=0.149, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1090 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1090batches [02:53,  6.23batches/s, epoch=1, loss=0.195, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1091 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1091batches [02:53,  6.28batches/s, epoch=1, loss=0.0737, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1092 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1092batches [02:53,  6.22batches/s, epoch=1, loss=0.326, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1093 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1093batches [02:54,  6.31batches/s, epoch=1, loss=0.203, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1094 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1094batches [02:54,  6.36batches/s, epoch=1, loss=0.0831, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1095 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1095batches [02:54,  6.32batches/s, epoch=1, loss=0.163, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1096 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1096batches [02:54,  6.31batches/s, epoch=1, loss=0.203, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1097 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1097batches [02:54,  6.30batches/s, epoch=1, loss=0.271, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1098 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1098batches [02:54,  6.27batches/s, epoch=1, loss=0.158, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1099 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1099batches [02:54,  6.28batches/s, epoch=1, loss=0.206, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1100 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1100batches [02:55,  6.29batches/s, epoch=1, loss=0.19, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1101 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1101batches [02:55,  6.25batches/s, epoch=1, loss=0.0342, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1102 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1102batches [02:55,  6.22batches/s, epoch=1, loss=0.118, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1103 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1103batches [02:55,  6.22batches/s, epoch=1, loss=0.327, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1104 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1104batches [02:55,  6.30batches/s, epoch=1, loss=0.142, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1105 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1105batches [02:55,  6.27batches/s, epoch=1, loss=0.297, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1106 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1106batches [02:56,  6.25batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1107 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1107batches [02:56,  6.29batches/s, epoch=1, loss=0.371, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1108 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1108batches [02:56,  6.27batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1109 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1109batches [02:56,  6.31batches/s, epoch=1, loss=0.302, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1110 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1110batches [02:56,  6.32batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1111 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1111batches [02:56,  6.32batches/s, epoch=1, loss=0.088, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1112 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1112batches [02:57,  6.29batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1113 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1113batches [02:57,  6.25batches/s, epoch=1, loss=0.214, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1114 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1114batches [02:57,  6.25batches/s, epoch=1, loss=0.165, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1115 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1115batches [02:57,  6.25batches/s, epoch=1, loss=0.102, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1116 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1116batches [02:57,  6.27batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1117 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1117batches [02:57,  6.23batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1118 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1118batches [02:58,  6.17batches/s, epoch=1, loss=0.283, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1119 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1119batches [02:58,  6.20batches/s, epoch=1, loss=0.154, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1120 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1120batches [02:58,  6.17batches/s, epoch=1, loss=0.122, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1121 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1121batches [02:58,  6.14batches/s, epoch=1, loss=0.0989, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1122 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1122batches [02:58,  6.18batches/s, epoch=1, loss=0.148, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1123 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1123batches [02:58,  6.15batches/s, epoch=1, loss=0.0863, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1124 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1124batches [02:59,  6.18batches/s, epoch=1, loss=0.308, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1125 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1125batches [02:59,  6.23batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1126 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1126batches [02:59,  6.24batches/s, epoch=1, loss=0.1, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1127 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1127batches [02:59,  6.24batches/s, epoch=1, loss=0.461, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1128 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1128batches [02:59,  6.21batches/s, epoch=1, loss=0.263, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1129 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1129batches [02:59,  6.25batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1130 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1130batches [02:59,  6.29batches/s, epoch=1, loss=0.212, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1131 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1131batches [03:00,  6.31batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1132 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1132batches [03:00,  6.33batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1133 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1133batches [03:00,  6.26batches/s, epoch=1, loss=0.213, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1134 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1134batches [03:00,  6.26batches/s, epoch=1, loss=0.286, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1135 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1135batches [03:00,  6.26batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1136 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1136batches [03:00,  6.24batches/s, epoch=1, loss=0.0849, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1137 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1137batches [03:01,  6.28batches/s, epoch=1, loss=0.17, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1138 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1138batches [03:01,  6.20batches/s, epoch=1, loss=0.362, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1139 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1139batches [03:01,  6.21batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1140 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1140batches [03:01,  6.17batches/s, epoch=1, loss=0.503, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1141 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1141batches [03:01,  6.18batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1142 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1142batches [03:01,  6.21batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1143 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1143batches [03:02,  6.21batches/s, epoch=1, loss=0.166, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1144 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1144batches [03:02,  6.21batches/s, epoch=1, loss=0.0831, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1145 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1145batches [03:02,  6.19batches/s, epoch=1, loss=0.19, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1146 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1146batches [03:02,  6.28batches/s, epoch=1, loss=0.209, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1147 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1147batches [03:02,  6.23batches/s, epoch=1, loss=0.0613, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1148 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1148batches [03:02,  6.18batches/s, epoch=1, loss=0.213, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1149 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1149batches [03:03,  6.24batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1150 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1150batches [03:03,  6.24batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1151 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1151batches [03:03,  6.31batches/s, epoch=1, loss=0.274, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1152 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1152batches [03:03,  6.30batches/s, epoch=1, loss=0.16, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1153 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1153batches [03:03,  6.20batches/s, epoch=1, loss=0.313, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1154 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1154batches [03:03,  6.24batches/s, epoch=1, loss=0.278, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1155 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1155batches [03:03,  6.25batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1156 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1156batches [03:04,  6.27batches/s, epoch=1, loss=0.108, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1157 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1157batches [03:04,  6.33batches/s, epoch=1, loss=0.242, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1158 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1158batches [03:04,  6.31batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1159 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1159batches [03:04,  6.26batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1160 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1160batches [03:04,  6.25batches/s, epoch=1, loss=0.225, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1161 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1161batches [03:04,  6.28batches/s, epoch=1, loss=0.15, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1162 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1162batches [03:05,  6.23batches/s, epoch=1, loss=0.206, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1163 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1163batches [03:05,  6.25batches/s, epoch=1, loss=0.108, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1164 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1164batches [03:05,  6.25batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1165 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1165batches [03:05,  6.26batches/s, epoch=1, loss=0.345, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1166 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1166batches [03:05,  6.25batches/s, epoch=1, loss=0.102, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1167 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1167batches [03:05,  6.23batches/s, epoch=1, loss=0.11, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1168 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1168batches [03:06,  6.27batches/s, epoch=1, loss=0.127, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1169 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1169batches [03:06,  6.30batches/s, epoch=1, loss=0.0891, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1170 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1170batches [03:06,  6.25batches/s, epoch=1, loss=0.0997, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1171 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1171batches [03:06,  6.30batches/s, epoch=1, loss=0.062, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1172 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1172batches [03:06,  6.32batches/s, epoch=1, loss=0.169, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1173 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1173batches [03:06,  6.33batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1174 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1174batches [03:06,  6.34batches/s, epoch=1, loss=0.0394, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1175 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1175batches [03:07,  6.31batches/s, epoch=1, loss=0.202, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1176 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1176batches [03:07,  6.31batches/s, epoch=1, loss=0.3, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1177 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1177batches [03:07,  6.31batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1178 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1178batches [03:07,  6.30batches/s, epoch=1, loss=0.317, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1179 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1179batches [03:07,  6.32batches/s, epoch=1, loss=0.297, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1180 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1180batches [03:07,  6.35batches/s, epoch=1, loss=0.248, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1181 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1181batches [03:08,  6.30batches/s, epoch=1, loss=0.19, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1182 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1182batches [03:08,  6.31batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1183 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1183batches [03:08,  6.28batches/s, epoch=1, loss=0.237, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1184 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1184batches [03:08,  6.26batches/s, epoch=1, loss=0.294, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1185 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1185batches [03:08,  6.26batches/s, epoch=1, loss=0.383, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1186 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1186batches [03:08,  6.26batches/s, epoch=1, loss=0.115, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1187 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1187batches [03:09,  6.28batches/s, epoch=1, loss=0.437, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1188 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1188batches [03:09,  6.26batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1189 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1189batches [03:09,  6.22batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1190 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1190batches [03:09,  6.25batches/s, epoch=1, loss=0.0892, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1191 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1191batches [03:09,  6.25batches/s, epoch=1, loss=0.479, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1192 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1192batches [03:09,  6.24batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1193 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1193batches [03:10,  6.23batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1194 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1194batches [03:10,  6.21batches/s, epoch=1, loss=0.239, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1195 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1195batches [03:10,  6.24batches/s, epoch=1, loss=0.289, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1196 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1196batches [03:10,  6.25batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1197 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1197batches [03:10,  6.26batches/s, epoch=1, loss=0.229, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1198 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1198batches [03:10,  6.28batches/s, epoch=1, loss=0.275, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1199 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1199batches [03:10,  6.23batches/s, epoch=1, loss=0.19, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1200 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1200batches [03:11,  6.16batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1201 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1201batches [03:11,  6.17batches/s, epoch=1, loss=0.198, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1202 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1202batches [03:11,  6.19batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1203 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1203batches [03:11,  6.23batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1204 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1204batches [03:11,  6.19batches/s, epoch=1, loss=0.181, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1205 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1205batches [03:11,  6.18batches/s, epoch=1, loss=0.335, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1206 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1206batches [03:12,  6.23batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1207 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1207batches [03:12,  6.26batches/s, epoch=1, loss=0.318, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1208 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1208batches [03:12,  6.26batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1209 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1209batches [03:12,  6.23batches/s, epoch=1, loss=0.135, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1210 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1210batches [03:12,  6.18batches/s, epoch=1, loss=0.305, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1211 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1211batches [03:12,  6.15batches/s, epoch=1, loss=0.0635, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1212 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1212batches [03:13,  6.12batches/s, epoch=1, loss=0.258, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1213 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1213batches [03:13,  6.17batches/s, epoch=1, loss=0.0664, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1214 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1214batches [03:13,  6.17batches/s, epoch=1, loss=0.227, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1215 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1215batches [03:13,  6.23batches/s, epoch=1, loss=0.199, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1216 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1216batches [03:13,  6.24batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1217 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1217batches [03:13,  6.17batches/s, epoch=1, loss=0.322, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1218 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1218batches [03:14,  6.21batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1219 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1219batches [03:14,  6.22batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1220 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1220batches [03:14,  6.24batches/s, epoch=1, loss=0.259, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1221 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1221batches [03:14,  6.25batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1222 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1222batches [03:14,  6.17batches/s, epoch=1, loss=0.119, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1223 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1223batches [03:14,  6.18batches/s, epoch=1, loss=0.112, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1224 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1224batches [03:15,  6.23batches/s, epoch=1, loss=0.195, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1225 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1225batches [03:15,  6.28batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1226 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1226batches [03:15,  6.25batches/s, epoch=1, loss=0.0968, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1227 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1227batches [03:15,  6.23batches/s, epoch=1, loss=0.182, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1228 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1228batches [03:15,  6.20batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1229 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1229batches [03:15,  6.14batches/s, epoch=1, loss=0.12, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1230 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1230batches [03:15,  6.18batches/s, epoch=1, loss=0.318, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1231 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1231batches [03:16,  6.22batches/s, epoch=1, loss=0.199, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1232 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1232batches [03:16,  6.12batches/s, epoch=1, loss=0.078, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1233 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1233batches [03:16,  6.18batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1234 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1234batches [03:16,  6.22batches/s, epoch=1, loss=0.29, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1235 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1235batches [03:16,  6.20batches/s, epoch=1, loss=0.17, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1236 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1236batches [03:16,  6.24batches/s, epoch=1, loss=0.122, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1237 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1237batches [03:17,  6.20batches/s, epoch=1, loss=0.0665, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1238 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1238batches [03:17,  6.20batches/s, epoch=1, loss=0.108, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1239 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1239batches [03:17,  6.21batches/s, epoch=1, loss=0.248, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1240 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1240batches [03:17,  6.22batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1241 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1241batches [03:17,  6.19batches/s, epoch=1, loss=0.249, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1242 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1242batches [03:17,  6.20batches/s, epoch=1, loss=0.185, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1243 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1243batches [03:18,  6.27batches/s, epoch=1, loss=0.364, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1244 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1244batches [03:18,  6.28batches/s, epoch=1, loss=0.2, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1245 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1245batches [03:18,  6.26batches/s, epoch=1, loss=0.0373, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1246 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1246batches [03:18,  6.25batches/s, epoch=1, loss=0.126, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1247 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1247batches [03:18,  6.25batches/s, epoch=1, loss=0.387, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1248 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1248batches [03:18,  6.24batches/s, epoch=1, loss=0.158, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1249 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1249batches [03:19,  6.23batches/s, epoch=1, loss=0.301, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1250 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1250batches [03:19,  6.23batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1251 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1251batches [03:19,  6.27batches/s, epoch=1, loss=0.223, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1252 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1252batches [03:19,  6.25batches/s, epoch=1, loss=0.199, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1253 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1253batches [03:19,  6.25batches/s, epoch=1, loss=0.169, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1254 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1254batches [03:19,  6.23batches/s, epoch=1, loss=0.175, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1255 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1255batches [03:19,  6.24batches/s, epoch=1, loss=0.265, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1256 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1256batches [03:20,  6.24batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1257 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1257batches [03:20,  6.21batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1258 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1258batches [03:20,  6.18batches/s, epoch=1, loss=0.0505, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1259 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1259batches [03:20,  6.19batches/s, epoch=1, loss=0.138, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1260 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1260batches [03:20,  6.22batches/s, epoch=1, loss=0.168, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1261 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1261batches [03:20,  6.25batches/s, epoch=1, loss=0.236, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1262 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1262batches [03:21,  6.22batches/s, epoch=1, loss=0.154, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1263 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1263batches [03:21,  6.27batches/s, epoch=1, loss=0.227, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1264 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1264batches [03:21,  6.29batches/s, epoch=1, loss=0.0889, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1265 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1265batches [03:21,  6.33batches/s, epoch=1, loss=0.137, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1266 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1266batches [03:21,  6.31batches/s, epoch=1, loss=0.204, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1267 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1267batches [03:21,  6.28batches/s, epoch=1, loss=0.0805, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1268 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1268batches [03:22,  6.29batches/s, epoch=1, loss=0.143, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1269 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1269batches [03:22,  6.29batches/s, epoch=1, loss=0.265, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1270 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1270batches [03:22,  6.33batches/s, epoch=1, loss=0.324, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1271 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1271batches [03:22,  6.31batches/s, epoch=1, loss=0.165, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1272 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1272batches [03:22,  6.29batches/s, epoch=1, loss=0.153, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1273 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1273batches [03:22,  6.27batches/s, epoch=1, loss=0.319, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1274 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1274batches [03:23,  6.24batches/s, epoch=1, loss=0.158, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1275 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1275batches [03:23,  6.23batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1276 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1276batches [03:23,  6.10batches/s, epoch=1, loss=0.159, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1277 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1277batches [03:23,  6.21batches/s, epoch=1, loss=0.0933, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1278 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1278batches [03:23,  6.26batches/s, epoch=1, loss=0.19, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1279 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1279batches [03:23,  6.21batches/s, epoch=1, loss=0.199, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1280 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1280batches [03:24,  6.18batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1281 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1281batches [03:24,  6.19batches/s, epoch=1, loss=0.296, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1282 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1282batches [03:24,  6.18batches/s, epoch=1, loss=0.192, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1283 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1283batches [03:24,  6.20batches/s, epoch=1, loss=0.316, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1284 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1284batches [03:24,  6.21batches/s, epoch=1, loss=0.296, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1285 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1285batches [03:24,  6.28batches/s, epoch=1, loss=0.335, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1286 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1286batches [03:24,  6.29batches/s, epoch=1, loss=0.17, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1287 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1287batches [03:25,  6.27batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1288 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1288batches [03:25,  6.27batches/s, epoch=1, loss=0.251, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1289 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1289batches [03:25,  6.23batches/s, epoch=1, loss=0.119, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1290 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1290batches [03:25,  6.24batches/s, epoch=1, loss=0.256, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1291 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1291batches [03:25,  6.27batches/s, epoch=1, loss=0.198, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1292 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1292batches [03:25,  6.29batches/s, epoch=1, loss=0.217, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1293 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1293batches [03:26,  6.33batches/s, epoch=1, loss=0.242, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1294 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1294batches [03:26,  6.28batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1295 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1295batches [03:26,  6.26batches/s, epoch=1, loss=0.248, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1296 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1296batches [03:26,  6.26batches/s, epoch=1, loss=0.127, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1297 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1297batches [03:26,  6.27batches/s, epoch=1, loss=0.233, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1298 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1298batches [03:26,  6.22batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1299 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1299batches [03:27,  6.20batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1300 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1300batches [03:27,  6.21batches/s, epoch=1, loss=0.261, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1301 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1301batches [03:27,  6.19batches/s, epoch=1, loss=0.175, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1302 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1302batches [03:27,  6.18batches/s, epoch=1, loss=0.1, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1303 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1303batches [03:27,  6.21batches/s, epoch=1, loss=0.417, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1304 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1304batches [03:27,  6.20batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1305 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1305batches [03:28,  6.24batches/s, epoch=1, loss=0.207, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1306 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1306batches [03:28,  6.26batches/s, epoch=1, loss=0.188, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1307 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1307batches [03:28,  6.32batches/s, epoch=1, loss=0.192, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1308 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1308batches [03:28,  6.27batches/s, epoch=1, loss=0.223, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1309 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1309batches [03:28,  6.21batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1310 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1310batches [03:28,  6.24batches/s, epoch=1, loss=0.0681, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1311 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1311batches [03:28,  6.26batches/s, epoch=1, loss=0.207, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1312 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1312batches [03:29,  6.28batches/s, epoch=1, loss=0.265, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1313 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1313batches [03:29,  6.29batches/s, epoch=1, loss=0.0795, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1314 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1314batches [03:29,  6.28batches/s, epoch=1, loss=0.216, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1315 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1315batches [03:29,  6.26batches/s, epoch=1, loss=0.342, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1316 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1316batches [03:29,  6.25batches/s, epoch=1, loss=0.336, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1317 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1317batches [03:29,  6.26batches/s, epoch=1, loss=0.0667, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1318 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1318batches [03:30,  6.30batches/s, epoch=1, loss=0.061, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1319 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1319batches [03:30,  6.31batches/s, epoch=1, loss=0.0795, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1320 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1320batches [03:30,  6.27batches/s, epoch=1, loss=0.325, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1321 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1321batches [03:30,  6.22batches/s, epoch=1, loss=0.253, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1322 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1322batches [03:30,  6.23batches/s, epoch=1, loss=0.228, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1323 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1323batches [03:30,  6.23batches/s, epoch=1, loss=0.39, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1324 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1324batches [03:31,  6.25batches/s, epoch=1, loss=0.209, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1325 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1325batches [03:31,  6.24batches/s, epoch=1, loss=0.43, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1326 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1326batches [03:31,  6.21batches/s, epoch=1, loss=0.351, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1327 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1327batches [03:31,  6.21batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1328 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1328batches [03:31,  6.22batches/s, epoch=1, loss=0.119, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1329 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1329batches [03:31,  5.97batches/s, epoch=1, loss=0.24, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1330 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1330batches [03:32,  5.68batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1331 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1331batches [03:32,  5.59batches/s, epoch=1, loss=0.251, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1332 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1332batches [03:32,  5.36batches/s, epoch=1, loss=0.2, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1333 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1333batches [03:32,  5.31batches/s, epoch=1, loss=0.377, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1334 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1334batches [03:32,  5.46batches/s, epoch=1, loss=0.117, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1335 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1335batches [03:32,  5.54batches/s, epoch=1, loss=0.135, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1336 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1336batches [03:33,  5.61batches/s, epoch=1, loss=0.12, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1337 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1337batches [03:33,  5.79batches/s, epoch=1, loss=0.0853, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1338 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1338batches [03:33,  5.69batches/s, epoch=1, loss=0.174, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1339 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1339batches [03:33,  5.51batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1340 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1340batches [03:33,  5.29batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1341 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1341batches [03:34,  5.46batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1342 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1342batches [03:34,  5.21batches/s, epoch=1, loss=0.262, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1343 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1343batches [03:34,  5.21batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1344 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1344batches [03:34,  5.53batches/s, epoch=1, loss=0.175, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1345 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1345batches [03:34,  5.61batches/s, epoch=1, loss=0.113, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1346 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1346batches [03:35,  5.29batches/s, epoch=1, loss=0.246, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1347 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1347batches [03:35,  5.24batches/s, epoch=1, loss=0.261, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1348 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1348batches [03:35,  5.11batches/s, epoch=1, loss=0.42, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1349 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1349batches [03:35,  5.33batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1350 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1350batches [03:35,  5.58batches/s, epoch=1, loss=0.21, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1351 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1351batches [03:35,  5.39batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1352 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1352batches [03:36,  5.54batches/s, epoch=1, loss=0.149, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1353 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1353batches [03:36,  5.44batches/s, epoch=1, loss=0.0514, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1354 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1354batches [03:36,  5.17batches/s, epoch=1, loss=0.163, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1355 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1355batches [03:36,  4.90batches/s, epoch=1, loss=0.302, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1356 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1356batches [03:36,  5.12batches/s, epoch=1, loss=0.2, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1357 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1357batches [03:37,  5.10batches/s, epoch=1, loss=0.262, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1358 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1358batches [03:37,  5.23batches/s, epoch=1, loss=0.223, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1359 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1359batches [03:37,  5.10batches/s, epoch=1, loss=0.0963, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1360 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1360batches [03:37,  5.31batches/s, epoch=1, loss=0.0811, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1361 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1361batches [03:37,  5.43batches/s, epoch=1, loss=0.283, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1362 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1362batches [03:38,  5.61batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1363 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1363batches [03:38,  5.71batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1364 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1364batches [03:38,  5.68batches/s, epoch=1, loss=0.119, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1365 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1365batches [03:38,  5.91batches/s, epoch=1, loss=0.0964, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1366 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1366batches [03:38,  6.01batches/s, epoch=1, loss=0.15, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1367 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1367batches [03:38,  6.08batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1368 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1368batches [03:39,  6.14batches/s, epoch=1, loss=0.104, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1369 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1369batches [03:39,  6.18batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1370 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1370batches [03:39,  6.25batches/s, epoch=1, loss=0.102, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1371 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1371batches [03:39,  6.26batches/s, epoch=1, loss=0.231, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1372 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1372batches [03:39,  6.22batches/s, epoch=1, loss=0.233, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1373 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1373batches [03:39,  6.26batches/s, epoch=1, loss=0.051, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1374 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1374batches [03:39,  6.27batches/s, epoch=1, loss=0.0691, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1375 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1375batches [03:40,  6.28batches/s, epoch=1, loss=0.189, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1376 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1376batches [03:40,  6.33batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1377 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1377batches [03:40,  6.32batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1378 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1378batches [03:40,  6.26batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1379 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1379batches [03:40,  6.24batches/s, epoch=1, loss=0.113, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1380 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1380batches [03:40,  6.21batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1381 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1381batches [03:41,  6.24batches/s, epoch=1, loss=0.211, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1382 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1382batches [03:41,  6.26batches/s, epoch=1, loss=0.346, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1383 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1383batches [03:41,  6.22batches/s, epoch=1, loss=0.235, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1384 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1384batches [03:41,  6.27batches/s, epoch=1, loss=0.112, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1385 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1385batches [03:41,  6.29batches/s, epoch=1, loss=0.136, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1386 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1386batches [03:41,  6.30batches/s, epoch=1, loss=0.208, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1387 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1387batches [03:42,  6.32batches/s, epoch=1, loss=0.114, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1388 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1388batches [03:42,  6.29batches/s, epoch=1, loss=0.298, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1389 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1389batches [03:42,  6.24batches/s, epoch=1, loss=0.325, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1390 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1390batches [03:42,  6.26batches/s, epoch=1, loss=0.117, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1391 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1391batches [03:42,  6.27batches/s, epoch=1, loss=0.071, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1392 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1392batches [03:42,  6.32batches/s, epoch=1, loss=0.28, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1393 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1393batches [03:42,  6.32batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1394 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1394batches [03:43,  6.32batches/s, epoch=1, loss=0.239, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1395 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1395batches [03:43,  6.26batches/s, epoch=1, loss=0.263, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1396 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1396batches [03:43,  5.59batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1397 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1397batches [03:43,  5.79batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1398 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1398batches [03:43,  5.82batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1399 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1399batches [03:44,  5.54batches/s, epoch=1, loss=0.236, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1400 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1400batches [03:44,  5.49batches/s, epoch=1, loss=0.306, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1401 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1401batches [03:44,  5.66batches/s, epoch=1, loss=0.0895, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1402 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1402batches [03:44,  5.75batches/s, epoch=1, loss=0.253, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1403 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1403batches [03:44,  5.91batches/s, epoch=1, loss=0.281, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1404 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1404batches [03:44,  6.00batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1405 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1405batches [03:45,  5.80batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1406 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1406batches [03:45,  5.98batches/s, epoch=1, loss=0.282, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1407 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1407batches [03:45,  5.72batches/s, epoch=1, loss=0.26, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1408 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1408batches [03:45,  5.93batches/s, epoch=1, loss=0.0137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1409 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1409batches [03:45,  5.93batches/s, epoch=1, loss=0.191, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1410 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1410batches [03:45,  5.88batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1411 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1411batches [03:46,  5.68batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1412 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1412batches [03:46,  5.94batches/s, epoch=1, loss=0.143, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1413 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1413batches [03:46,  5.98batches/s, epoch=1, loss=0.288, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1414 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1414batches [03:46,  6.01batches/s, epoch=1, loss=0.259, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1415 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1415batches [03:46,  5.98batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1416 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1416batches [03:46,  6.07batches/s, epoch=1, loss=0.191, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1417 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1417batches [03:47,  6.16batches/s, epoch=1, loss=0.181, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1418 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1418batches [03:47,  5.70batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1419 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1419batches [03:47,  5.70batches/s, epoch=1, loss=0.189, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1420 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1420batches [03:47,  5.69batches/s, epoch=1, loss=0.0902, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1421 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1421batches [03:47,  5.86batches/s, epoch=1, loss=0.388, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1422 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1422batches [03:47,  5.96batches/s, epoch=1, loss=0.113, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1423 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1423batches [03:48,  5.64batches/s, epoch=1, loss=0.217, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1424 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1424batches [03:48,  5.86batches/s, epoch=1, loss=0.172, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1425 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1425batches [03:48,  5.50batches/s, epoch=1, loss=0.108, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1426 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1426batches [03:48,  5.33batches/s, epoch=1, loss=0.266, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1427 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1427batches [03:48,  5.36batches/s, epoch=1, loss=0.349, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1428 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1428batches [03:49,  5.35batches/s, epoch=1, loss=0.0555, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1429 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1429batches [03:49,  5.65batches/s, epoch=1, loss=0.0893, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1430 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1430batches [03:49,  5.73batches/s, epoch=1, loss=0.333, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1431 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1431batches [03:49,  5.56batches/s, epoch=1, loss=0.242, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1432 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1432batches [03:49,  5.27batches/s, epoch=1, loss=0.0754, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1433 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1433batches [03:49,  5.61batches/s, epoch=1, loss=0.11, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1434 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1434batches [03:50,  5.74batches/s, epoch=1, loss=0.231, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1435 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1435batches [03:50,  5.67batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1436 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1436batches [03:50,  5.09batches/s, epoch=1, loss=0.0861, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1437 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1437batches [03:50,  4.75batches/s, epoch=1, loss=0.131, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1438 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1438batches [03:50,  4.94batches/s, epoch=1, loss=0.186, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1439 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1439batches [03:51,  4.93batches/s, epoch=1, loss=0.2, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1440 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1440batches [03:51,  5.11batches/s, epoch=1, loss=0.0926, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1441 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1441batches [03:51,  5.11batches/s, epoch=1, loss=0.101, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1442 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1442batches [03:51,  5.14batches/s, epoch=1, loss=0.203, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1443 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1443batches [03:51,  5.17batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1444 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1444batches [03:52,  5.18batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1445 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1445batches [03:52,  4.73batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1446 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1446batches [03:52,  5.00batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1447 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1447batches [03:52,  5.24batches/s, epoch=1, loss=0.072, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1448 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1448batches [03:52,  5.43batches/s, epoch=1, loss=0.366, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1449 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1449batches [03:53,  5.40batches/s, epoch=1, loss=0.437, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1450 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1450batches [03:53,  5.45batches/s, epoch=1, loss=0.282, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1451 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1451batches [03:53,  5.61batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1452 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1452batches [03:53,  5.75batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1453 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1453batches [03:53,  5.48batches/s, epoch=1, loss=0.271, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1454 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1454batches [03:53,  5.59batches/s, epoch=1, loss=0.0765, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1455 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1455batches [03:54,  5.59batches/s, epoch=1, loss=0.122, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1456 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1456batches [03:54,  5.58batches/s, epoch=1, loss=0.182, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1457 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1457batches [03:54,  5.61batches/s, epoch=1, loss=0.203, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1458 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1458batches [03:54,  5.82batches/s, epoch=1, loss=0.371, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1459 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1459batches [03:54,  5.97batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1460 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1460batches [03:55,  5.50batches/s, epoch=1, loss=0.188, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1461 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1461batches [03:55,  5.57batches/s, epoch=1, loss=0.259, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1462 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1462batches [03:55,  5.57batches/s, epoch=1, loss=0.143, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1463 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1463batches [03:55,  5.50batches/s, epoch=1, loss=0.321, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1464 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1464batches [03:55,  5.51batches/s, epoch=1, loss=0.172, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1465 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1465batches [03:55,  5.61batches/s, epoch=1, loss=0.238, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1466 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1466batches [03:56,  5.63batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1467 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1467batches [03:56,  5.48batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1468 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1468batches [03:56,  5.16batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1469 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1469batches [03:56,  5.49batches/s, epoch=1, loss=0.172, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1470 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1470batches [03:56,  5.62batches/s, epoch=1, loss=0.282, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1471 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1471batches [03:57,  5.73batches/s, epoch=1, loss=0.201, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1472 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1472batches [03:57,  5.72batches/s, epoch=1, loss=0.17, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1473 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1473batches [03:57,  5.89batches/s, epoch=1, loss=0.102, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1474 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1474batches [03:57,  5.70batches/s, epoch=1, loss=0.416, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1475 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1475batches [03:57,  5.67batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1476 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1476batches [03:57,  5.85batches/s, epoch=1, loss=0.081, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1477 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1477batches [03:58,  5.42batches/s, epoch=1, loss=0.256, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1478 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1478batches [03:58,  5.42batches/s, epoch=1, loss=0.0785, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1479 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1479batches [03:58,  5.67batches/s, epoch=1, loss=0.365, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1480 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1480batches [03:58,  5.64batches/s, epoch=1, loss=0.158, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1481 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1481batches [03:58,  5.62batches/s, epoch=1, loss=0.226, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1482 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1482batches [03:58,  5.66batches/s, epoch=1, loss=0.251, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1483 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1483batches [03:59,  5.85batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1484 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1484batches [03:59,  5.75batches/s, epoch=1, loss=0.135, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1485 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1485batches [03:59,  5.87batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1486 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1486batches [03:59,  6.01batches/s, epoch=1, loss=0.29, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1487 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1487batches [03:59,  6.04batches/s, epoch=1, loss=0.303, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1488 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1488batches [03:59,  6.09batches/s, epoch=1, loss=0.0825, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1489 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1489batches [04:00,  5.92batches/s, epoch=1, loss=0.309, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1490 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1490batches [04:00,  5.77batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1491 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1491batches [04:00,  5.41batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1492 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1492batches [04:00,  5.62batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1493 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1493batches [04:00,  5.67batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1494 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1494batches [04:01,  5.58batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1495 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1495batches [04:01,  5.32batches/s, epoch=1, loss=0.158, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1496 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1496batches [04:01,  5.24batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1497 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1497batches [04:01,  5.56batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1498 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1498batches [04:01,  5.74batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1499 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1499batches [04:01,  5.74batches/s, epoch=1, loss=0.138, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1500 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1500batches [04:02,  5.74batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1501 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1501batches [04:02,  5.71batches/s, epoch=1, loss=0.164, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1502 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1502batches [04:02,  5.69batches/s, epoch=1, loss=0.142, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1503 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1503batches [04:02,  5.81batches/s, epoch=1, loss=0.21, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1504 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1504batches [04:02,  5.61batches/s, epoch=1, loss=0.085, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1505 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1505batches [04:03,  5.62batches/s, epoch=1, loss=0.0499, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1506 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1506batches [04:03,  5.67batches/s, epoch=1, loss=0.224, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1507 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1507batches [04:03,  5.69batches/s, epoch=1, loss=0.331, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1508 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1508batches [04:03,  5.77batches/s, epoch=1, loss=0.324, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1509 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1509batches [04:03,  5.58batches/s, epoch=1, loss=0.233, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1510 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1510batches [04:03,  5.57batches/s, epoch=1, loss=0.243, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1511 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1511batches [04:04,  5.79batches/s, epoch=1, loss=0.175, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1512 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1512batches [04:04,  5.88batches/s, epoch=1, loss=0.154, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1513 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1513batches [04:04,  6.00batches/s, epoch=1, loss=0.143, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1514 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1514batches [04:04,  5.89batches/s, epoch=1, loss=0.289, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1515 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1515batches [04:04,  5.67batches/s, epoch=1, loss=0.161, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1516 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1516batches [04:04,  5.84batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1517 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1517batches [04:05,  5.97batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1518 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1518batches [04:05,  5.95batches/s, epoch=1, loss=0.174, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1519 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1519batches [04:05,  5.94batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1520 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1520batches [04:05,  5.71batches/s, epoch=1, loss=0.106, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1521 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1521batches [04:05,  5.38batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1522 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1522batches [04:05,  5.50batches/s, epoch=1, loss=0.104, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1523 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1523batches [04:06,  5.19batches/s, epoch=1, loss=0.0866, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1524 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1524batches [04:06,  5.25batches/s, epoch=1, loss=0.186, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1525 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1525batches [04:06,  5.55batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1526 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1526batches [04:06,  5.53batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1527 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1527batches [04:06,  5.56batches/s, epoch=1, loss=0.0973, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1528 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1528batches [04:07,  5.38batches/s, epoch=1, loss=0.172, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1529 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1529batches [04:07,  5.67batches/s, epoch=1, loss=0.315, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1530 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1530batches [04:07,  5.81batches/s, epoch=1, loss=0.343, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1531 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1531batches [04:07,  5.90batches/s, epoch=1, loss=0.0603, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1532 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1532batches [04:07,  5.95batches/s, epoch=1, loss=0.328, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1533 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1533batches [04:07,  5.95batches/s, epoch=1, loss=0.104, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1534 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1534batches [04:08,  6.04batches/s, epoch=1, loss=0.197, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1535 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1535batches [04:08,  6.09batches/s, epoch=1, loss=0.353, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1536 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1536batches [04:08,  6.18batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1537 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1537batches [04:08,  6.19batches/s, epoch=1, loss=0.319, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1538 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1538batches [04:08,  6.12batches/s, epoch=1, loss=0.228, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1539 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1539batches [04:08,  6.13batches/s, epoch=1, loss=0.0751, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1540 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1540batches [04:09,  6.22batches/s, epoch=1, loss=0.0914, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1541 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1541batches [04:09,  6.27batches/s, epoch=1, loss=0.21, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1542 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1542batches [04:09,  6.24batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1543 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1543batches [04:09,  6.21batches/s, epoch=1, loss=0.301, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1544 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1544batches [04:09,  6.23batches/s, epoch=1, loss=0.0516, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1545 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1545batches [04:09,  6.22batches/s, epoch=1, loss=0.121, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1546 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1546batches [04:09,  6.25batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1547 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1547batches [04:10,  6.27batches/s, epoch=1, loss=0.158, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1548 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1548batches [04:10,  6.26batches/s, epoch=1, loss=0.119, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1549 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1549batches [04:10,  6.24batches/s, epoch=1, loss=0.267, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1550 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1550batches [04:10,  6.23batches/s, epoch=1, loss=0.24, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1551 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1551batches [04:10,  6.25batches/s, epoch=1, loss=0.328, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1552 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1552batches [04:10,  6.25batches/s, epoch=1, loss=0.0744, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1553 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1553batches [04:11,  6.24batches/s, epoch=1, loss=0.213, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1554 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1554batches [04:11,  6.23batches/s, epoch=1, loss=0.321, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1555 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1555batches [04:11,  6.21batches/s, epoch=1, loss=0.141, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1556 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1556batches [04:11,  6.26batches/s, epoch=1, loss=0.179, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1557 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1557batches [04:11,  6.25batches/s, epoch=1, loss=0.166, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1558 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1558batches [04:11,  6.25batches/s, epoch=1, loss=0.257, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1559 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1559batches [04:12,  6.23batches/s, epoch=1, loss=0.265, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1560 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1560batches [04:12,  6.20batches/s, epoch=1, loss=0.228, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1561 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1561batches [04:12,  6.24batches/s, epoch=1, loss=0.26, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1562 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1562batches [04:12,  6.27batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1563 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1563batches [04:12,  6.29batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1564 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1564batches [04:12,  6.33batches/s, epoch=1, loss=0.045, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1565 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1565batches [04:13,  6.27batches/s, epoch=1, loss=0.0775, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1566 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1566batches [04:13,  6.26batches/s, epoch=1, loss=0.222, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1567 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1567batches [04:13,  6.25batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1568 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1568batches [04:13,  6.28batches/s, epoch=1, loss=0.26, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1569 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1569batches [04:13,  6.27batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1570 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1570batches [04:13,  6.21batches/s, epoch=1, loss=0.192, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1571 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1571batches [04:13,  6.19batches/s, epoch=1, loss=0.143, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1572 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1572batches [04:14,  6.19batches/s, epoch=1, loss=0.168, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1573 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1573batches [04:14,  6.20batches/s, epoch=1, loss=0.159, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1574 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1574batches [04:14,  6.21batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1575 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1575batches [04:14,  6.20batches/s, epoch=1, loss=0.106, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1576 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1576batches [04:14,  6.21batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1577 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1577batches [04:14,  6.21batches/s, epoch=1, loss=0.11, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1578 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1578batches [04:15,  6.25batches/s, epoch=1, loss=0.182, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1579 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1579batches [04:15,  6.29batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1580 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1580batches [04:15,  6.25batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1581 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1581batches [04:15,  6.24batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1582 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1582batches [04:15,  6.17batches/s, epoch=1, loss=0.319, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1583 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1583batches [04:15,  6.20batches/s, epoch=1, loss=0.266, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1584 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1584batches [04:16,  6.26batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1585 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1585batches [04:16,  6.20batches/s, epoch=1, loss=0.3, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1586 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1586batches [04:16,  6.21batches/s, epoch=1, loss=0.313, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1587 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1587batches [04:16,  6.31batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1588 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1588batches [04:16,  6.36batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1589 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1589batches [04:16,  6.30batches/s, epoch=1, loss=0.128, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1590 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1590batches [04:17,  6.27batches/s, epoch=1, loss=0.288, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1591 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1591batches [04:17,  6.23batches/s, epoch=1, loss=0.249, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1592 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1592batches [04:17,  6.25batches/s, epoch=1, loss=0.0481, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1593 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1593batches [04:17,  6.29batches/s, epoch=1, loss=0.299, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1594 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1594batches [04:17,  6.26batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1595 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1595batches [04:17,  6.22batches/s, epoch=1, loss=0.341, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1596 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1596batches [04:17,  6.21batches/s, epoch=1, loss=0.293, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1597 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1597batches [04:18,  6.21batches/s, epoch=1, loss=0.127, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1598 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1598batches [04:18,  6.24batches/s, epoch=1, loss=0.213, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1599 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1599batches [04:18,  6.20batches/s, epoch=1, loss=0.139, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1600 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1600batches [04:18,  6.23batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1601 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1601batches [04:18,  6.25batches/s, epoch=1, loss=0.23, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1602 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1602batches [04:18,  6.22batches/s, epoch=1, loss=0.104, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1603 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1603batches [04:19,  6.25batches/s, epoch=1, loss=0.12, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1604 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1604batches [04:19,  6.25batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1605 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1605batches [04:19,  6.16batches/s, epoch=1, loss=0.163, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1606 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1606batches [04:19,  6.22batches/s, epoch=1, loss=0.0649, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1607 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1607batches [04:19,  6.17batches/s, epoch=1, loss=0.136, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1608 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1608batches [04:19,  6.22batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1609 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1609batches [04:20,  6.28batches/s, epoch=1, loss=0.233, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1610 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1610batches [04:20,  6.24batches/s, epoch=1, loss=0.321, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1611 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1611batches [04:20,  6.23batches/s, epoch=1, loss=0.368, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1612 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1612batches [04:20,  6.21batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1613 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1613batches [04:20,  6.24batches/s, epoch=1, loss=0.213, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1614 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1614batches [04:20,  6.30batches/s, epoch=1, loss=0.104, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1615 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1615batches [04:21,  6.33batches/s, epoch=1, loss=0.307, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1616 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1616batches [04:21,  6.29batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1617 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1617batches [04:21,  6.28batches/s, epoch=1, loss=0.135, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1618 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1618batches [04:21,  6.25batches/s, epoch=1, loss=0.236, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1619 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1619batches [04:21,  6.18batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1620 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1620batches [04:21,  6.22batches/s, epoch=1, loss=0.0859, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1621 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1621batches [04:22,  6.21batches/s, epoch=1, loss=0.24, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1622 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1622batches [04:22,  6.21batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1623 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1623batches [04:22,  6.16batches/s, epoch=1, loss=0.307, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1624 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1624batches [04:22,  6.18batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1625 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1625batches [04:22,  6.13batches/s, epoch=1, loss=0.261, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1626 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1626batches [04:22,  6.17batches/s, epoch=1, loss=0.24, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1627 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1627batches [04:22,  6.18batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1628 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1628batches [04:23,  6.23batches/s, epoch=1, loss=0.1, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1629 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1629batches [04:23,  6.25batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1630 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1630batches [04:23,  6.22batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1631 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1631batches [04:23,  6.25batches/s, epoch=1, loss=0.15, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1632 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1632batches [04:23,  6.23batches/s, epoch=1, loss=0.17, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1633 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1633batches [04:23,  6.23batches/s, epoch=1, loss=0.0693, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1634 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1634batches [04:24,  6.28batches/s, epoch=1, loss=0.179, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1635 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1635batches [04:24,  6.21batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1636 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1636batches [04:24,  6.20batches/s, epoch=1, loss=0.369, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1637 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1637batches [04:24,  6.24batches/s, epoch=1, loss=0.243, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1638 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1638batches [04:24,  6.27batches/s, epoch=1, loss=0.104, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1639 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1639batches [04:24,  6.27batches/s, epoch=1, loss=0.185, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1640 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1640batches [04:25,  6.26batches/s, epoch=1, loss=0.109, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1641 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1641batches [04:25,  6.25batches/s, epoch=1, loss=0.203, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1642 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1642batches [04:25,  6.24batches/s, epoch=1, loss=0.377, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1643 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1643batches [04:25,  6.22batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1644 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1644batches [04:25,  6.20batches/s, epoch=1, loss=0.0545, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1645 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1645batches [04:25,  6.15batches/s, epoch=1, loss=0.115, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1646 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1646batches [04:26,  6.18batches/s, epoch=1, loss=0.0826, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1647 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1647batches [04:26,  6.12batches/s, epoch=1, loss=0.281, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1648 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1648batches [04:26,  6.16batches/s, epoch=1, loss=0.184, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1649 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1649batches [04:26,  6.15batches/s, epoch=1, loss=0.348, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1650 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1650batches [04:26,  6.15batches/s, epoch=1, loss=0.129, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1651 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1651batches [04:26,  6.17batches/s, epoch=1, loss=0.196, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1652 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1652batches [04:27,  6.18batches/s, epoch=1, loss=0.244, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1653 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1653batches [04:27,  6.17batches/s, epoch=1, loss=0.16, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1654 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1654batches [04:27,  6.21batches/s, epoch=1, loss=0.227, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1655 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1655batches [04:27,  6.21batches/s, epoch=1, loss=0.535, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1656 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1656batches [04:27,  6.26batches/s, epoch=1, loss=0.254, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1657 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1657batches [04:27,  6.25batches/s, epoch=1, loss=0.29, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1658 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1658batches [04:27,  6.25batches/s, epoch=1, loss=0.0574, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1659 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1659batches [04:28,  6.28batches/s, epoch=1, loss=0.228, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1660 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1660batches [04:28,  6.26batches/s, epoch=1, loss=0.198, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1661 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1661batches [04:28,  6.26batches/s, epoch=1, loss=0.214, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1662 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1662batches [04:28,  6.30batches/s, epoch=1, loss=0.206, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1663 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1663batches [04:28,  6.33batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1664 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1664batches [04:28,  6.31batches/s, epoch=1, loss=0.127, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1665 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1665batches [04:29,  6.29batches/s, epoch=1, loss=0.196, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1666 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1666batches [04:29,  6.28batches/s, epoch=1, loss=0.212, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1667 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1667batches [04:29,  6.25batches/s, epoch=1, loss=0.0979, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1668 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1668batches [04:29,  6.24batches/s, epoch=1, loss=0.141, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1669 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1669batches [04:29,  6.21batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1670 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1670batches [04:29,  6.17batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1671 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1671batches [04:30,  6.20batches/s, epoch=1, loss=0.254, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1672 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1672batches [04:30,  6.18batches/s, epoch=1, loss=0.206, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1673 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1673batches [04:30,  6.20batches/s, epoch=1, loss=0.251, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1674 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1674batches [04:30,  6.18batches/s, epoch=1, loss=0.165, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1675 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1675batches [04:30,  6.14batches/s, epoch=1, loss=0.399, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1676 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1676batches [04:30,  6.20batches/s, epoch=1, loss=0.138, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1677 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1677batches [04:31,  6.19batches/s, epoch=1, loss=0.273, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1678 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1678batches [04:31,  6.23batches/s, epoch=1, loss=0.238, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1679 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1679batches [04:31,  6.31batches/s, epoch=1, loss=0.152, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1680 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1680batches [04:31,  6.29batches/s, epoch=1, loss=0.148, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1681 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1681batches [04:31,  6.31batches/s, epoch=1, loss=0.243, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1682 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1682batches [04:31,  6.28batches/s, epoch=1, loss=0.13, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1683 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1683batches [04:31,  6.31batches/s, epoch=1, loss=0.17, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1684 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1684batches [04:32,  6.29batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1685 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1685batches [04:32,  6.24batches/s, epoch=1, loss=0.0819, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1686 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1686batches [04:32,  6.25batches/s, epoch=1, loss=0.0361, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1687 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1687batches [04:32,  6.26batches/s, epoch=1, loss=0.123, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1688 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1688batches [04:32,  6.24batches/s, epoch=1, loss=0.207, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1689 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1689batches [04:32,  6.22batches/s, epoch=1, loss=0.201, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1690 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1690batches [04:33,  6.20batches/s, epoch=1, loss=0.151, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1691 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1691batches [04:33,  6.20batches/s, epoch=1, loss=0.336, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1692 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1692batches [04:33,  6.19batches/s, epoch=1, loss=0.346, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1693 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1693batches [04:33,  6.21batches/s, epoch=1, loss=0.282, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1694 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1694batches [04:33,  6.22batches/s, epoch=1, loss=0.14, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1695 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1695batches [04:33,  6.24batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1696 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1696batches [04:34,  6.22batches/s, epoch=1, loss=0.348, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1697 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1697batches [04:34,  6.19batches/s, epoch=1, loss=0.225, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1698 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1698batches [04:34,  6.24batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1699 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1699batches [04:34,  6.28batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1700 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1700batches [04:34,  6.28batches/s, epoch=1, loss=0.406, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1701 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1701batches [04:34,  6.29batches/s, epoch=1, loss=0.0574, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1702 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1702batches [04:35,  6.28batches/s, epoch=1, loss=0.186, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1703 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1703batches [04:35,  6.29batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1704 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1704batches [04:35,  6.28batches/s, epoch=1, loss=0.121, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1705 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1705batches [04:35,  6.28batches/s, epoch=1, loss=0.197, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1706 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1706batches [04:35,  6.32batches/s, epoch=1, loss=0.2, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1707 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1707batches [04:35,  6.22batches/s, epoch=1, loss=0.134, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1708 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1708batches [04:35,  6.21batches/s, epoch=1, loss=0.069, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1709 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1709batches [04:36,  6.28batches/s, epoch=1, loss=0.386, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1710 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1710batches [04:36,  6.29batches/s, epoch=1, loss=0.259, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1711 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1711batches [04:36,  6.25batches/s, epoch=1, loss=0.316, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1712 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1712batches [04:36,  6.25batches/s, epoch=1, loss=0.169, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1713 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1713batches [04:36,  6.24batches/s, epoch=1, loss=0.131, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1714 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1714batches [04:36,  6.19batches/s, epoch=1, loss=0.273, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1715 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1715batches [04:37,  6.22batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1716 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1716batches [04:37,  6.24batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1717 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1717batches [04:37,  6.22batches/s, epoch=1, loss=0.3, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1718 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1718batches [04:37,  6.22batches/s, epoch=1, loss=0.214, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1719 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1719batches [04:37,  6.21batches/s, epoch=1, loss=0.103, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1720 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1720batches [04:37,  6.23batches/s, epoch=1, loss=0.148, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1721 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1721batches [04:38,  6.19batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1722 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1722batches [04:38,  6.16batches/s, epoch=1, loss=0.109, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1723 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1723batches [04:38,  6.21batches/s, epoch=1, loss=0.255, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1724 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1724batches [04:38,  6.22batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1725 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1725batches [04:38,  6.26batches/s, epoch=1, loss=0.308, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1726 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1726batches [04:38,  6.29batches/s, epoch=1, loss=0.108, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1727 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1727batches [04:39,  6.25batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1728 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1728batches [04:39,  6.24batches/s, epoch=1, loss=0.0662, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1729 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1729batches [04:39,  6.24batches/s, epoch=1, loss=0.295, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1730 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1730batches [04:39,  6.24batches/s, epoch=1, loss=0.228, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1731 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1731batches [04:39,  6.30batches/s, epoch=1, loss=0.317, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1732 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1732batches [04:39,  6.28batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1733 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1733batches [04:39,  6.25batches/s, epoch=1, loss=0.0714, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1734 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1734batches [04:40,  6.27batches/s, epoch=1, loss=0.318, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1735 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1735batches [04:40,  6.32batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1736 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1736batches [04:40,  6.28batches/s, epoch=1, loss=0.125, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1737 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1737batches [04:40,  6.26batches/s, epoch=1, loss=0.339, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1738 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1738batches [04:40,  6.22batches/s, epoch=1, loss=0.346, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1739 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1739batches [04:40,  6.11batches/s, epoch=1, loss=0.111, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1740 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1740batches [04:41,  6.20batches/s, epoch=1, loss=0.36, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1741 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1741batches [04:41,  6.24batches/s, epoch=1, loss=0.41, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1742 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1742batches [04:41,  6.26batches/s, epoch=1, loss=0.513, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1743 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1743batches [04:41,  6.25batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1744 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1744batches [04:41,  6.23batches/s, epoch=1, loss=0.0447, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1745 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1745batches [04:41,  6.28batches/s, epoch=1, loss=0.0586, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1746 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1746batches [04:42,  6.29batches/s, epoch=1, loss=0.299, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1747 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1747batches [04:42,  6.30batches/s, epoch=1, loss=0.148, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1748 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1748batches [04:42,  6.32batches/s, epoch=1, loss=0.326, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1749 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1749batches [04:42,  6.25batches/s, epoch=1, loss=0.222, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1750 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1750batches [04:42,  6.25batches/s, epoch=1, loss=0.124, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1751 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1751batches [04:42,  6.30batches/s, epoch=1, loss=0.351, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1752 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1752batches [04:43,  6.30batches/s, epoch=1, loss=0.185, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1753 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1753batches [04:43,  6.16batches/s, epoch=1, loss=0.027, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1754 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1754batches [04:43,  5.93batches/s, epoch=1, loss=0.293, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1755 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1755batches [04:43,  5.65batches/s, epoch=1, loss=0.152, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1756 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1756batches [04:43,  5.92batches/s, epoch=1, loss=0.169, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1757 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1757batches [04:43,  6.01batches/s, epoch=1, loss=0.264, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1758 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1758batches [04:44,  5.97batches/s, epoch=1, loss=0.3, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1759 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1759batches [04:44,  5.44batches/s, epoch=1, loss=0.29, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1760 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1760batches [04:44,  5.24batches/s, epoch=1, loss=0.176, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1761 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1761batches [04:44,  5.54batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1762 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1762batches [04:44,  5.76batches/s, epoch=1, loss=0.4, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1763 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1763batches [04:44,  5.80batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1764 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1764batches [04:45,  5.30batches/s, epoch=1, loss=0.218, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1765 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1765batches [04:45,  5.41batches/s, epoch=1, loss=0.0799, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1766 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1766batches [04:45,  5.71batches/s, epoch=1, loss=0.0488, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1767 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1767batches [04:45,  5.83batches/s, epoch=1, loss=0.275, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1768 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1768batches [04:45,  5.92batches/s, epoch=1, loss=0.298, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1769 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1769batches [04:45,  6.02batches/s, epoch=1, loss=0.276, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1770 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1770batches [04:46,  5.96batches/s, epoch=1, loss=0.249, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1771 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1771batches [04:46,  6.04batches/s, epoch=1, loss=0.28, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1772 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1772batches [04:46,  6.09batches/s, epoch=1, loss=0.26, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1773 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1773batches [04:46,  6.07batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1774 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1774batches [04:46,  6.09batches/s, epoch=1, loss=0.15, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1775 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1775batches [04:46,  6.12batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1776 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1776batches [04:47,  6.21batches/s, epoch=1, loss=0.266, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1777 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1777batches [04:47,  6.19batches/s, epoch=1, loss=0.162, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1778 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1778batches [04:47,  6.17batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1779 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1779batches [04:47,  6.23batches/s, epoch=1, loss=0.18, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1780 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1780batches [04:47,  6.24batches/s, epoch=1, loss=0.0507, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1781 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1781batches [04:47,  6.30batches/s, epoch=1, loss=0.288, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1782 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1782batches [04:48,  6.27batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1783 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1783batches [04:48,  6.26batches/s, epoch=1, loss=0.316, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1784 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1784batches [04:48,  6.29batches/s, epoch=1, loss=0.267, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1785 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1785batches [04:48,  6.24batches/s, epoch=1, loss=0.147, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1786 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1786batches [04:48,  6.29batches/s, epoch=1, loss=0.213, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1787 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1787batches [04:48,  6.30batches/s, epoch=1, loss=0.122, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1788 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1788batches [04:49,  6.31batches/s, epoch=1, loss=0.113, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1789 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1789batches [04:49,  6.29batches/s, epoch=1, loss=0.416, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1790 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1790batches [04:49,  6.23batches/s, epoch=1, loss=0.289, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1791 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1791batches [04:49,  6.22batches/s, epoch=1, loss=0.2, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1792 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1792batches [04:49,  6.20batches/s, epoch=1, loss=0.121, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1793 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1793batches [04:49,  6.17batches/s, epoch=1, loss=0.305, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1794 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1794batches [04:50,  6.21batches/s, epoch=1, loss=0.114, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1795 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1795batches [04:50,  6.18batches/s, epoch=1, loss=0.322, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1796 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1796batches [04:50,  6.17batches/s, epoch=1, loss=0.148, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1797 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1797batches [04:50,  6.21batches/s, epoch=1, loss=0.246, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1798 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1798batches [04:50,  6.23batches/s, epoch=1, loss=0.3, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1799 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1799batches [04:50,  6.25batches/s, epoch=1, loss=0.439, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1800 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1800batches [04:50,  6.23batches/s, epoch=1, loss=0.115, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1801 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1801batches [04:51,  6.28batches/s, epoch=1, loss=0.296, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1802 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1802batches [04:51,  6.27batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1803 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1803batches [04:51,  6.28batches/s, epoch=1, loss=0.207, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1804 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1804batches [04:51,  6.30batches/s, epoch=1, loss=0.263, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1805 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1805batches [04:51,  6.27batches/s, epoch=1, loss=0.0857, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1806 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1806batches [04:51,  6.30batches/s, epoch=1, loss=0.197, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1807 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1807batches [04:52,  6.27batches/s, epoch=1, loss=0.137, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1808 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1808batches [04:52,  6.27batches/s, epoch=1, loss=0.12, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1809 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1809batches [04:52,  6.29batches/s, epoch=1, loss=0.145, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1810 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1810batches [04:52,  6.26batches/s, epoch=1, loss=0.242, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1811 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1811batches [04:52,  6.24batches/s, epoch=1, loss=0.301, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1812 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1812batches [04:52,  6.27batches/s, epoch=1, loss=0.0867, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1813 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1813batches [04:53,  6.26batches/s, epoch=1, loss=0.223, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1814 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1814batches [04:53,  6.25batches/s, epoch=1, loss=0.0857, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1815 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1815batches [04:53,  6.24batches/s, epoch=1, loss=0.105, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1816 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1816batches [04:53,  6.25batches/s, epoch=1, loss=0.074, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1817 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1817batches [04:53,  6.22batches/s, epoch=1, loss=0.0421, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1818 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1818batches [04:53,  6.22batches/s, epoch=1, loss=0.184, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1819 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1819batches [04:54,  6.24batches/s, epoch=1, loss=0.0631, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1820 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1820batches [04:54,  6.26batches/s, epoch=1, loss=0.16, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1821 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1821batches [04:54,  6.22batches/s, epoch=1, loss=0.153, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1822 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1822batches [04:54,  6.15batches/s, epoch=1, loss=0.382, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1823 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1823batches [04:54,  6.22batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1824 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1824batches [04:54,  6.22batches/s, epoch=1, loss=0.349, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1825 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1825batches [04:54,  6.20batches/s, epoch=1, loss=0.384, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1826 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1826batches [04:55,  6.25batches/s, epoch=1, loss=0.357, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1827 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1827batches [04:55,  6.26batches/s, epoch=1, loss=0.406, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1828 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1828batches [04:55,  6.28batches/s, epoch=1, loss=0.167, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1829 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1829batches [04:55,  6.30batches/s, epoch=1, loss=0.316, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1830 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1830batches [04:55,  6.29batches/s, epoch=1, loss=0.202, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1831 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1831batches [04:55,  6.26batches/s, epoch=1, loss=0.222, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1832 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1832batches [04:56,  6.27batches/s, epoch=1, loss=0.304, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1833 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1833batches [04:56,  6.28batches/s, epoch=1, loss=0.145, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1834 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1834batches [04:56,  6.28batches/s, epoch=1, loss=0.361, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1835 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1835batches [04:56,  6.27batches/s, epoch=1, loss=0.165, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1836 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1836batches [04:56,  6.25batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1837 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1837batches [04:56,  6.26batches/s, epoch=1, loss=0.346, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1838 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1838batches [04:57,  6.26batches/s, epoch=1, loss=0.146, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1839 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1839batches [04:57,  6.24batches/s, epoch=1, loss=0.1, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1840 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1840batches [04:57,  6.09batches/s, epoch=1, loss=0.261, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1841 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1841batches [04:57,  6.10batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1842 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1842batches [04:57,  6.15batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1843 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1843batches [04:57,  6.16batches/s, epoch=1, loss=0.216, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1844 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1844batches [04:58,  6.18batches/s, epoch=1, loss=0.171, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1845 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1845batches [04:58,  6.18batches/s, epoch=1, loss=0.194, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1846 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1846batches [04:58,  6.18batches/s, epoch=1, loss=0.155, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1847 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1847batches [04:58,  6.19batches/s, epoch=1, loss=0.0714, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1848 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1848batches [04:58,  6.27batches/s, epoch=1, loss=0.0594, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1849 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1849batches [04:58,  6.29batches/s, epoch=1, loss=0.162, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1850 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1850batches [04:58,  6.24batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1851 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1851batches [04:59,  6.29batches/s, epoch=1, loss=0.524, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1852 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1852batches [04:59,  6.28batches/s, epoch=1, loss=0.133, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1853 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1853batches [04:59,  6.27batches/s, epoch=1, loss=0.123, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1854 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1854batches [04:59,  6.28batches/s, epoch=1, loss=0.0971, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1855 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1855batches [04:59,  6.24batches/s, epoch=1, loss=0.165, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1856 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1856batches [04:59,  6.27batches/s, epoch=1, loss=0.26, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1857 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1857batches [05:00,  6.27batches/s, epoch=1, loss=0.126, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1858 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1858batches [05:00,  6.25batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1859 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1859batches [05:00,  6.20batches/s, epoch=1, loss=0.369, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1860 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1860batches [05:00,  6.24batches/s, epoch=1, loss=0.118, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1861 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1861batches [05:00,  6.26batches/s, epoch=1, loss=0.237, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1862 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1862batches [05:00,  6.23batches/s, epoch=1, loss=0.249, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1863 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1863batches [05:01,  6.24batches/s, epoch=1, loss=0.27, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1864 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1864batches [05:01,  6.25batches/s, epoch=1, loss=0.103, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1865 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1865batches [05:01,  6.22batches/s, epoch=1, loss=0.319, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1866 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1866batches [05:01,  6.24batches/s, epoch=1, loss=0.0588, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1867 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1867batches [05:01,  6.25batches/s, epoch=1, loss=0.355, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1868 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1868batches [05:01,  6.22batches/s, epoch=1, loss=0.144, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1869 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1869batches [05:02,  6.22batches/s, epoch=1, loss=0.12, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1870 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1870batches [05:02,  6.26batches/s, epoch=1, loss=0.132, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1871 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1871batches [05:02,  6.30batches/s, epoch=1, loss=0.119, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1872 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1872batches [05:02,  6.24batches/s, epoch=1, loss=0.192, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1873 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1873batches [05:02,  6.23batches/s, epoch=1, loss=0.224, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1874 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1874batches [05:02,  6.25batches/s, epoch=1, loss=0.0749, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1875 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1875batches [05:02,  6.29batches/s, epoch=1, loss=0.261, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1876 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1876batches [05:03,  6.32batches/s, epoch=1, loss=0.114, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1877 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1877batches [05:03,  6.26batches/s, epoch=1, loss=0.392, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1878 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1878batches [05:03,  6.24batches/s, epoch=1, loss=0.221, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1879 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1879batches [05:03,  6.25batches/s, epoch=1, loss=0.157, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1880 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1880batches [05:03,  6.26batches/s, epoch=1, loss=0.153, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1881 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1881batches [05:03,  6.22batches/s, epoch=1, loss=0.149, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1882 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1882batches [05:04,  6.25batches/s, epoch=1, loss=0.0765, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1883 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1883batches [05:04,  6.23batches/s, epoch=1, loss=0.0595, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1884 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1884batches [05:04,  6.22batches/s, epoch=1, loss=0.0826, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1885 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1885batches [05:04,  6.23batches/s, epoch=1, loss=0.225, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1886 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1886batches [05:04,  6.22batches/s, epoch=1, loss=0.187, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1887 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1887batches [05:04,  6.25batches/s, epoch=1, loss=0.11, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1888 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1888batches [05:05,  6.25batches/s, epoch=1, loss=0.398, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1889 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1889batches [05:05,  6.19batches/s, epoch=1, loss=0.22, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1890 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1890batches [05:05,  6.24batches/s, epoch=1, loss=0.121, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1891 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1891batches [05:05,  6.24batches/s, epoch=1, loss=0.107, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1892 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1892batches [05:05,  6.23batches/s, epoch=1, loss=0.14, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1893 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1893batches [05:05,  6.28batches/s, epoch=1, loss=0.0896, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1894 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1894batches [05:06,  6.28batches/s, epoch=1, loss=0.139, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1895 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1895batches [05:06,  6.26batches/s, epoch=1, loss=0.375, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1896 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1896batches [05:06,  6.30batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1897 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1897batches [05:06,  6.30batches/s, epoch=1, loss=0.189, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1898 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1898batches [05:06,  6.31batches/s, epoch=1, loss=0.1, split=eval]  /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1899 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1899batches [05:06,  6.25batches/s, epoch=1, loss=0.205, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1900 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1900batches [05:06,  6.26batches/s, epoch=1, loss=0.215, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1901 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1901batches [05:07,  6.25batches/s, epoch=1, loss=0.231, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1902 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1902batches [05:07,  6.24batches/s, epoch=1, loss=0.154, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1903 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1903batches [05:07,  6.25batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1904 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1904batches [05:07,  6.15batches/s, epoch=1, loss=0.0832, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1905 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1905batches [05:07,  6.20batches/s, epoch=1, loss=0.147, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1906 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1906batches [05:07,  6.23batches/s, epoch=1, loss=0.244, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1907 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1907batches [05:08,  6.25batches/s, epoch=1, loss=0.295, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1908 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1908batches [05:08,  6.23batches/s, epoch=1, loss=0.288, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1909 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1909batches [05:08,  6.22batches/s, epoch=1, loss=0.288, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1910 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1910batches [05:08,  6.24batches/s, epoch=1, loss=0.177, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1911 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1911batches [05:08,  6.18batches/s, epoch=1, loss=0.105, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1912 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1912batches [05:08,  6.24batches/s, epoch=1, loss=0.114, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1913 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1913batches [05:09,  6.24batches/s, epoch=1, loss=0.149, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1914 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1914batches [05:09,  6.21batches/s, epoch=1, loss=0.193, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1915 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1915batches [05:09,  6.26batches/s, epoch=1, loss=0.248, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1916 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1916batches [05:09,  6.27batches/s, epoch=1, loss=0.224, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1917 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1917batches [05:09,  6.28batches/s, epoch=1, loss=0.178, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1918 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1918batches [05:09,  6.32batches/s, epoch=1, loss=0.0413, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1919 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1919batches [05:10,  6.21batches/s, epoch=1, loss=0.106, split=eval] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1920 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1920batches [05:10,  6.26batches/s, epoch=1, loss=0.377, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1921 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1921batches [05:10,  6.24batches/s, epoch=1, loss=0.156, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1922 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1922batches [05:10,  6.29batches/s, epoch=1, loss=0.158, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1923 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1923batches [05:10,  6.32batches/s, epoch=1, loss=0.458, split=eval]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1924 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "MaskedLanguageModeling: 1924batches [05:10,  6.31batches/s, epoch=1, loss=0.195, split=eval]\n",
            "SequenceClassification:   0%|          | 0/125 [00:00<?, ?batches/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1925 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   1%|          | 1/125 [00:00<00:18,  6.69batches/s, epoch=1, loss=0.656, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1926 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   2%|▏         | 2/125 [00:00<00:19,  6.43batches/s, epoch=1, loss=0.683, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1927 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   2%|▏         | 3/125 [00:00<00:19,  6.36batches/s, epoch=1, loss=0.659, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1928 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   3%|▎         | 4/125 [00:00<00:19,  6.31batches/s, epoch=1, loss=0.655, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1929 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   4%|▍         | 5/125 [00:00<00:18,  6.34batches/s, epoch=1, loss=0.675, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1930 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   5%|▍         | 6/125 [00:00<00:18,  6.34batches/s, epoch=1, loss=0.649, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1931 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   6%|▌         | 7/125 [00:01<00:19,  6.17batches/s, epoch=1, loss=0.702, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1932 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   6%|▋         | 8/125 [00:01<00:18,  6.19batches/s, epoch=1, loss=0.632, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1933 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   7%|▋         | 9/125 [00:01<00:18,  6.15batches/s, epoch=1, loss=0.637, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1934 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   8%|▊         | 10/125 [00:01<00:18,  6.21batches/s, epoch=1, loss=0.637, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1935 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:   9%|▉         | 11/125 [00:01<00:18,  6.30batches/s, epoch=1, loss=0.668, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1936 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  10%|▉         | 12/125 [00:01<00:18,  6.28batches/s, epoch=1, loss=0.647, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1937 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  10%|█         | 13/125 [00:02<00:17,  6.34batches/s, epoch=1, loss=0.661, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1938 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  11%|█         | 14/125 [00:02<00:17,  6.37batches/s, epoch=1, loss=0.689, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1939 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  12%|█▏        | 15/125 [00:02<00:17,  6.28batches/s, epoch=1, loss=0.679, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1940 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  13%|█▎        | 16/125 [00:02<00:17,  6.27batches/s, epoch=1, loss=0.64, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1941 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  14%|█▎        | 17/125 [00:02<00:17,  6.28batches/s, epoch=1, loss=0.653, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1942 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  14%|█▍        | 18/125 [00:02<00:16,  6.31batches/s, epoch=1, loss=0.654, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1943 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  15%|█▌        | 19/125 [00:03<00:16,  6.31batches/s, epoch=1, loss=0.651, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1944 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  16%|█▌        | 20/125 [00:03<00:16,  6.32batches/s, epoch=1, loss=0.644, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1945 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  17%|█▋        | 21/125 [00:03<00:16,  6.33batches/s, epoch=1, loss=0.655, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1946 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  18%|█▊        | 22/125 [00:03<00:16,  6.29batches/s, epoch=1, loss=0.684, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1947 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  18%|█▊        | 23/125 [00:03<00:16,  6.25batches/s, epoch=1, loss=0.677, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1948 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  19%|█▉        | 24/125 [00:03<00:16,  6.31batches/s, epoch=1, loss=0.665, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1949 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  20%|██        | 25/125 [00:03<00:15,  6.36batches/s, epoch=1, loss=0.648, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1950 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  21%|██        | 26/125 [00:04<00:15,  6.33batches/s, epoch=1, loss=0.684, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1951 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  22%|██▏       | 27/125 [00:04<00:15,  6.33batches/s, epoch=1, loss=0.631, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1952 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  22%|██▏       | 28/125 [00:04<00:15,  6.30batches/s, epoch=1, loss=0.666, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1953 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  23%|██▎       | 29/125 [00:04<00:15,  6.28batches/s, epoch=1, loss=0.675, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1954 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  24%|██▍       | 30/125 [00:04<00:15,  6.28batches/s, epoch=1, loss=0.638, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1955 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  25%|██▍       | 31/125 [00:04<00:15,  6.24batches/s, epoch=1, loss=0.682, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1956 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  26%|██▌       | 32/125 [00:05<00:14,  6.29batches/s, epoch=1, loss=0.646, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1957 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  26%|██▋       | 33/125 [00:05<00:14,  6.35batches/s, epoch=1, loss=0.606, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1958 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  27%|██▋       | 34/125 [00:05<00:14,  6.36batches/s, epoch=1, loss=0.676, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1959 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  28%|██▊       | 35/125 [00:05<00:14,  6.39batches/s, epoch=1, loss=0.681, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1960 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  29%|██▉       | 36/125 [00:05<00:14,  6.29batches/s, epoch=1, loss=0.711, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1961 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  30%|██▉       | 37/125 [00:05<00:13,  6.29batches/s, epoch=1, loss=0.682, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1962 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  30%|███       | 38/125 [00:06<00:13,  6.29batches/s, epoch=1, loss=0.655, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1963 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  31%|███       | 39/125 [00:06<00:13,  6.24batches/s, epoch=1, loss=0.668, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1964 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  32%|███▏      | 40/125 [00:06<00:13,  6.26batches/s, epoch=1, loss=0.636, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1965 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  33%|███▎      | 41/125 [00:06<00:13,  6.24batches/s, epoch=1, loss=0.668, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1966 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  34%|███▎      | 42/125 [00:06<00:13,  6.28batches/s, epoch=1, loss=0.673, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1967 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  34%|███▍      | 43/125 [00:06<00:13,  6.16batches/s, epoch=1, loss=0.634, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1968 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  35%|███▌      | 44/125 [00:07<00:13,  6.13batches/s, epoch=1, loss=0.677, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1969 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  36%|███▌      | 45/125 [00:07<00:12,  6.22batches/s, epoch=1, loss=0.669, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1970 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  37%|███▋      | 46/125 [00:07<00:12,  6.15batches/s, epoch=1, loss=0.668, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1971 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  38%|███▊      | 47/125 [00:07<00:12,  6.19batches/s, epoch=1, loss=0.647, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1972 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  38%|███▊      | 48/125 [00:07<00:12,  6.20batches/s, epoch=1, loss=0.635, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1973 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  39%|███▉      | 49/125 [00:07<00:12,  6.21batches/s, epoch=1, loss=0.66, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1974 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  40%|████      | 50/125 [00:07<00:12,  6.22batches/s, epoch=1, loss=0.708, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1975 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  41%|████      | 51/125 [00:08<00:12,  6.16batches/s, epoch=1, loss=0.662, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1976 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  42%|████▏     | 52/125 [00:08<00:11,  6.23batches/s, epoch=1, loss=0.651, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1977 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  42%|████▏     | 53/125 [00:08<00:11,  6.22batches/s, epoch=1, loss=0.643, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1978 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  43%|████▎     | 54/125 [00:08<00:11,  6.19batches/s, epoch=1, loss=0.638, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1979 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  44%|████▍     | 55/125 [00:08<00:11,  6.26batches/s, epoch=1, loss=0.638, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1980 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  45%|████▍     | 56/125 [00:08<00:11,  6.18batches/s, epoch=1, loss=0.676, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1981 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  46%|████▌     | 57/125 [00:09<00:10,  6.21batches/s, epoch=1, loss=0.622, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1982 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  46%|████▋     | 58/125 [00:09<00:10,  6.30batches/s, epoch=1, loss=0.643, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1983 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  47%|████▋     | 59/125 [00:09<00:10,  6.22batches/s, epoch=1, loss=0.621, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1984 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  48%|████▊     | 60/125 [00:09<00:10,  6.24batches/s, epoch=1, loss=0.688, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1985 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  49%|████▉     | 61/125 [00:09<00:10,  6.25batches/s, epoch=1, loss=0.665, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1986 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  50%|████▉     | 62/125 [00:09<00:10,  6.29batches/s, epoch=1, loss=0.661, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1987 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  50%|█████     | 63/125 [00:10<00:09,  6.35batches/s, epoch=1, loss=0.672, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1988 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  51%|█████     | 64/125 [00:10<00:09,  6.36batches/s, epoch=1, loss=0.701, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1989 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  52%|█████▏    | 65/125 [00:10<00:09,  6.35batches/s, epoch=1, loss=0.73, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1990 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  53%|█████▎    | 66/125 [00:10<00:09,  6.34batches/s, epoch=1, loss=0.785, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1991 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  54%|█████▎    | 67/125 [00:10<00:09,  6.33batches/s, epoch=1, loss=0.75, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1992 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  54%|█████▍    | 68/125 [00:10<00:09,  6.30batches/s, epoch=1, loss=0.775, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1993 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  55%|█████▌    | 69/125 [00:10<00:08,  6.31batches/s, epoch=1, loss=0.737, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1994 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  56%|█████▌    | 70/125 [00:11<00:08,  6.30batches/s, epoch=1, loss=0.788, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1995 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  57%|█████▋    | 71/125 [00:11<00:08,  6.38batches/s, epoch=1, loss=0.734, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1996 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  58%|█████▊    | 72/125 [00:11<00:08,  6.40batches/s, epoch=1, loss=0.718, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1997 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  58%|█████▊    | 73/125 [00:11<00:08,  6.39batches/s, epoch=1, loss=0.754, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1998 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  59%|█████▉    | 74/125 [00:11<00:07,  6.41batches/s, epoch=1, loss=0.744, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 1999 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  60%|██████    | 75/125 [00:11<00:07,  6.42batches/s, epoch=1, loss=0.714, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2000 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  61%|██████    | 76/125 [00:12<00:07,  6.36batches/s, epoch=1, loss=0.708, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2001 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  62%|██████▏   | 77/125 [00:12<00:07,  6.33batches/s, epoch=1, loss=0.702, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2002 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  62%|██████▏   | 78/125 [00:12<00:07,  6.35batches/s, epoch=1, loss=0.757, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2003 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  63%|██████▎   | 79/125 [00:12<00:07,  6.29batches/s, epoch=1, loss=0.72, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2004 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  64%|██████▍   | 80/125 [00:12<00:07,  6.30batches/s, epoch=1, loss=0.734, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2005 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  65%|██████▍   | 81/125 [00:12<00:06,  6.33batches/s, epoch=1, loss=0.728, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2006 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  66%|██████▌   | 82/125 [00:13<00:06,  6.35batches/s, epoch=1, loss=0.69, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2007 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  66%|██████▋   | 83/125 [00:13<00:06,  6.35batches/s, epoch=1, loss=0.75, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2008 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  67%|██████▋   | 84/125 [00:13<00:06,  6.29batches/s, epoch=1, loss=0.703, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2009 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  68%|██████▊   | 85/125 [00:13<00:06,  6.22batches/s, epoch=1, loss=0.761, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2010 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  69%|██████▉   | 86/125 [00:13<00:06,  6.25batches/s, epoch=1, loss=0.771, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2011 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  70%|██████▉   | 87/125 [00:13<00:06,  6.22batches/s, epoch=1, loss=0.729, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2012 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  70%|███████   | 88/125 [00:14<00:05,  6.24batches/s, epoch=1, loss=0.708, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2013 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  71%|███████   | 89/125 [00:14<00:05,  6.20batches/s, epoch=1, loss=0.73, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2014 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  72%|███████▏  | 90/125 [00:14<00:05,  6.27batches/s, epoch=1, loss=0.677, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2015 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  73%|███████▎  | 91/125 [00:14<00:05,  6.33batches/s, epoch=1, loss=0.744, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2016 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  74%|███████▎  | 92/125 [00:14<00:05,  6.30batches/s, epoch=1, loss=0.75, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2017 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  74%|███████▍  | 93/125 [00:14<00:05,  6.35batches/s, epoch=1, loss=0.74, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2018 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  75%|███████▌  | 94/125 [00:14<00:04,  6.27batches/s, epoch=1, loss=0.774, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2019 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  76%|███████▌  | 95/125 [00:15<00:04,  6.28batches/s, epoch=1, loss=0.766, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2020 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  77%|███████▋  | 96/125 [00:15<00:04,  6.31batches/s, epoch=1, loss=0.717, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2021 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  78%|███████▊  | 97/125 [00:15<00:04,  6.36batches/s, epoch=1, loss=0.787, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2022 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  78%|███████▊  | 98/125 [00:15<00:04,  6.39batches/s, epoch=1, loss=0.734, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2023 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  79%|███████▉  | 99/125 [00:15<00:04,  6.38batches/s, epoch=1, loss=0.765, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2024 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  80%|████████  | 100/125 [00:15<00:03,  6.33batches/s, epoch=1, loss=0.698, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2025 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  81%|████████  | 101/125 [00:16<00:03,  6.20batches/s, epoch=1, loss=0.713, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2026 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  82%|████████▏ | 102/125 [00:16<00:03,  6.18batches/s, epoch=1, loss=0.729, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2027 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  82%|████████▏ | 103/125 [00:16<00:03,  6.16batches/s, epoch=1, loss=0.766, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2028 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  83%|████████▎ | 104/125 [00:16<00:03,  6.22batches/s, epoch=1, loss=0.76, split=eval] \u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2029 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  84%|████████▍ | 105/125 [00:16<00:03,  6.20batches/s, epoch=1, loss=0.735, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2030 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  85%|████████▍ | 106/125 [00:16<00:03,  6.18batches/s, epoch=1, loss=0.729, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2031 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  86%|████████▌ | 107/125 [00:17<00:02,  6.17batches/s, epoch=1, loss=0.729, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2032 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  86%|████████▋ | 108/125 [00:17<00:02,  6.26batches/s, epoch=1, loss=0.754, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2033 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  87%|████████▋ | 109/125 [00:17<00:02,  6.31batches/s, epoch=1, loss=0.702, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2034 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  88%|████████▊ | 110/125 [00:17<00:02,  6.22batches/s, epoch=1, loss=0.739, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2035 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  89%|████████▉ | 111/125 [00:17<00:02,  6.16batches/s, epoch=1, loss=0.757, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2036 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  90%|████████▉ | 112/125 [00:17<00:02,  6.19batches/s, epoch=1, loss=0.755, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2037 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  90%|█████████ | 113/125 [00:18<00:01,  6.19batches/s, epoch=1, loss=0.726, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2038 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  91%|█████████ | 114/125 [00:18<00:01,  6.10batches/s, epoch=1, loss=0.699, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2039 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  92%|█████████▏| 115/125 [00:18<00:01,  6.20batches/s, epoch=1, loss=0.765, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2040 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  93%|█████████▎| 116/125 [00:18<00:01,  6.21batches/s, epoch=1, loss=0.769, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2041 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  94%|█████████▎| 117/125 [00:18<00:01,  6.24batches/s, epoch=1, loss=0.781, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2042 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  94%|█████████▍| 118/125 [00:18<00:01,  6.31batches/s, epoch=1, loss=0.719, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2043 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  95%|█████████▌| 119/125 [00:18<00:00,  6.29batches/s, epoch=1, loss=0.715, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2044 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  96%|█████████▌| 120/125 [00:19<00:00,  6.23batches/s, epoch=1, loss=0.698, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2045 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  97%|█████████▋| 121/125 [00:19<00:00,  6.22batches/s, epoch=1, loss=0.732, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2046 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  98%|█████████▊| 122/125 [00:19<00:00,  6.24batches/s, epoch=1, loss=0.763, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2047 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  98%|█████████▊| 123/125 [00:19<00:00,  6.25batches/s, epoch=1, loss=0.731, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2048 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification:  99%|█████████▉| 124/125 [00:19<00:00,  6.23batches/s, epoch=1, loss=0.723, split=eval]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:533: UserWarning: Length of IterableDataset <adaptor.utils.TransformerAdaptationDataset object at 0x7fec83212a90> was reported to be 250 (when accessing len(dataloader)), but 2049 samples have been fetched. \n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "SequenceClassification: 100%|██████████| 125/125 [00:19<00:00,  6.19batches/s, epoch=1, loss=0.747, split=eval]\u001b[AConverged objectives: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.1942417472600937, 'eval_runtime': 330.8067, 'eval_samples_per_second': 0.756, 'eval_steps_per_second': 0.756, 'eval_MaskedLanguageModeling_loss': 0.1940250468039556, 'eval_MaskedLanguageModeling_num_batches': 1924, 'eval_SequenceClassification_loss': 0.6981173262596131, 'eval_SequenceClassification_num_batches': 125, 'epoch': 0.01}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4aa55c792680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0madapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCometCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1495\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1497\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1498\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0;31m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: save_model() got an unexpected keyword argument '_internal_call'"
          ]
        }
      ]
    }
  ]
}